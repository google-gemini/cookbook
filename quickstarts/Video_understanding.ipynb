{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5yiH5h8x3h"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGdicu8PVD9"
      },
      "source": [
        "# Video understanding with Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR4Ti6Q0QKIl"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w14yjWnPVD-"
      },
      "source": [
        "Gemini has from the begining been a multimodal model, capable of analyzing all sorts of medias using its [long context window](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/).\n",
        "\n",
        "[Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) and later bring video analysis to a whole new level as illustrated in [this video](https://www.youtube.com/watch?v=Mot-JEU26GQ):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "CumMaR-sts53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Mot-JEU26GQ?si=pcb7-_MZTSi_1Zkw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Building with Gemini 2.0: Video understanding\n",
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Mot-JEU26GQ?si=pcb7-_MZTSi_1Zkw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jexx9acnuDsA"
      },
      "source": [
        "This notebook will show you how to easily use Gemini to perform the same kind of video analysis. Each of them has different prompts that you can select using the dropdown, also feel free to experiment with your own.\n",
        "\n",
        "You can also check the [live demo](https://aistudio.google.com/starter-apps/video) and try it on your own videos on [AI Studio](https://aistudio.google.com/starter-apps/video)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0HWzIEAQYqz"
      },
      "source": [
        "## Setup\n",
        "\n",
        "This section install the SDK, set it up using your [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n",
        "\n",
        "Expand the section if you are curious, but you can also just run it (it should take a couple of minutes since there are large files) and go straight to the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzBKAaL4QYq0"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both. This means that you can prototype an application using the Developer API and then migrate the application to Vertex AI without rewriting your code.\n",
        "\n",
        "More details about this new SDK on the [documentation](https://ai.google.dev/gemini-api/docs/sdks) or in the [Getting started](../quickstarts/Get_started.ipynb) notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q 'google-genai'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDUGen_kQYq2"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Lez1vBQYq3"
      },
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK you now only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITgsQyaXQYq4"
      },
      "source": [
        "### Select the Gemini model\n",
        "\n",
        "Video understanding works best Gemini 2.5 pro model. You can also select former models to compare their behavior but it is recommended to use at least the 2.0 ones.\n",
        "\n",
        "For more information about all Gemini models, check the [documentation](https://ai.google.dev/gemini-api/docs/models/gemini) for extended information on each of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv8ULT0lvJ47"
      },
      "source": [
        "### Get sample videos\n",
        "\n",
        "You will start with uploaded videos, as it's a more common use-case, but you will also see later that you can also use Youtube videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMcwUw48vL1N"
      },
      "outputs": [],
      "source": [
        "# Load sample images\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4 -O Pottery.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4 -O Trailcam.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4 -O Post_its.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4 -O User_study.mp4 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4YMNQulz_yY"
      },
      "source": [
        "### Upload the videos\n",
        "\n",
        "Upload all the videos using the File API. You can find modre details about how to use it in the [Get Started](../quickstarts/Get_started.ipynb#scrollTo=KdUjkIQP-G_i) notebook.\n",
        "\n",
        "This can take a couple of minutes as the videos will need to be processed and tokenized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUUMJ4kE0OZS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/a8oqdle18w7l\n",
            "Waiting for video to be processed.\n",
            "Waiting for video to be processed.\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/up8zhje3r0kt\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/h3edbtghktrw\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/mggylqo1cari\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "pottery_video = upload_video('Pottery.mp4')\n",
        "trailcam_video = upload_video('Trailcam.mp4')\n",
        "post_its_video = upload_video('Post_its.mp4')\n",
        "user_study_video = upload_video('User_study.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAa7sCD7tuMW"
      },
      "source": [
        "# Search within videos\n",
        "\n",
        "First, try using the model to search within your videos and describe all the animal sightings in the trailcam video.\n",
        "\n",
        "<video controls width=\"500\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZw41-lsKKMf"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "```json\n[\n  {\"timecode\": \"00:00:00\", \"caption\": \"The camera view is obscured by the fur of an animal sniffing it, before pulling back to show two gray foxes exploring a rocky, leaf-strewn woodland area during the day.\"},\n  {\"timecode\": \"00:11:00\", \"caption\": \"One of the gray foxes leaps onto a large boulder while the other continues sniffing the ground.\"},\n  {\"timecode\": \"00:17:00\", \"caption\": \"In black and white infrared footage, a mountain lion walks through the same woodland area, sniffing the ground intently.\"},\n  {\"timecode\": \"00:28:00\", \"caption\": \"The mountain lion pauses, shakes its head, looks around, and continues sniffing before walking out of frame.\"},\n  {\"timecode\": \"00:34:00\", \"caption\": \"At night, under infrared light, two gray foxes are in the woodland. One sniffs the ground while the other rolls playfully on its back.\"},\n  {\"timecode\": \"00:43:00\", \"caption\": \"The rolling fox sits up as the other approaches. They interact briefly before darting away quickly.\"},\n  {\"timecode\": \"00:50:00\", \"caption\": \"Three gray foxes are now visible in the rocky area at night. One knocks the camera over as it passes.\"},\n  {\"timecode\": \"00:54:00\", \"caption\": \"Two foxes scramble up the rocks while one remains lower down, sniffing around before also climbing.\"},\n  {\"timecode\": \"01:04:00\", \"caption\": \"A mountain lion stands on the rocks at night, looking around, before walking further up and disappearing behind the boulders.\"},\n  {\"timecode\": \"01:17:00\", \"caption\": \"Another mountain lion, possibly a cub, appears briefly on the rocks in the background.\"},\n  {\"timecode\": \"01:18:00\", \"caption\": \"An adult mountain lion walks towards the camera and then turns right, while a smaller mountain lion (cub) walks along the rocks behind it.\"},\n  {\"timecode\": \"01:28:00\", \"caption\": \"A bobcat stands in the woodland at night, illuminated by infrared light.\"},\n  {\"timecode\": \"01:32:00\", \"caption\": \"The bobcat sniffs the ground, briefly rolls onto its side, gets up, looks around, and then continues sniffing.\"},\n  {\"timecode\": \"01:50:00\", \"caption\": \"During the day, a large black bear walks towards the camera in the woodland, then turns and walks away.\"},\n  {\"timecode\": \"01:56:00\", \"caption\": \"Under infrared light, a mountain lion walks briskly through the woods from left to right.\"},\n  {\"timecode\": \"02:04:00\", \"caption\": \"A bear cub bumps the camera with its nose.\"},\n  {\"timecode\": \"02:07:00\", \"caption\": \"The bear cub walks away as another cub enters the frame, sniffs the ground, and follows the first.\"},\n  {\"timecode\": \"02:17:00\", \"caption\": \"The two bear cubs sniff the ground near a tree and then walk off together.\"},\n  {\"timecode\": \"02:22:00\", \"caption\": \"At night, a gray fox stands on a ridge overlooking the distant lights of a city, sniffing the ground.\"},\n  {\"timecode\": \"02:34:00\", \"caption\": \"A black bear walks along the same ridge at night, passing in front of the camera with the city lights in the background.\"},\n  {\"timecode\": \"02:41:00\", \"caption\": \"A mountain lion walks along the ridge overlooking the city lights at night.\"},\n  {\"timecode\": \"02:51:00\", \"caption\": \"At night, a mountain lion backs up to a tree and scent-marks it by spraying.\"},\n  {\"timecode\": \"02:56:00\", \"caption\": \"The mountain lion turns, sniffs the ground where it marked, looks up briefly, and continues sniffing.\"},\n  {\"timecode\": \"03:04:00\", \"caption\": \"An adult black bear stands in the sunlit woodland, facing the camera.\"},\n  {\"timecode\": \"03:09:00\", \"caption\": \"The bear looks around, sniffs the air with its mouth slightly open, and then walks towards the camera.\"},\n  {\"timecode\": \"03:22:00\", \"caption\": \"A light brown (cinnamon phase) bear cub stands sideways to the camera in the woodland.\"},\n  {\"timecode\": \"03:26:00\", \"caption\": \"The cub sniffs the ground, while a second, darker cub appears behind it.\"},\n  {\"timecode\": \"03:31:00\", \"caption\": \"The first cub walks towards the camera, followed closely by the second cub.\"},\n  {\"timecode\": \"03:40:00\", \"caption\": \"The two cubs are now very close to the camera, sniffing the ground. A third cub walks past in the background.\"},\n  {\"timecode\": \"03:49:00\", \"caption\": \"The first cub sits down facing away from the camera and scratches its side with a hind leg.\"},\n  {\"timecode\": \"03:57:00\", \"caption\": \"The sitting cub gets up, and all three cubs walk away from the camera together.\"},\n  {\"timecode\": \"04:03:00\", \"caption\": \"A light brown bear cub walks towards the camera, followed by another.\"},\n  {\"timecode\": \"04:11:00\", \"caption\": \"The two cubs stand near each other, looking around the woodland.\"},\n  {\"timecode\": \"04:21:00\", \"caption\": \"At night, a bobcat sits in the undergrowth, looking towards the camera with glowing eyes.\"},\n  {\"timecode\": \"04:24:00\", \"caption\": \"The bobcat looks away, then walks off into the darkness.\"},\n  {\"timecode\": \"04:29:00\", \"caption\": \"A gray fox emerges from the undergrowth at night, its eyes reflecting the infrared light.\"},\n  {\"timecode\": \"04:35:00\", \"caption\": \"The fox sniffs around near a fallen log, looks at the camera, and continues exploring.\"},\n  {\"timecode\": \"04:44:00\", \"caption\": \"Another gray fox appears briefly in the background and runs off quickly.\"},\n  {\"timecode\": \"04:49:00\", \"caption\": \"The first gray fox walks away from the camera into the dark woods.\"},\n  {\"timecode\": \"04:57:00\", \"caption\": \"A mountain lion sniffs the ground near the base of a tree at night.\"},\n  {\"timecode\": \"05:03:00\", \"caption\": \"The mountain lion looks up briefly, then turns and walks away from the camera.\"}\n]\n```",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\"  # @param [\"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\", \"Organize all scenes from this video in a table, along with timecode, a short description, a list of objects visible in the scene (with representative emojis) and an estimation of the level of excitement on a scale of 1 to 10\"] {\"allow-input\":true}\n",
        "\n",
        "video = trailcam_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOQzKYGJKAnD"
      },
      "source": [
        "The prompt used is quite a generic one, but you can get even better results if you cutomize it to your needs (like asking specifically for foxes).\n",
        "\n",
        "The [live demo on AI Studio](https://aistudio.google.com/starter-apps/video) shows how you can postprocess this output to jump directly to the the specific part of the video by clicking on the timecodes. If you are interested, you can check the [code of that demo on Github](https://github.com/google-gemini/starter-applets/tree/main/video)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wog32E7CKnT6"
      },
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the video and extract it in an organized way. You can even use Gemini reasoning capabilities to generate new ideas for you.\n",
        "\n",
        "<video controls width=\"400\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baNCeA3GKrfu"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Okay, here is the transcription of the sticky notes from the video, organized alphabetically into a table, followed by a few additional brainstormed ideas in a similar style.\n\n**Transcribed Project Name Ideas:**\n\n|                   |                     |                     |                    |\n| :---------------- | :------------------ | :------------------ | :----------------- |\n| Aether            | Chaos Field         | Euler's Path        | Odin               |\n| Andromeda's Reach | Chaos Theory        | Fractal             | Orion's Belt       |\n| Astral Forge      | Chimera Dream       | Galactic Core       | Orion's Sword      |\n| Athena            | Comet's Tail        | Golden Ratio        | Pandora's Box      |\n| Athena's Eye      | Convergence         | Hera                | Perseus Shield     |\n| Bayes Theorem     | Delphinus           | Infinity Loop       | Phoenix            |\n| Canis Major       | Draco               | Leo Minor           | Prometheus Rising  |\n| Centaurus         | Echo                | Lunar Eclipse       | Riemann's Hypoth.  |\n| Cerberus          | Equilibrium         | Lynx                | Sagitta            |\n| Celestial Drift   |                     | Lyra                | Serpens            |\n| Stellar Nexus     | Stokes Theorem      | Supernova Echo      | Symmetry           |\n| Taylor Series     | Titan               | Vector              | Zephyr             |\n\n*(Note: \"Riemann's Hypothesis\" was abbreviated slightly in the table for space.)*\n\n**Additional Brainstormed Ideas:**\n\n1.  **Event Horizon:** (Astronomy/Physics - Point of no return near a black hole)\n2.  **Project Icarus:** (Mythology - Referencing ambition and flight)\n3.  **Quantum Leap:** (Physics - Sudden change in state, implies advancement)\n4.  **Fibonacci Spiral:** (Mathematics/Nature - Pattern of growth and beauty)\n5.  **Vanguard:** (General/Abstract - Leading position, forefront of development)\n6.  **Nebula Prime:** (Astronomy - Primary or first cloud of gas/dust)\n7.  **Axiom Core:** (Mathematics/Logic - Fundamental truth or core principle)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\" # @param [\"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\", \"Which of those names who fit an AI product that can resolve complex questions using its thinking abilities?\"] {\"allow-input\":true}\n",
        "\n",
        "video = post_its_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjKIsLDMTNk1"
      },
      "source": [
        "# Structure information\n",
        "\n",
        "Gemini 2.0 is not only able to read text but also to reason and structure about real world objects. Like in this video about a display of ceramics with handwritten prices and notes.\n",
        "\n",
        "<video controls width=\"500\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqzqedMFT5Wp"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Okay, here is a table summarizing the items and notes shown in the image:\n\n| Item          | Description / Notes                       | Price |\n| :------------ | :---------------------------------------- | :---- |\n| Tumblers      | Glaze: #5 Artichoke double dip<br>4\"h x 3\"d (-ish) | \\$20  |\n| Small bowls   | 3.5\"h x 6.5\"d                             | \\$35  |\n| Med bowls     | 4\"h x 7\"d                                 | \\$40  |\n| *Glaze Info*  | #5 Artichoke double dip (Test tile shown) | N/A   |\n| *Glaze Info*  | #6 Gemini double dip, SLOW COOL (Test tile shown, marked 6rb) | N/A   |\n\n**Note:** The glaze for the small and medium bowls appears to be the \"#6 Gemini double dip\" based on visual similarity to the test tile, although the notes next to the bowls don't explicitly state the glaze name.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Give me a table of my items and notes\" # @param [\"Give me a table of my items and notes\", \"Help me come up with a selling pitch for my potteries\"] {\"allow-input\":true}\n",
        "\n",
        "video = pottery_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ],\n",
        "    config = types.GenerateContentConfig(\n",
        "        system_instruction=\"Don't forget to escape the dollar signs\",\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsh6i-Z6VHNK"
      },
      "source": [
        "As you can see, Gemini is able to grasp to with item corresponds each note, including the last one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIfsFC0pVUTD"
      },
      "source": [
        "# Analyze screen recordings for key moments\n",
        "\n",
        "You can also use the model to analyze screen recordings. Let's say you're doing user studies on how people use your product, so you end up with lots of screen recordings, like this one, that you have to manually comb through.\n",
        "With just one prompt, the model can describe all the actions in your video.\n",
        "\n",
        "<video controls width=\"400\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrMHZ0MxW75y"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Here is a summary of the video:\n\n(00:00-00:10) The video displays a mobile application called \"My Garden App\" showcasing various plants available for purchase.\n(00:10-00:17) The user interacts with the app by clicking the \"Like\" button for the Rose Plant, Fern, and Cactus, turning the buttons red.\n(00:13-00:25) They proceed to add the Fern, Cactus, and Hibiscus plants to the shopping cart, indicated by the \"Add to Cart\" button briefly changing to \"Added!\".\n(00:29-00:34) The user navigates to the \"Cart\" tab, showing the three selected items and the total price, and then briefly views the \"Profile\" tab showing counts for liked plants and cart items.\n(00:37-00:45) After returning to the home screen, the user unlikes the Hibiscus, likes the Snake Plant, and adds the Orchid to their cart.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\" # @param [\"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\", \"Choose 5 key shots from this video and put them in a table with the timecode, text description of 10 words or less, and a list of objects visible in the scene (with representative emojis).\", \"Generate bullet points for the video. Place each bullet point into an object with the timecode of the bullet point in the video.\"] {\"allow-input\":true}\n",
        "\n",
        "video = user_study_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEYYemjyKcZ7"
      },
      "source": [
        "# Analyze youtube videos\n",
        "\n",
        "On top of using your own videos you can also ask Gemini to get a video from Youtube and analyze it. He's an example using the keynote from Google IO 2023. Guess what the main theme was?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP0Dd0hJKvYm"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Okay, here are all the instances where Sundar Pichai says \"AI\" in the provided video, along with timestamps and context:\n\n1.  **0:29** - Context: Setting the stage for the keynote, acknowledging the current focus on AI.\n    > \"As you may have heard, **AI** is having a very busy year.\"\n\n2.  **0:38** - Context: Highlighting Google's long-term commitment and shift towards AI.\n    > \"Seven years into our journey as an **AI**-first company, we are at an exciting inflection point.\"\n\n3.  **0:45** - Context: Describing the goal and potential impact of AI development.\n    > \"We have an opportunity to make **AI** even more helpful for people, for businesses, for communities, for everyone.\"\n\n4.  **0:54** - Context: Referring to Google's ongoing use of AI to improve its products.\n    > \"We've been applying **AI** to make our products radically more helpful for a while.\"\n\n5.  **1:41** - Context: Discussing advancements in Google Workspace features like Smart Compose.\n    > \"Smart Compose led to more advanced writing features powered by **AI**.\"\n\n6.  **3:02** - Context: Explaining the technology behind Google Street View.\n    > \"Since the early days of Street View, **AI** has stitched together billions of panoramic images...\"\n\n7.  **3:15** - Context: Describing the technology used for the Immersive View feature in Google Maps.\n    > \"...Immersive View, which uses **AI** to create a high-fidelity representation of a place...\"\n\n8.  **5:08** - Context: Introducing Google Photos as an example of an AI-enhanced product.\n    > \"Another product made better by **AI** is Google Photos.\"\n\n9.  **5:38** - Context: Explaining how AI enables more powerful photo editing features.\n    > \"**AI** advancements give us more powerful ways to do this.\"\n\n10. **7:40** - Context: Summarizing the product examples shown (Gmail, Photos, Maps).\n    > \"...these are just a few examples of how **AI** can help you in moments that matter.\"\n\n11. **7:47** - Context: Stating the broader goal of leveraging AI across all Google products.\n    > \"...so much more we can do to deliver the full potential of **AI** across the products you know and love.\"\n\n12. **8:22** - Context: Positioning AI as central to Google's mission going forward.\n    > \"Looking ahead, making **AI** helpful for everyone is the most profound way we will advance our mission.\"\n\n13. **8:53** - Context: Highlighting the importance of responsible AI development and deployment.\n    > \"...by building and deploying **AI** responsibly so that everyone can benefit equally.\"\n\n14. **9:02** - Context: Linking the advancement of foundation models to the goal of making AI helpful.\n    > \"Our ability to make **AI** helpful for everyone relies on continuously advancing our foundation models.\"\n\n15. **11:26** - Context: Describing the capabilities of Sec-PaLM, a security-focused AI model.\n    > \"It uses **AI** to better detect malicious scripts...\"\n\n16. **12:14** - Context: Discussing future potential applications of Med-PaLM 2 in healthcare.\n    > \"You can imagine an **AI** collaborator that helps radiologists interpret images...\"\n\n17. **12:46** - Context: Framing PaLM 2 within Google's long-term vision for responsible AI.\n    > \"...latest step in our decade-long journey to bring **AI** in responsible ways to billions of people.\"\n\n18. **14:09** - Context: Emphasizing the parallel investment in AI responsibility alongside model development.\n    > \"As we invest in more advanced models, we're also deeply investing in **AI** responsibility.\"\n\n19. **15:04** - Context: Discussing metadata as a tool for identifying AI-generated content.\n    > \"We'll ensure every one of our **AI**-generated images has that metadata.\"\n\n20. **15:11** - Context: Referring to a future segment specifically on responsible AI.\n    > \"James will talk about our responsible approach to **AI** later.\"\n\n21. **15:30** - Context: Introducing Bard as Google's platform for conversational AI interaction.\n    > \"...our experiment for conversational **AI**.\"",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Find all the instances where Sundar says \\\"AI\\\". Provide timestamps and broader context for each instance.\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=ixRanV-rdAQ')\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cizoUEdIYLd0"
      },
      "source": [
        "Once again, you can check the  [live demo on AI Studio](https://aistudio.google.com/starter-apps/video) shows an example on how to postprocess this output. Check the [code of that demo](https://github.com/google-gemini/starter-applets/tree/main/video) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lND4jB6MrsSk"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "Try with you own videos using the [AI Studio's live demo](https://aistudio.google.com/starter-apps/video) or play with the examples from this notebook (in case you haven't seen, there are other prompts you can try in the dropdowns).\n",
        "\n",
        "For more examples of the Gemini capabilities, check the other guide from the [Cookbook](https://github.com/google-gemini/cookbook/). You'll learn how to use the [Live API](../quickstarts/Get_started_LiveAPI.ipynb), juggle with [multiple tools](../quickstarts/Get_started_LiveAPI_tools.ipynb) or use Gemini 2.0 [spatial understanding](../quickstarts/Spatial_understanding.ipynb) abilities.\n",
        "\n",
        "The [examples](https://github.com/google-gemini/cookbook/tree/main/examples/) folder from the cookbook is also full of nice code samples illustrating creative ways to use Gemini multimodal capabilities and long-context."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Video_understanding.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
