{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkenge/cookbook/blob/apollo/examples/Apollo_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Prompting with an Apollo 11 transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQ_LVlzIeXo"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7QvXQMrIhuZ"
      },
      "source": [
        "This notebook provides a quick example of how to prompt Gemini using a text file. In this case, you'll use a 400 page transcript from [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qLuL9m7KhvxR"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-genai>=1.7.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "Download the transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V4XeFdX1rxaE",
        "outputId": "fa8d04de-b249-46cf-fdf5-053804e45f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 04:24:23--  https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.207, 74.125.137.207, 142.250.101.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 847790 (828K) [text/plain]\n",
            "Saving to: ‘a11.txt’\n",
            "\n",
            "\ra11.txt               0%[                    ]       0  --.-KB/s               \ra11.txt             100%[===================>] 827.92K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-04-04 04:24:23 (71.0 MB/s) - ‘a11.txt’ saved [847790/847790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoiKgO2CswzA"
      },
      "source": [
        "Upload the file using the File API so its easier to pass it to the model later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_HzrDdp2Q1Cu",
        "outputId": "c289bd98-24e2-468a-f7ed-f50182e35549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/w1aam9an1xje\n"
          ]
        }
      ],
      "source": [
        "text_file_name = \"a11.txt\"\n",
        "print(f\"Uploading file...\")\n",
        "text_file = client.files.upload(file=text_file_name)\n",
        "print(f\"Completed upload: {text_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "## Generate Content\n",
        "\n",
        "After the file has been uploaded, you can make `client.models.generate_content` requests that reference the File API URI. Then you will ask the model to find a few lighthearted moments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9b1d2fe3ea31",
        "outputId": "9737a944-48f1-42f7-ab61-5f78fb55a0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here are four lighthearted moments from the provided text file:\n\n1.  **00 00 05 35 CDR**\n\nYou sure sound clear down there, Bruce. Sounds like you're sitting in your living room.\n\n**00 00 05 39 CC**\nOh, thank you. You all are coming through beautifully, too.\n\n    *   This exchange between the Commander and the Capsule Communicator (CAP COMM) expresses how clearly they're communicating, even comparing it to being in a comfortable setting like a living room.\n\n2.  **04 15 09 51 CC**\n(Laughter) Yes. (Laughter)\n\n    *   This marks the point where someone's laughter was recorded.\n\n3.  **05 04 49 53 CC**\nWe'll let you know about that.\n\n    *   This humorous remark from one of the crew members or from the controllers in the Mission Control, followed by the controllers' \"We'll let you know about that\" comment.\n\n4.  **05 10 49 16 CC**\n...and the ice is melted. And we're in good shape.\n\n    *   In a joking comment from the group at mission control.\n\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "prompt = \"Find four lighthearted moments in this text file.\"\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model=f\"models/{MODEL_ID}\",\n",
        "  contents=[\n",
        "   prompt,\n",
        "   text_file\n",
        "  ],\n",
        "  config={\n",
        "   \"httpOptions\": {\"timeout\": 18000}\n",
        "  }\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPDYdQSKTg4"
      },
      "source": [
        "## Delete File\n",
        "\n",
        "Files are automatically deleted after 2 days or you can manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d4eO8ZXoKdZf",
        "outputId": "275daed5-72ef-49a9-9af1-ec807197d839",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeleteFileResponse()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "client.files.delete(name=text_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oUCqb6IUnH"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "The File API accepts files under 2GB in size and can store up to 20GB of files per project. Learn more about the [File API](../quickstarts/File_API.ipynb) here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "Apollo_11.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}