{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjkBUWm8ZMlc"
      },
      "source": [
        "##### Copyright 2026 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZC64QGBZ2v9"
      },
      "source": [
        "# Engineering Reliability (API Features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDDzTW8DRVcc"
      },
      "source": [
        "To build a production-ready robotics system, you need more than just smart reasoningâ€”you need **determinism and reliability**.\n",
        "\n",
        "A robot controller cannot parse \"chatty\" or inconsistent text. It requires strict data formats and predictable latency. This notebook explores the Gemini API features that help bridge the gap between probabilistic AI and deterministic hardware.\n",
        "\n",
        "This notebook covers:\n",
        "1.  **JSON Mode:** Enforcing type safety to prevent controller crashes.\n",
        "2.  **Thinking Budgets:** Controlling the trade-off between response speed and reasoning depth.\n",
        "3.  **Code Execution:** Using a Python sandbox for precise math and high-resolution inspections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81jqmyhKZTZ1"
      },
      "source": [
        "## 1. Setup & Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONn2UcU7akFl"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-genai google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l6k_URWnnuz",
        "outputId": "606eea93-ce6a-4596-ac6d-49dac89cf71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading assets... Done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import textwrap\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "if not os.path.exists('robotics_utils.py'):\n",
        "    url = \"https://raw.githubusercontent.com/williamito/robotics-samples/refs/heads/main/robotics_utils.py\"\n",
        "    urllib.request.urlretrieve(url, 'robotics_utils.py')\n",
        "\n",
        "import robotics_utils as utils\n",
        "utils.download_assets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L0iD346and2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "MODEL_ID = \"gemini-3-flash-preview\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "json-mode-markdown"
      },
      "source": [
        "## 2. Part 1: Determinism (JSON Mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "filler-text-markdown"
      },
      "source": [
        "### Example: Eliminating Filler Text\n",
        "By enforcing JSON mode, we create a strict contract between the AI and our robot controller, ensuring the output is always machine-readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "filler-text-code",
        "outputId": "16dc3a85-92b0-4d35-bd0e-6731ffc265b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  \"Vacuuming floors\",\n",
            "  \"Mopping surfaces\",\n",
            "  \"Folding laundry\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "prompt = \"List 3 common household tasks for a robot.\"\n",
        "\n",
        "# Enforce JSON mode via configuration\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latency-control-markdown"
      },
      "source": [
        "## 3. Part 2: Latency Control (Thinking Budget)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "speed-vs-depth-markdown"
      },
      "source": [
        "### Example: Speed vs. Depth\n",
        "With **Thinking**, the model can take more time to reason about complex queries. For time-critical robotics loops (e.g., visual servoing), you can set a low budget. For complex planning, you can increase it.\n",
        "\n",
        "*Note: Thinking is supported on select models like `gemini-3-flash-preview`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "speed-vs-depth-code",
        "outputId": "f1ad11c3-93bf-4fd9-a41e-a1330b33ce3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fast Mode Time: 0.94s\n",
            "Dynamic Mode Time: 2.83s\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Define 'Inverse Kinematics' in one sentence.\"\n",
        "\n",
        "# Scenario A: Low Latency (Fast Mode)\n",
        "t0 = time.time()\n",
        "client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
        "    )\n",
        ")\n",
        "print(f\"Fast Mode Time: {time.time() - t0:.2f}s\")\n",
        "\n",
        "# Scenario B: Reasoning (Dynamic Mode)\n",
        "t1 = time.time()\n",
        "client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "print(f\"Dynamic Mode Time: {time.time() - t1:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "code-execution-markdown"
      },
      "source": [
        "## 4. Part 3: Precise Action (Code Execution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoom-inspection-markdown"
      },
      "source": [
        "### Example: Sensor Reading with Zoom\n",
        "The model can write Python code to crop and zoom into high-resolution images, mimicking a robot moving its head closer for a better look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoom-inspection-code",
        "outputId": "a541289e-ad72-4735-fe37-b85b1dbd7520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Answer: Based on the zoomed-in image of the display, the PM2.5 air quality reading is **014**. According to the sticker below the display, a reading between 0-12 particles is considered \"Excellent\" and 13-35 is \"Moderate,\" placing this reading at the low end of the \"Moderate\" range.\n"
          ]
        }
      ],
      "source": [
        "img_sensor = Image.open(\"air_quality.jpeg\")\n",
        "prompt_zoom = \"What is the air quality reading? Use code execution to zoom in on the display first.\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[img_sensor, prompt_zoom],\n",
        "    config=types.GenerateContentConfig(\n",
        "        tools=[types.Tool(code_execution=types.ToolCodeExecution)]\n",
        "    )\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.text: print(f\"Model Answer: {part.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion-markdown"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "You've completed the core capabilities tour!\n",
        "\n",
        "**Where to go next:**\n",
        "*   **[Gemini API Documentation](https://ai.google.dev/gemini-api/docs/):** Deep dive into the API."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
