{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Prompting with an Apollo 11 transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQ_LVlzIeXo"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7QvXQMrIhuZ"
      },
      "source": [
        "This notebook provides a quick example of how to prompt Gemini using a text file. In this case, you'll use a 400 page transcript from [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qLuL9m7KhvxR"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-genai>=1.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "Download the transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V4XeFdX1rxaE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-04 11:48:01--  https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.207, 74.125.142.207, 74.125.195.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 847790 (828K) [text/plain]\n",
            "Saving to: ‘a11.txt.1’\n",
            "\n",
            "\ra11.txt.1             0%[                    ]       0  --.-KB/s               \ra11.txt.1           100%[===================>] 827.92K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-03-04 11:48:01 (107 MB/s) - ‘a11.txt.1’ saved [847790/847790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoiKgO2CswzA"
      },
      "source": [
        "Upload the file using the File API so its easier to pass it to the model later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_HzrDdp2Q1Cu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/umcpmw8s1adm\n"
          ]
        }
      ],
      "source": [
        "text_file_name = \"a11.txt\"\n",
        "print(f\"Uploading file...\")\n",
        "text_file = client.files.upload(file=text_file_name)\n",
        "print(f\"Completed upload: {text_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "## Generate Content\n",
        "\n",
        "After the file has been uploaded, you can make `client.models.generate_content` requests that reference the File API URI. Then you will ask the model to find a few lighthearted moments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9b1d2fe3ea31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are four lighthearted moments from the Apollo 11 air-to-ground voice transcription:\n",
            "\n",
            "1.  **00 00 05 35 CDR: You sure sound clear down there, Bruce. Sounds like you're sitting in your living room.**\n",
            "    **00 00 05 39 CC: Oh, thank you. You all are coming through beautifully, too.**\n",
            "    *This exchange is light because the Commander compliments the CapCom on the clarity of his voice, suggesting a very relaxed and comfortable connection.*\n",
            "\n",
            "2.  **00 00 54 13 CMP: And tell Glenn Parker down at the Cape that he lucked out.**\n",
            "    **00 00 54 17 CC: Understand. Tell Glenn Parker he lucked out.**\n",
            "    **00 00 54 22 CMP: Yes. He lucked out. He doesn't owe me a cup of coffee.**\n",
            "    **00 00 54 26 CC: This is Houston. Roger. We'll pass it on.**\n",
            "    *This is funny because they are saying they're saying someone \"lucked out\" and doesn't owe someone a cup of coffee. The phrase \"lucked out\" has a casual, playful feel, and the quick passing of a message involving coffee adds to it.*\n",
            "\n",
            "3.  **00 01 29 27 LMP: Cecil B. deAldrin is standing by for instructions.**\n",
            "    *Buzz Aldrin refers to himself in a mock-formal, theatrical way, referencing the famous director Cecil B. DeMille. This is humorous due to the contrast between the serious, high-tech mission and the melodramatic, old-Hollywood reference.*\n",
            "\n",
            "4.  **00 04 28 45 CMP: I wanted to be 18 or 20 pounds above nominal, babe.**\n",
            "    **00 04 28 49 CC: Sorry about that.**\n",
            "    *There is a humorous use of the word babe as in what was supposed to be the intention.*\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Find four lighthearted moments in this text file.\"\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model=f\"models/{MODEL_ID}\",\n",
        "  contents=[\n",
        "   prompt,\n",
        "   text_file\n",
        "  ],\n",
        "  config={\n",
        "   \"httpOptions\": {\"timeout\": 600}\n",
        "  }\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPDYdQSKTg4"
      },
      "source": [
        "## Delete File\n",
        "\n",
        "Files are automatically deleted after 2 days or you can manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "d4eO8ZXoKdZf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeleteFileResponse()"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.files.delete(name=text_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oUCqb6IUnH"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "The File API accepts files under 2GB in size and can store up to 20GB of files per project. Learn more about the [File API](../quickstarts/File_API.ipynb) here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "Apollo_11.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
