{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8968a502d25e"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ca23c3f523a7"
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwH5rYtX5Xco"
   },
   "source": [
    "# What's new in Gemini-1.5-pro-002 and Gemini-1.5-flash-002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67ad518df45c"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4RV6XuQLjCc"
   },
   "source": [
    "This notebook explores the new options added with the 002 versions of the 1.5 series models:\n",
    "\n",
    "* Candidate count\n",
    "* Presence and frequency penalties\n",
    "* Response logprobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5ZjsAuEGK6i"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tnl6PeGKOfcA"
   },
   "source": [
    "Install a `002` compatible version of the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVTnXHg_nxMC"
   },
   "outputs": [],
   "source": [
    "%pip install -q \"google-genai>=1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLASVngmOm8K"
   },
   "source": [
    "import the package and give it your API-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6fY-RbxJl78"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRmN-qzhM47E"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d-e1KfaOxlJ"
   },
   "source": [
    "Import other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giN4GuufOu02"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJO3Cz7UO0Ms"
   },
   "source": [
    "Check available 002 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTBDsceYMh2S"
   },
   "outputs": [],
   "source": [
    "for model in client.models.list():\n",
    "  if '002' in model.name:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCFdQUXsIDcm"
   },
   "outputs": [],
   "source": [
    "model_name = \"models/gemini-1.5-flash-002\"\n",
    "test_prompt=\"Why don't people have tails\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBiweaL6LLKm"
   },
   "source": [
    "## Quick refresher on `generation_config` [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwwgGRtnLOqJ"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(model=model_name, contents='hello', config = types.GenerateContentConfig(temperature=1.0, max_output_tokens=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sDxl0g-LQdx"
   },
   "source": [
    "Note:\n",
    "\n",
    "* Each `generate_content` request is sent with a `config` (`chat.send_message` uses `generate_content`).\n",
    "* You can set the `config` by passing it in the arguments to `generate_content` (or `chat.send_message`).\n",
    "* You can pass the `config` as either a Python `dict`, or a `types.GenerateContentConfig`.\n",
    "* If you're ever unsure about the parameters of `config` check `types.GenerateContentConfig`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Cu9hYM4H8Cz"
   },
   "source": [
    "## Candidate count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_D56ekoO4pd"
   },
   "source": [
    "With 002 models you can now use `candidate_count > 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5fwiDPjIAfj"
   },
   "outputs": [],
   "source": [
    "config = dict(candidate_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr6DXm9_IGEJ"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(model=model_name, contents=test_prompt, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg9Qdl1oPBX9"
   },
   "source": [
    "But note that the `.text` quick-accessor only works for the simple 1-candidate case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxNgE6_SI7az"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  response.text # Fails with multiple candidates, sorry!\n",
    "except ValueError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDCqgP7YPHur"
   },
   "source": [
    "With multiple candidates you have to handle the list of candidates yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8Ud37EjJCfc"
   },
   "outputs": [],
   "source": [
    "for candidate in response.candidates:\n",
    "  display(Markdown(candidate.content.parts[0].text))\n",
    "  display(Markdown(\"-------------\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iUxBkmsPYvq"
   },
   "source": [
    "The response contains multiple full `Candidate` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOxbI7oSRNV_"
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g86txlIpW3FE"
   },
   "source": [
    "## Penalties\n",
    "\n",
    "The `002` models expose `penalty` arguments that let you affect the statistics of output tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw5ZwCCCUR2d"
   },
   "source": [
    "### Presence penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PeJ2GhBW537"
   },
   "source": [
    "The `presence_penalty` penalizes tokens that have already been used in the output, so it induces variety in the model's output. This is detectible if you count the unique words in the output.\n",
    "\n",
    "Here's a function to run a prompt a few times and report the fraction of unique words (words don't map perfectly to tokens but it's a simple way to see the effect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ecolt7BNHUr2"
   },
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FbjPwM3ZIaH"
   },
   "outputs": [],
   "source": [
    "def unique_words(prompt, config, N=10):\n",
    "  responses = []\n",
    "  vocab_fractions = []\n",
    "  for n in range(N):\n",
    "    response = client.models.generate_content(model=model_name, contents=prompt, config=config)\n",
    "    responses.append(response)\n",
    "\n",
    "    words = response.text.lower().split()\n",
    "    score = len(set(words))/len(words)\n",
    "    print(score)\n",
    "    vocab_fractions.append(score)\n",
    "\n",
    "  return vocab_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2PqpDPIZpr6"
   },
   "outputs": [],
   "source": [
    "prompt='Tell me a story'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GTXnUVlYyY9"
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "v = unique_words(prompt, config={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwFZBP68wKp3"
   },
   "outputs": [],
   "source": [
    "mean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlM8BVflUpAj"
   },
   "outputs": [],
   "source": [
    "# the penalty encourages diversity in the oputput tokens.\n",
    "v = unique_words(prompt, config=dict(presence_penalty=1.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJo-_6_owQfu"
   },
   "outputs": [],
   "source": [
    "mean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-CztHdqTc__"
   },
   "outputs": [],
   "source": [
    "# a negative penalty discourages diversity in the output tokens.\n",
    "v = unique_words(prompt, config=dict(presence_penalty=-1.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1eWaOAOwWrE"
   },
   "outputs": [],
   "source": [
    "mean(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA7LkwvBMCjd"
   },
   "source": [
    "The `presence_penalty` has a small effect on the vocabulary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_Anpg6YRPEx"
   },
   "source": [
    "### Frequency Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-m1BaNuXVoY"
   },
   "source": [
    "Frequency penalty is similar to the `presence_penalty` but  the penalty is multiplied by the number of times a token is used. This effect is much stronger than the `presence_penalty`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZw9D5ZvWnmq"
   },
   "source": [
    "The easiest way to see that it works is to ask the model to do something repetitive. The model has to get creative while trying to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ju9AIzBJ_-dR"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(model=model_name, contents='please repeat \"Cat\" 50 times, 10 per line',\n",
    "                                  config=dict(frequency_penalty=1.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9eixhvwS6It"
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HMQhl2bJnk1"
   },
   "source": [
    "Since the frequency penalty accumulates with usage, it can have a much stronger effect on the output compared to the presence penalty.\n",
    "\n",
    "> Caution: Be careful with negative frequency penalties: A negative penalty makes a token more likely the more it's used. This positive feedback quickly leads the model to just repeat a common token until it hits the `max_output_tokens` limit (once it starts the model can't produce the `<STOP>` token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48HdqCUK2oT9"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_name,\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=400,\n",
    "        frequency_penalty=-2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QpGQoHU27zK"
   },
   "outputs": [],
   "source": [
    "Markdown(response.text)  # the, the, the, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmntZO3gNt6r"
   },
   "outputs": [],
   "source": [
    "response.candidates[0].finish_reason"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "New_in_002.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}