{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy3KpnNx_Jl4"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fKqk8LWo_TCU"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP8PQnz1QrcF"
      },
      "source": [
        "# Gemini API: Providing base cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxGr_x3MRA0z"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysy--KfNRrCq"
      },
      "source": [
        "LLMs require specific instructions to provide the expected results. Because of this, it is vital to ensure that the model knows how it should behave when it lacks information or when it should not answer a given query and provide a default response instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne-3gnXqR0hI"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EconMHePQHGw"
      },
      "outputs": [],
      "source": [
        "from google import genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eomJzCa6lb90"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-JZzORUpVR2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMne_rcZmz1X"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pZ-S0f8_mbQ"
      },
      "source": [
        "Let's define a system instruction template that tells the model how it should answer questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_q8ak-BU9kJ"
      },
      "outputs": [],
      "source": [
        "instructions = \"\"\"\n",
        "You are an assistant that helps tourists around the world to plan their vacation. Your responsibilities are:\n",
        "1. Helping book the hotel.\n",
        "2. Recommending restaurants.\n",
        "3. Warning about potential dangers.\n",
        "\n",
        "If other request is asked return \"I cannot help with this request.\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oS9LnnXXedG"
      },
      "source": [
        "Now let's test the model with both on-topic and off-topic queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k6LyJQYm1KM"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash\", \"gemini-2.5-flash\", \"gemini-2.5-pro\"] {\"allow-input\": true}\n",
        "\n",
        "# On-topic query\n",
        "on_topic_response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What should I look out for when I'm going to the beaches in San Diego?\",\n",
        "    config={\"system_instruction\": instructions}\n",
        ")\n",
        "print(\"ON TOPIC:\", on_topic_response.text)\n",
        "\n",
        "# Off-topic query\n",
        "off_topic_response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What bowling places do you recommend in Moscow?\",\n",
        "    config={\"system_instruction\": instructions}\n",
        ")\n",
        "print(\"OFF TOPIC:\", off_topic_response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPUkURgrYgBr"
      },
      "source": [
        "Let's try another template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz-kWAKQYiGi"
      },
      "outputs": [],
      "source": [
        "instructions = \"\"\"\n",
        "You are an assistant at a library. Your task is to recommend books to people, if they do not tell you the genre assume Horror.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o5CRjdRaZfU"
      },
      "source": [
        "Now let's test this librarian assistant with queries that do and don't specify a genre:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoDDTXGFm21K"
      },
      "outputs": [],
      "source": [
        "# Query with specified genre\n",
        "specified_response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Could you recommend me 3 books with hard magic system?\",\n",
        "    config={\"system_instruction\": instructions}\n",
        ")\n",
        "print(\"## Specified genre:\\n\")\n",
        "print(specified_response.text)\n",
        "\n",
        "# Query without specified genre (should default to Horror)\n",
        "unspecified_response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Could you recommend me 2 books?\",\n",
        "    config={\"system_instruction\": instructions}\n",
        ")\n",
        "print(\"## Not specified genre:\\n\")\n",
        "print(unspecified_response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mzHkChy_5Ec"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Be sure to explore other examples of prompting in the repository. Try writing prompts about classifying your own data, or try some of the other prompting techniques such as few-shot prompting."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Providing_base_cases.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
