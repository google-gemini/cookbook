{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8968a502d25e"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ca23c3f523a7"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwH5rYtX5Xco"
      },
      "source": [
        "# Exploring Advanced Parameters with Updated Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67ad518df45c"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4RV6XuQLjCc"
      },
      "source": [
        "This notebook is updated for the `gemini-2.5 series` models that explores advanced parameters like `candidate_count`, `temperature`, `top_k`, and `top_p` for fine-grained output control. Unsupported parameters like `presence_penalty` and `frequency_penalty` are replaced by the model's inherent handling of repetition and diversity. It also demonstrates using response logprobs to analyze and refine outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3d3HM90Nma7"
      },
      "source": [
        "**Note**:\n",
        "\n",
        "* This notebook was originally designed for `002` models. It has been updated to work with the latest models in the SDK, focusing on advanced parameter exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ZjsAuEGK6i"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnl6PeGKOfcA"
      },
      "source": [
        "Install the latest version of the `google-genai` SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVTnXHg_nxMC"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-genai>=1.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLASVngmOm8K"
      },
      "source": [
        "Import the package and set up your API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6fY-RbxJl78"
      },
      "outputs": [],
      "source": [
        "from google import genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRmN-qzhM47E"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"GEMINI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GemsC2jENma9"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d-e1KfaOxlJ"
      },
      "source": [
        "Import other packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giN4GuufOu02"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJO3Cz7UO0Ms"
      },
      "source": [
        "Check model availibility:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmH-X-cDNma9",
        "outputId": "2c858957-a2ea-4e3e-c7aa-75811b56e144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-preview\n",
            "models/veo-3.0-fast-generate-preview\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/veo-3.1-generate-preview\n",
            "models/veo-3.1-fast-generate-preview\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ],
      "source": [
        "for model in client.models.list():\n",
        "        print(model.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCFdQUXsIDcm"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}\n",
        "test_prompt=\"Why don't people have tails?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBiweaL6LLKm"
      },
      "source": [
        "## Quick refresher on `generation_config` [Optional]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r339xAi1Nma-"
      },
      "outputs": [],
      "source": [
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwwgGRtnLOqJ"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "model= model_name,\n",
        "contents='hello',\n",
        "config=types.GenerateContentConfig(\n",
        "temperature=1.0,\n",
        "max_output_tokens=5,\n",
        "),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sDxl0g-LQdx"
      },
      "source": [
        "Note:\n",
        "\n",
        "* Each `generate_content` request is sent with a `generation_config` (`chat.send_message` uses `generate_content`).\n",
        "* You can set the `generation_config` by either passing it to the model's initializer, or passing it in the arguments to `generate_content` (or `chat.send_message`).\n",
        "* Any `generation_config` attributes set in `generate_content` override the attributes set on the model.\n",
        "* You can pass the `generation_config` as either a Python `dict`, or a `genai.GenerationConfig`.\n",
        "* If you're ever unsure about the parameters of `generation_config` check `genai.GenerationConfig`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cu9hYM4H8Cz"
      },
      "source": [
        "## Candidate count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_D56ekoO4pd"
      },
      "source": [
        "you can also use `candidate_count > 1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez_8Dm-WMIcp"
      },
      "outputs": [],
      "source": [
        "model = model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5fwiDPjIAfj"
      },
      "outputs": [],
      "source": [
        "generation_config = dict(candidate_count=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr6DXm9_IGEJ"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model= model,\n",
        "    contents=test_prompt,\n",
        "    config=generation_config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg9Qdl1oPBX9"
      },
      "source": [
        "Here the `.text` quick-accessor returns the text result from the first candidate when multiple candidates are present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxNgE6_SI7az",
        "outputId": "50e7a9b3-e2bb-4b96-a4bf-2a25c59f7274"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:google_genai.types:there are 2 candidates, returning text result from the first candidate. Access response.candidates directly to get the result from other candidates.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  response.text # Does not fail with multiple candidates, Returns text from the first candidate when multiple candidates are present.\n",
        "except ValueError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDCqgP7YPHur"
      },
      "source": [
        "When multiple candidates are present, iterate over `response.candidates` to access the content of each candidate individually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b8Ud37EjJCfc",
        "outputId": "12a006fe-21d1-42fd-ca50-108e4872ab95"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "People don't have tails primarily because of **evolutionary adaptation to bipedalism (walking upright)**.\n",
              "\n",
              "Here's a breakdown of the key reasons:\n",
              "\n",
              "1.  **Bipedalism and Balance:**\n",
              "    *   **Tails for Quadrupeds:** Many animals use their tails for balance when running, climbing, or leaping on four legs (quadrupeds). Think of a cheetah using its tail as a counterweight, or a monkey using its prehensile tail to grip branches.\n",
              "    *   **Human Balance:** When early hominids began walking exclusively on two legs, their center of gravity shifted. Our pelvis, spine, and leg structure evolved to provide stability and balance for upright walking. A tail would actually be a hindrance, an unnecessary appendage that could throw off balance rather than aid it.\n",
              "\n",
              "2.  **Dexterous Hands and Communication:**\n",
              "    *   **Grasping:** Humans developed highly dexterous hands with opposable thumbs, which became incredibly efficient for grasping, manipulating tools, and climbing (when necessary). This eliminated the need for a prehensile (grasping) tail.\n",
              "    *   **Communication:** Many animals use their tails for communication (e.g., dogs wagging, cats lashing, deer flagging). Humans, however, developed complex vocal language, intricate facial expressions, and sophisticated body language, making a communicative tail redundant.\n",
              "\n",
              "3.  **Vestigial Remnant: The Coccyx (Tailbone):**\n",
              "    *   While we don't have an external tail, we do have a **coccyx**, or tailbone, at the end of our spine. This is a vestigial structure, meaning it's a reduced and non-functional remnant of a feature that was present in our tailed ancestors. It's a clear piece of evidence that humans evolved from animals that *did* have tails.\n",
              "    *   The genes for tail development are still present in our DNA, but they are typically \"switched off\" during human embryonic development.\n",
              "\n",
              "4.  **No Functional Advantage:**\n",
              "    *   In the course of human evolution, a tail simply ceased to offer any functional advantage and, in fact, became a potential liability (extra weight, potential for injury, no use for balance or manipulation). Natural selection favored individuals without tails as they were better adapted to their environment and lifestyle.\n",
              "\n",
              "**In summary:** The absence of a tail in humans is a consequence of our unique evolutionary path, particularly our transition to upright walking and the development of sophisticated hands and communication methods."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "-------------"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Humans don't have tails because of a long evolutionary journey that led our ancestors to lose them. Here's a breakdown of the key reasons:\n",
              "\n",
              "1.  **Evolutionary History and Common Ancestors:**\n",
              "    *   **Shared Ancestry:** We share a common ancestor with many animals that *do* have tails, including monkeys.\n",
              "    *   **The Divergence:** The lineage that led to humans, along with other great apes (chimpanzees, gorillas, orangutans, gibbons), diverged from the lineage that led to monkeys approximately 20-25 million years ago. It was around this time that the ancestors of apes lost their tails.\n",
              "\n",
              "2.  **Adaptive Advantages (The \"Why\"):**\n",
              "    *   **Locomotion Changes:**\n",
              "        *   **Brachiation and Climbing:** Early apes developed different modes of locomotion. Instead of using tails for balance while running along branches (like many monkeys), they became adept at **brachiation** (swinging arm-over-arm through trees) or developed stronger grasping abilities for climbing. A tail might have been more of a hindrance than a help in these new movements.\n",
              "        *   **Ground Dwelling:** As some ape lineages spent more time on the ground, the need for an arboreal balancing tail diminished further.\n",
              "        *   **Bipedalism:** Much later, when our direct hominin ancestors began walking upright on two legs (**bipedalism**), a tail would have been actively disadvantageous, disrupting balance rather than aiding it, and requiring energy to maintain for no benefit.\n",
              "    *   **Energy Efficiency:** Building and maintaining a tail (muscles, nerves, bone) requires energy. If a tail is no longer useful, natural selection would favor individuals who don't expend resources on it, allowing that energy to be used for other vital functions.\n",
              "\n",
              "3.  **Genetic Basis (The \"How\"):**\n",
              "    *   **Gene Mutation:** The loss of tails is attributed to a series of genetic mutations. Recent research, for example, points to a specific insertion in the *TBXT* gene (also known as *Brachyury*) that likely played a crucial role in suppressing tail development in early ape ancestors. This mutation essentially \"turned off\" the tail-growing program.\n",
              "    *   **Developmental Pathways:** The genetic instructions for building a tail are still present in our DNA, but they are suppressed or modified during development.\n",
              "\n",
              "4.  **Evidence of Our Tailless History:**\n",
              "    *   **The Coccyx (Tailbone):** This small, fused set of vertebrae at the base of our spine is a vestigial structure – a remnant of a tail. It's the proof that our ancestors *did* have tails, and we still carry the basic anatomical blueprint.\n",
              "    *   **Embryonic Tail:** Human embryos actually develop a tail-like structure for a few weeks during early gestation (around 4-6 weeks). This \"embryonic tail\" consists of 10-12 vertebrae and looks very much like a short tail. However, it is normally reabsorbed by the body, with the remaining vertebrae fusing to form the coccyx. This transient tail is a powerful piece of evidence for our evolutionary link to tailed ancestors.\n",
              "\n",
              "In summary, humans lack tails because our ape ancestors, tens of millions of years ago, underwent genetic mutations that led to their loss. This loss was likely favored by natural selection because it offered advantages in their changing modes of locomotion and environments, eventually solidifying with the evolution of bipedalism in the human lineage."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "-------------"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for candidate in response.candidates:\n",
        "  display(Markdown(candidate.content.parts[0].text))\n",
        "  display(Markdown(\"-------------\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iUxBkmsPYvq"
      },
      "source": [
        "The response contains multiple full `Candidate` objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOxbI7oSRNV_",
        "outputId": "35b34596-a53d-44a6-89fc-d560beed862e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GenerateContentResponse(\n",
              "  automatic_function_calling_history=[],\n",
              "  candidates=[\n",
              "    Candidate(\n",
              "      content=Content(\n",
              "        parts=[\n",
              "          Part(\n",
              "            text=\"\"\"People don't have tails primarily because of **evolutionary adaptation to bipedalism (walking upright)**.\n",
              "\n",
              "Here's a breakdown of the key reasons:\n",
              "\n",
              "1.  **Bipedalism and Balance:**\n",
              "    *   **Tails for Quadrupeds:** Many animals use their tails for balance when running, climbing, or leaping on four legs (quadrupeds). Think of a cheetah using its tail as a counterweight, or a monkey using its prehensile tail to grip branches.\n",
              "    *   **Human Balance:** When early hominids began walking exclusively on two legs, their center of gravity shifted. Our pelvis, spine, and leg structure evolved to provide stability and balance for upright walking. A tail would actually be a hindrance, an unnecessary appendage that could throw off balance rather than aid it.\n",
              "\n",
              "2.  **Dexterous Hands and Communication:**\n",
              "    *   **Grasping:** Humans developed highly dexterous hands with opposable thumbs, which became incredibly efficient for grasping, manipulating tools, and climbing (when necessary). This eliminated the need for a prehensile (grasping) tail.\n",
              "    *   **Communication:** Many animals use their tails for communication (e.g., dogs wagging, cats lashing, deer flagging). Humans, however, developed complex vocal language, intricate facial expressions, and sophisticated body language, making a communicative tail redundant.\n",
              "\n",
              "3.  **Vestigial Remnant: The Coccyx (Tailbone):**\n",
              "    *   While we don't have an external tail, we do have a **coccyx**, or tailbone, at the end of our spine. This is a vestigial structure, meaning it's a reduced and non-functional remnant of a feature that was present in our tailed ancestors. It's a clear piece of evidence that humans evolved from animals that *did* have tails.\n",
              "    *   The genes for tail development are still present in our DNA, but they are typically \"switched off\" during human embryonic development.\n",
              "\n",
              "4.  **No Functional Advantage:**\n",
              "    *   In the course of human evolution, a tail simply ceased to offer any functional advantage and, in fact, became a potential liability (extra weight, potential for injury, no use for balance or manipulation). Natural selection favored individuals without tails as they were better adapted to their environment and lifestyle.\n",
              "\n",
              "**In summary:** The absence of a tail in humans is a consequence of our unique evolutionary path, particularly our transition to upright walking and the development of sophisticated hands and communication methods.\"\"\"\n",
              "          ),\n",
              "          Part(\n",
              "            text=\"\"\"Humans don't have tails because of a long evolutionary journey that led our ancestors to lose them. Here's a breakdown of the key reasons:\n",
              "\n",
              "1.  **Evolutionary History and Common Ancestors:**\n",
              "    *   **Shared Ancestry:** We share a common ancestor with many animals that *do* have tails, including monkeys.\n",
              "    *   **The Divergence:** The lineage that led to humans, along with other great apes (chimpanzees, gorillas, orangutans, gibbons), diverged from the lineage that led to monkeys approximately 20-25 million years ago. It was around this time that the ancestors of apes lost their tails.\n",
              "\n",
              "2.  **Adaptive Advantages (The \"Why\"):**\n",
              "    *   **Locomotion Changes:**\n",
              "        *   **Brachiation and Climbing:** Early apes developed different modes of locomotion. Instead of using tails for balance while running along branches (like many monkeys), they became adept at **brachiation** (swinging arm-over-arm through trees) or developed stronger grasping abilities for climbing. A tail might have been more of a hindrance than a help in these new movements.\n",
              "        *   **Ground Dwelling:** As some ape lineages spent more time on the ground, the need for an arboreal balancing tail diminished further.\n",
              "        *   **Bipedalism:** Much later, when our direct hominin ancestors began walking upright on two legs (**bipedalism**), a tail would have been actively disadvantageous, disrupting balance rather than aiding it, and requiring energy to maintain for no benefit.\n",
              "    *   **Energy Efficiency:** Building and maintaining a tail (muscles, nerves, bone) requires energy. If a tail is no longer useful, natural selection would favor individuals who don't expend resources on it, allowing that energy to be used for other vital functions.\n",
              "\n",
              "3.  **Genetic Basis (The \"How\"):**\n",
              "    *   **Gene Mutation:** The loss of tails is attributed to a series of genetic mutations. Recent research, for example, points to a specific insertion in the *TBXT* gene (also known as *Brachyury*) that likely played a crucial role in suppressing tail development in early ape ancestors. This mutation essentially \"turned off\" the tail-growing program.\n",
              "    *   **Developmental Pathways:** The genetic instructions for building a tail are still present in our DNA, but they are suppressed or modified during development.\n",
              "\n",
              "4.  **Evidence of Our Tailless History:**\n",
              "    *   **The Coccyx (Tailbone):** This small, fused set of vertebrae at the base of our spine is a vestigial structure – a remnant of a tail. It's the proof that our ancestors *did* have tails, and we still carry the basic anatomical blueprint.\n",
              "    *   **Embryonic Tail:** Human embryos actually develop a tail-like structure for a few weeks during early gestation (around 4-6 weeks). This \"embryonic tail\" consists of 10-12 vertebrae and looks very much like a short tail. However, it is normally reabsorbed by the body, with the remaining vertebrae fusing to form the coccyx. This transient tail is a powerful piece of evidence for our evolutionary link to tailed ancestors.\n",
              "\n",
              "In summary, humans lack tails because our ape ancestors, tens of millions of years ago, underwent genetic mutations that led to their loss. This loss was likely favored by natural selection because it offered advantages in their changing modes of locomotion and environments, eventually solidifying with the evolution of bipedalism in the human lineage.\"\"\"\n",
              "          ),\n",
              "        ],\n",
              "        role='model'\n",
              "      ),\n",
              "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
              "      index=0\n",
              "    ),\n",
              "    Candidate(\n",
              "      content=Content(\n",
              "        parts=[\n",
              "          Part(\n",
              "            text=\"\"\"Humans don't have tails because of a long evolutionary journey that led our ancestors to lose them. Here's a breakdown of the key reasons:\n",
              "\n",
              "1.  **Evolutionary History and Common Ancestors:**\n",
              "    *   **Shared Ancestry:** We share a common ancestor with many animals that *do* have tails, including monkeys.\n",
              "    *   **The Divergence:** The lineage that led to humans, along with other great apes (chimpanzees, gorillas, orangutans, gibbons), diverged from the lineage that led to monkeys approximately 20-25 million years ago. It was around this time that the ancestors of apes lost their tails.\n",
              "\n",
              "2.  **Adaptive Advantages (The \"Why\"):**\n",
              "    *   **Locomotion Changes:**\n",
              "        *   **Brachiation and Climbing:** Early apes developed different modes of locomotion. Instead of using tails for balance while running along branches (like many monkeys), they became adept at **brachiation** (swinging arm-over-arm through trees) or developed stronger grasping abilities for climbing. A tail might have been more of a hindrance than a help in these new movements.\n",
              "        *   **Ground Dwelling:** As some ape lineages spent more time on the ground, the need for an arboreal balancing tail diminished further.\n",
              "        *   **Bipedalism:** Much later, when our direct hominin ancestors began walking upright on two legs (**bipedalism**), a tail would have been actively disadvantageous, disrupting balance rather than aiding it, and requiring energy to maintain for no benefit.\n",
              "    *   **Energy Efficiency:** Building and maintaining a tail (muscles, nerves, bone) requires energy. If a tail is no longer useful, natural selection would favor individuals who don't expend resources on it, allowing that energy to be used for other vital functions.\n",
              "\n",
              "3.  **Genetic Basis (The \"How\"):**\n",
              "    *   **Gene Mutation:** The loss of tails is attributed to a series of genetic mutations. Recent research, for example, points to a specific insertion in the *TBXT* gene (also known as *Brachyury*) that likely played a crucial role in suppressing tail development in early ape ancestors. This mutation essentially \"turned off\" the tail-growing program.\n",
              "    *   **Developmental Pathways:** The genetic instructions for building a tail are still present in our DNA, but they are suppressed or modified during development.\n",
              "\n",
              "4.  **Evidence of Our Tailless History:**\n",
              "    *   **The Coccyx (Tailbone):** This small, fused set of vertebrae at the base of our spine is a vestigial structure – a remnant of a tail. It's the proof that our ancestors *did* have tails, and we still carry the basic anatomical blueprint.\n",
              "    *   **Embryonic Tail:** Human embryos actually develop a tail-like structure for a few weeks during early gestation (around 4-6 weeks). This \"embryonic tail\" consists of 10-12 vertebrae and looks very much like a short tail. However, it is normally reabsorbed by the body, with the remaining vertebrae fusing to form the coccyx. This transient tail is a powerful piece of evidence for our evolutionary link to tailed ancestors.\n",
              "\n",
              "In summary, humans lack tails because our ape ancestors, tens of millions of years ago, underwent genetic mutations that led to their loss. This loss was likely favored by natural selection because it offered advantages in their changing modes of locomotion and environments, eventually solidifying with the evolution of bipedalism in the human lineage.\"\"\"\n",
              "          ),\n",
              "        ],\n",
              "        role='model'\n",
              "      ),\n",
              "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
              "      index=1\n",
              "    ),\n",
              "  ],\n",
              "  model_version='gemini-2.5-flash',\n",
              "  response_id='Q_nwaJ_SPMDmqtsPsuz58Ag',\n",
              "  sdk_http_response=HttpResponse(\n",
              "    headers=<dict len=10>\n",
              "  ),\n",
              "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
              "    candidates_token_count=527,\n",
              "    prompt_token_count=9,\n",
              "    prompt_tokens_details=[\n",
              "      ModalityTokenCount(\n",
              "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "        token_count=9\n",
              "      ),\n",
              "    ],\n",
              "    thoughts_token_count=2094,\n",
              "    total_token_count=2630\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw5ZwCCCUR2d"
      },
      "source": [
        "### Temperature, Top-k & Top-p Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PeJ2GhBW537"
      },
      "source": [
        "parameters like `temperature`, `top_k`, and `top_p` can be used to influence the diversity and randomness of the model's output.\n",
        "\n",
        "* Temperature: Controls the randomness of token selection. Higher values (e.g., 1.5) increase diversity, while lower values (e.g., 0.2) make the output more deterministic.\n",
        "* Top-k: Limits the sampling to the top k most probable tokens, reducing randomness and encouraging repetition.\n",
        "* Top-p: Implements nucleus sampling, where the model considers the smallest set of tokens whose cumulative probability exceeds p.\n",
        "These parameters provide fine-grained control over the token sampling process, allowing you to achieve effects similar to those previously achieved with the `presence_penalty` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecolt7BNHUr2"
      },
      "outputs": [],
      "source": [
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FbjPwM3ZIaH"
      },
      "outputs": [],
      "source": [
        "def unique_words(prompt, generation_config, N=10):\n",
        "  responses = []\n",
        "  vocab_fractions = []\n",
        "  for n in range(N):\n",
        "    response = client.models.generate_content(\n",
        "      model= model_name,\n",
        "      contents=prompt,\n",
        "      config=generation_config\n",
        "    )\n",
        "    responses.append(response)\n",
        "\n",
        "    # Access the text content of the first candidate\n",
        "    words = response.text.lower().split()\n",
        "    score = len(set(words)) / len(words)\n",
        "    print(score)\n",
        "    vocab_fractions.append(score)\n",
        "\n",
        "  return vocab_fractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2PqpDPIZpr6"
      },
      "outputs": [],
      "source": [
        "prompt='Tell me a story'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GTXnUVlYyY9",
        "outputId": "5b2107c0-b80b-4762-98e2-9218414d2c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5250338294993234\n",
            "0.5386313465783664\n",
            "0.5520974289580515\n",
            "0.5456349206349206\n",
            "0.5435393258426966\n",
            "0.5512265512265512\n",
            "0.5147727272727273\n",
            "0.5535390199637024\n",
            "0.5032679738562091\n",
            "0.47992351816443596\n"
          ]
        }
      ],
      "source": [
        "# baseline\n",
        "v = unique_words(prompt, generation_config={})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwFZBP68wKp3",
        "outputId": "9a0a4d27-5af5-49df-83ae-9ac62eb8e7ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5307666641996984"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlM8BVflUpAj",
        "outputId": "05131ff8-2b12-4270-b703-71118e0799a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5605700712589073\n",
            "0.537746806039489\n",
            "0.5265901981230449\n",
            "0.5391304347826087\n",
            "0.5413687436159347\n",
            "0.5548098434004475\n",
            "0.5195586760280843\n",
            "0.5638888888888889\n",
            "0.5224438902743143\n",
            "0.588150289017341\n"
          ]
        }
      ],
      "source": [
        "# these temperature, top_k, and top_p parameters can be used for diversity in output tokens.\n",
        "v = unique_words(prompt, generation_config= dict(temperature=1.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKI1qgE0NmbE"
      },
      "source": [
        "NOTE:\n",
        "* Penalty parameters (`presence_penalty`, `frequency_penalty`) are not supported in Gemini 2.5 models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W_9Aw5tNmbE"
      },
      "source": [
        "Migration Note:\n",
        "* The penalty parameters previously available in older models (like `-002` versions) are no longer supported in the `Gemini 2.5` series. The new model architecture inherently handles issues like repetition, and attempts to set penalties will result in an `INVALID_ARGUMENT` error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJo-_6_owQfu",
        "outputId": "2682c2ba-2911-4fdc-cbb8-697c48c1eb1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.545425784142906"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-CztHdqTc__",
        "outputId": "40c927bb-c8d9-4ec5-e037-46b01a90f879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5230566534914362\n",
            "0.4872665534804754\n",
            "0.5427286356821589\n",
            "0.5389221556886228\n",
            "0.5248041775456919\n",
            "0.5141579731743666\n",
            "0.5514809590973202\n",
            "0.5097783572359843\n",
            "0.5432098765432098\n",
            "0.5388127853881278\n"
          ]
        }
      ],
      "source": [
        "# parameters like temperature, top_k, top_p can also discourage diversity in the output tokens.\n",
        "v = unique_words(prompt, generation_config=dict(temperature=0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1eWaOAOwWrE",
        "outputId": "561417ca-44d8-4278-9391-65ff48d124fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5274218127327394"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA7LkwvBMCjd"
      },
      "source": [
        "The `temperature`, `top_k`, and `top_p` parameters can be used to influence the diversity and randomness of the model's output. These parameters provide fine-grained control over the token sampling process, allowing you to achieve effects similar to those previously achieved with the `presence_penalty` parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lydc1dN8NmbF"
      },
      "source": [
        "## Top-k Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-m1BaNuXVoY"
      },
      "source": [
        "The `top_k` parameter limits the sampling to the top `k` most probable tokens, encouraging repetition and reducing randomness. This can be used as an alternative to the unsupported `frequency_penalty` parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZw9D5ZvWnmq"
      },
      "source": [
        "The easiest way to see that it works is to ask the model to do something repetitive. The model has to get creative while trying to complete the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju9AIzBJ_-dR"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model= model_name,\n",
        "    contents='please repeat \"Cat\" 50 times, 10 per line, with random capitalization.',\n",
        "    config=dict(top_k=10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9eixhvwS6It",
        "outputId": "914ff12f-a6c6-4278-8618-d5d25ab51f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cat cAt CAT caT CAt Cat caT cat CaT CAT\n",
            "cat CA T cAt Cat caT CAt CAT caT Cat CaT\n",
            "CAT cAt Cat caT CAt cat CaT cAt CAT cat\n",
            "CAt CaT cat CAT caT CAt cat CAT cAt Cat\n",
            "Cat caT CAt cat CAT caT Cat cAt CaT CAT\n"
          ]
        }
      ],
      "source": [
        "print(response.candidates[0].content.parts[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HMQhl2bJnk1"
      },
      "source": [
        "\n",
        "> **Note**: The `frequency_penalty` parameter is not available in Gemini 2.5 models. Instead, the new model architecture inherently handles repetition issues. However, when the `max_output_tokens` limit is reached, the model may stop generating content prematurely, especially if internal reasoning consumes most of the tokens. To address this, consider adjusting parameters like `temperature`, `top_k`, and `top_p` to better control token usage and output diversity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHRLr-SfNmbF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48HdqCUK2oT9",
        "outputId": "e1d7536f-986f-4384-f8cd-f993bff61510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=10>\n",
            ") candidates=[Candidate(\n",
            "  content=Content(\n",
            "    role='model'\n",
            "  ),\n",
            "  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n",
            "  index=0\n",
            ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='JgTxaP6pEMeHqtsPir-p0QY' usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  prompt_token_count=5,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=5\n",
            "    ),\n",
            "  ],\n",
            "  thoughts_token_count=399,\n",
            "  total_token_count=404\n",
            ") automatic_function_calling_history=[] parsed=None\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents= prompt,\n",
        "    config=dict(\n",
        "        max_output_tokens=400,\n",
        "        top_p=0.2,\n",
        "        temperature=0.2,\n",
        "        )    # Controls randomness in token selection\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz09PvvqNmbG"
      },
      "source": [
        "### Token Consumption in Gemini 2.5 Models\n",
        "\n",
        "In the Gemini 2.5 models, the \"thoughts\" token count often consumes the majority of the allocated tokens, leaving little room for generating meaningful output. This behavior is particularly noticeable when using the `max_output_tokens` parameter, as shown in the example below.\n",
        "\n",
        "Additionally, the `frequency_penalty` parameter, which was available in older models, is not supported in Gemini 2.5. The new model architecture inherently handles repetition issues, but this can lead to scenarios where token allocation is dominated by internal reasoning rather than output generation.\n",
        "\n",
        "> **Observation**: The `finish_reason` in the response indicates `MAX_TOKENS`, highlighting that the model reached the token limit without producing meaningful content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QpGQoHU27zK",
        "outputId": "5119b16f-70c5-4b3f-9738-a183555e27c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(response.text)  # the, the, the, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "tmntZO3gNt6r",
        "outputId": "2639fe4a-e6a7-4a14-dc80-f31cd5c684fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.candidates[0].finish_reason"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
