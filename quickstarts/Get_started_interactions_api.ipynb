{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "019b978a",
      "metadata": {
        "id": "62f5797ad760"
      },
      "source": [
        "##### Copyright 2026 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48fe9408",
      "metadata": {
        "cellView": "form",
        "id": "67a5f9ada7de"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc1905c",
      "metadata": {
        "id": "aec7096a4c68"
      },
      "source": [
        "# Gemini API: Getting started with Interactions API\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_interactions_api.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>\n",
        "\n",
        "The [Interactions API](https://ai.google.dev/gemini-api/docs/interactions?ua=chat) is a unified interface for building with Gemini models and agents. It simplifies the development of agentic applications by handling server-side state management, tool orchestration, and long-running tasks.\n",
        "\n",
        "With a single endpoint, you can:\n",
        "\n",
        "- Interact with Gemini models for text, image, and audio generation\n",
        "- Build multi-turn conversations without managing history client-side\n",
        "- Call custom functions and built-in tools like Google Search\n",
        "- Run specialized agents like Deep Research for complex tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08889f50",
      "metadata": {
        "id": "61bd8ec2ebd8"
      },
      "source": [
        "<a name=\"setup\"></a>\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be5e0d4",
      "metadata": {
        "id": "3eeaea0c235c"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "Install the SDK from [PyPI](https://github.com/googleapis/python-genai). It's recommended to always use the latest version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafc3a85",
      "metadata": {
        "id": "edf82a078910"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q 'google-genai>=1.55.0' # 1.55 for Interactions API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "febc05b0",
      "metadata": {
        "id": "45d2c1d38f1e"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GEMINI_API_KEY`. If you don't already have an API key or you aren't sure how to create a Colab Secret, see [Authentication ![image](https://storage.googleapis.com/generativeai-downloads/images/colab_icon16.png)](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98086d18",
      "metadata": {
        "id": "d9034fd0e219"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e416ccd",
      "metadata": {
        "id": "fe15d30be553"
      },
      "source": [
        "## Create an interaction\n",
        "\n",
        "At its simplest, the Interactions API works like a standard chat completion. You provide a model and an input string. By default, interactions are stored (`store=True`), allowing you to reference them later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc364ca",
      "metadata": {
        "id": "502cd07febb8"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    system_instruction=\"You are a helpful assistant.\",\n",
        "    input=\"Explain quantum entanglement in one sentence.\"\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)\n",
        "# Output: Quantum entanglement is a phenomenon where particles become linked..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0feb5a5",
      "metadata": {
        "id": "8a4d2a6cae09"
      },
      "source": [
        "## Stateful Multi-turn Conversations\n",
        "\n",
        "One of the most powerful features of this API is **server-side state management**. You do not need to append messages to a list and send the full history back to the server every time.\n",
        "\n",
        "Use `previous_interaction_id` to continue a conversation.\n",
        "\n",
        "Note: Only conversation history is preserved. Parameters like `tools` or `generation_config` are interaction-scoped and must be re-declared if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd11680",
      "metadata": {
        "id": "c5b4bcc73247"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "turn_1 = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"My name is Alice and I am a software engineer.\"\n",
        ")\n",
        "print(f\"Turn 1 ID: {turn_1.id}\")\n",
        "\n",
        "turn_2 = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"What is my job?\",\n",
        "    previous_interaction_id=turn_1.id\n",
        ")\n",
        "\n",
        "print(turn_2.outputs[-1].text)\n",
        "# Output: You are a software engineer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f021ef",
      "metadata": {
        "id": "bc540b10978d"
      },
      "source": [
        "For client-managed history, see\n",
        "[Stateless conversations](/gemini-api/docs/interactions#stateless-conversation).\n",
        "\n",
        "### Forking Conversations\n",
        "Because state is managed by ID, you can \"fork\" a conversation by referencing an older interaction ID with a different prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f03cd6c",
      "metadata": {
        "id": "1fb6b21cd5e6"
      },
      "outputs": [],
      "source": [
        "# Branch off from Turn 1 with a different topic\n",
        "turn_2_fork = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"What is my name?\",\n",
        "    previous_interaction_id=turn_1.id\n",
        ")\n",
        "\n",
        "print(turn_2_fork.outputs[-1].text)\n",
        "# Output: Your name is Alice."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "893841d0",
      "metadata": {
        "id": "7f687c406746"
      },
      "source": [
        "## Multimodal Interactions\n",
        "\n",
        "Gemini models natively understand and generate multiple content types. You can pass text, images, audio, or PDF documents in a single interaction. This example uses a remote image URL.\n",
        "\n",
        "### Multimodal understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce2eb99d",
      "metadata": {
        "id": "7a0568138c55"
      },
      "outputs": [],
      "source": [
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=[\n",
        "        {\"type\": \"text\", \"text\": \"Generate a recipe for the shown scones.\"},\n",
        "        {\n",
        "            \"type\": \"image\", \n",
        "            \"uri\": \"https://storage.googleapis.com/generativeai-downloads/images/scones.jpg\"\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42be0050",
      "metadata": {
        "id": "6f69e3f8e17f"
      },
      "source": [
        "For audio, video, and document (PDF) understanding, see\n",
        "[Multimodal understanding](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#understanding).\n",
        "\n",
        "\n",
        "### Multimodal Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ecb29e",
      "metadata": {
        "id": "06c405fb6598"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from IPython.display import Image\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-pro-image-preview\",\n",
        "    input=\"Generate an image of a futuristic city at sunset.\"\n",
        ")\n",
        "\n",
        "for output in interaction.outputs:\n",
        "    if output.type == \"image\":\n",
        "        with open(\"city.png\", \"wb\") as f:\n",
        "            f.write(base64.b64decode(output.data))\n",
        "\n",
        "Image(filename='city.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ee1711",
      "metadata": {
        "id": "b0fff123c906"
      },
      "source": [
        "For audio generation see [Multimodal generations](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#generation).\n",
        "\n",
        "\n",
        "## Tool use\n",
        "\n",
        "Tools extend the model's capabilities by letting it call external functions or\n",
        "services. The API includes ready-to-use tools, like Google Search or lets you define custom tools as JSON schema. The model decides when to call them based on the conversation:\n",
        "\n",
        "### Built-in tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2788b72",
      "metadata": {
        "id": "a70981da744f"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Who won the 2024 Nobel Prize in Physics?\",\n",
        "    tools=[{\"type\": \"google_search\"}]\n",
        ")\n",
        "\n",
        "text_output = next((o for o in interaction.outputs if o.type == \"text\"), None)\n",
        "if text_output:\n",
        "    print(text_output.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceea94fe",
      "metadata": {
        "id": "bf90ebd90997"
      },
      "source": [
        "Other built-in tools include [Code Execution](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#tools-and-function-calling) and [Computer Use](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#tools-and-function-calling).\n",
        "\n",
        "\n",
        "### Function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c3166d5",
      "metadata": {
        "id": "83650f2f1d5c"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# Define a tool\n",
        "weather_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"Get current weather for a location\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"location\": {\"type\": \"string\", \"description\": \"City name\"}\n",
        "        },\n",
        "        \"required\": [\"location\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Send request with tool\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"What's the weather in Tokyo?\",\n",
        "    tools=[weather_tool]\n",
        ")\n",
        "\n",
        "# Handle tool call\n",
        "for output in interaction.outputs:\n",
        "    if output.type == \"function_call\":\n",
        "        # Execute your function (mocked here)\n",
        "        # result = get_weather(output.arguments)\n",
        "        result = {\"temperature\": \"22Â°C\", \"condition\": \"sunny\"}\n",
        "\n",
        "        # Return result to model\n",
        "        interaction = client.interactions.create(\n",
        "            model=\"gemini-3-flash-preview\",\n",
        "            previous_interaction_id=interaction.id,\n",
        "            input={\n",
        "                \"type\": \"function_result\",\n",
        "                \"name\": output.name,\n",
        "                \"call_id\": output.id,\n",
        "                \"result\": result\n",
        "            }\n",
        "        )\n",
        "        print(interaction.outputs[-1].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912189aa",
      "metadata": {
        "id": "170b6ccbf65d"
      },
      "source": [
        "For code execution, URL context, and MCP servers, see\n",
        "[Agentic capabilities](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#tools-and-function-calling).\n",
        "\n",
        "## Agents & Long-Running Tasks\n",
        "\n",
        "Beyond models, the Interactions API provides access to specialized agents.\n",
        "Deep Research executes multi-step research tasks, synthesizing information from\n",
        "multiple sources into comprehensive reports.\n",
        "\n",
        "Agents run asynchronously with `background=True`. Poll the interaction status\n",
        "to retrieve results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8c4eee",
      "metadata": {
        "id": "e283444e6f77"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "agent_interaction = client.interactions.create(\n",
        "    agent=\"deep-research-pro-preview-12-2025\", # Note: use 'agent', not 'model'\n",
        "    input=\"Research the history of the Google TPUs with a focus on 2025 specs.\",\n",
        "    background=True\n",
        ")\n",
        "\n",
        "\n",
        "# Poll for completion\n",
        "while True:\n",
        "    status_check = client.interactions.get(agent_interaction.id)\n",
        "    print(f\"Status: {status_check.status}\")\n",
        "    \n",
        "    if status_check.status == \"completed\":\n",
        "        print(\"\\n--- Final Report ---\\n\")\n",
        "        print(status_check.outputs[-1].text)\n",
        "        break\n",
        "    elif status_check.status in [\"failed\", \"cancelled\"]:\n",
        "        print(\"Agent failed.\")\n",
        "        break\n",
        "        \n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facb3b4b",
      "metadata": {
        "id": "c48f5aa2f4c1"
      },
      "source": [
        "For more details, see [Deep Research](https://ai.google.dev/gemini-api/docs/deep-research).\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "The Interactions API supports many more complex workflows. Check the [API Reference](https://ai.google.dev/api/interactions-api) for details on:\n",
        "\n",
        "\n",
        "*   **[Structured Outputs](https://ai.google.dev/gemini-api/docs/structured-output):** Force the model to return valid JSON matching a specific schema.\n",
        "*   **[Streaming](https://ai.google.dev/gemini-api/docs/interactions#streaming):** Stream token responses for real-time applications.\n",
        "*   **[Thinking Models](https://ai.google.dev/api/interactions-api#thinking):** Configure `thinking_level` for Gemini 2.5 and 3.0 models to handle complex reasoning.\n",
        "*   **[Remote MCP](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#remote-mcp-model-context-protocol):** Connect Gemini to your own private MCP servers.\n",
        "*   **[Combining tools and structured outputs](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#combining-tools-and-structured-output):** Combine tools and structured outputs to create more complex workflows.\n",
        "*   **[File Uploads](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#working-with-files):** Upload files to the model for processing.\n",
        "*   **[Data Model](https://ai.google.dev/gemini-api/docs/interactions?ua=chat#data-model):** high level overview of the main inputs and outputs of the API."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Get_started_interactions_api.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
