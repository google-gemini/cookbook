{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Customer Financial Profiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Customer_financial_profiler.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCVydW40iixa"
      },
      "source": [
        "<!-- Community Contributor Badge -->\n",
        "<table>\n",
        "  <tr>\n",
        "    <!-- Author Avatar Cell -->\n",
        "    <td bgcolor=\"#d7e6ff\">\n",
        "      <a href=\"https://github.com/sharathrushi\" target=\"_blank\" title=\"View Sharath Rushi's profile on GitHub\">\n",
        "        <img src=\"https://github.com/sharathrushi.png?size=100\"\n",
        "             alt=\"Sharath's GitHub avatar\"\n",
        "             width=\"100\"\n",
        "             height=\"100\">\n",
        "      </a>\n",
        "    </td>\n",
        "    <!-- Text Content Cell -->\n",
        "    <td bgcolor=\"#d7e6ff\">\n",
        "      <h2><font color='black'>This notebook was contributed by <a href=\"https://github.com/sharathrushi\" target=\"_blank\"><font color='#217bfe'><strong>Sharath Rushi</strong></font></a>.</font></h2>\n",
        "      <h5><font color='black'><a href=\"https://github.com/sharathrushi\" target=\"_blank\">\n",
        "      <!-- Footer -->\n",
        "      <font color='black'><small><em>Have a cool Gemini example? Feel free to <a href=\"https://github.com/google-gemini/cookbook/blob/main/CONTRIBUTING.md\" target=\"_blank\"><font color=\"#078efb\">share it too</font></a>!</em></small></font>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "# Overview\n",
        "This tutorial demonstrates estimating customer financial status\n",
        "Given a customer's financial documents such as payslips, rental agreements, house valuation, shares\n",
        "\n",
        "Estimating customer monthly income, movable assets, immovable assets\n",
        "\n",
        "This is helpful for financial institutions to check for loan eligibility, estimating customer's value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monLpKy7423V"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mi7BrkD44MF"
      },
      "source": [
        "### Install SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AQJjzmYgH3sX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf812f7-45b8-4979-c87c-916800941cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m724.2/724.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U -q \"google-genai>=1.0.0\"  # Install the Python SDK\n",
        "\n",
        "# Always set at least 1.0.0 as the minimal version as there were breaking\n",
        "# changes through the previous versions\n",
        "# Of course, if your notebook uses a new feature and needs a more recent\n",
        "# version, set the right minimum version to indicate when the feature was\n",
        "# introduced.\n",
        "# Always test your notebook with that fixed version (eg. '==1.0.0') to make.\n",
        "# sure it's really the minimum version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iOH07TaHFvGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4359054c-e8fc-43e6-a605-e7357ea70940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# This step might ask you to restart the session for the installed packages to be reflected\n",
        "\n",
        "%pip install -U -q pymupdf nougat-ocr transformers \"albumentations==1.3.1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "### Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication ![image](https://storage.googleapis.com/generativeai-downloads/images/colab_icon16.png)](../quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wltbMJLIIXGk"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL54YG-kMDVF"
      },
      "source": [
        "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](./Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lf6FamchMDsk"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-3-flash-preview\" # @param [\"gemini-2.5-flash-lite\", \"gemini-2.5-flash\", \"gemini-2.5-pro\", \"gemini-3-flash-preview\", \"gemini-3-pro-preview\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "# Ideally order the model by \"cabability\" ie. generation then within generation\n",
        "# 8b/flash-lite then flash then pro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6v8YIdSJBdi"
      },
      "source": [
        "# Configurable params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-aBCi_wEGVLc"
      },
      "outputs": [],
      "source": [
        "# Change this to the person you are interested in and upload their financial documents\n",
        "person_of_interest = \"Jesse Nathan\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB0isylKGVjJ"
      },
      "source": [
        "# Loading necessary sample files\n",
        "##### Below code downloads the sample input files to session storage\n",
        "##### This requires user to authenticate\n",
        "##### Note: These files get deleted after session expires"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "oK4xsRqLcy_-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage cp --recursive gs://ksharathrushik-genai/gemini-cookbook-customer-financial-profiler/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PERGM9rRbyEF",
        "outputId": "7e77056a-503c-4a84-db3c-df29658302f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://ksharathrushik-genai/gemini-cookbook-customer-financial-profiler/Jesse Nathan_1.pdf to file://./Jesse Nathan_1.pdf\n",
            "Copying gs://ksharathrushik-genai/gemini-cookbook-customer-financial-profiler/Jesse Nathan_2.pdf to file://./Jesse Nathan_2.pdf\n",
            "Copying gs://ksharathrushik-genai/gemini-cookbook-customer-financial-profiler/Jesse Nathan_3.pdf to file://./Jesse Nathan_3.pdf\n",
            "\n",
            "Average throughput: 13.3MiB/s\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWMplqvLI0N-"
      },
      "source": [
        "# Imports and files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zKbtxLrfIzqQ"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wj_c5SeXI268"
      },
      "outputs": [],
      "source": [
        "grounding_tool = types.Tool(google_search=types.GoogleSearch())\n",
        "config = types.GenerateContentConfig(tools=[grounding_tool])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hDjclftgJABQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            "1026e16ffca74b58b354f8ab7c7224fe",
            "f25001fdd84a413189fa290bba39777f",
            "82b150e3520d428caeaffce8fb3e9512",
            "7010ab964803470d9d4b0c737539e738",
            "e5c28905b9b24d4883b0c23b8dbafbf2",
            "ef02d6902fd7455f86e192f5f58e215b",
            "dbb58f5d6bed47cc90c17260b35f2d8c",
            "42ca3a1c74eb4b27954a137a6ebfbefd",
            "a8b3c0bc61814d549db10d58373a7dc6",
            "f8504da2840e4e4d81ca164402424975",
            "877762223bf042bd8d09a684c8a96131",
            "27ae39676a5b4c77a6117508aa430850",
            "c14bee5185e74d0e9c4c59f6729bf9ca",
            "b4e32a7d9db849688900011829614a3a",
            "e750a9648cc1429783f42aa66d14dee3",
            "241dafd5bac748bd8d35d30181680d30",
            "bd136da57ca84b02a53b6423753e1091",
            "8dbc4494b8664f5b9383b702109cc3b3",
            "655f004257b8466ab2c689d75873edb1",
            "cabf8a17acfa4720927329d2729374e9",
            "21ac35497a44491d99deae4f80795f0f",
            "5c8a4d1047534da69766bd2b58510f21",
            "1cc96c7d65684636bb06221b8df033d5",
            "0b721d32e33a413c991f16c4c8551421",
            "6b0ba3abb3fb4fc995fe9e20711eaa74",
            "52e08d49bc7046faab2c6df7273dae6b",
            "417fccc4f94e41e497d8cb13df81046c",
            "a27ad6e8baa14f71aebbc504dd218d5c",
            "3ef480db69554e37a1ee654f69ba53e4",
            "19123fd6ccf74cc4ad807d1b2038cca2",
            "0de2aa57c9894b0f9a9ef684b4d93112",
            "fa8f8cea5bfe47d8b6a0642cec1db9bb",
            "a2c38f3e5c8d4c899098daa40f4c8525",
            "bc195a57dc5944819502f438d8459481",
            "6b9fb84196774a83bd9d536281b8dee5",
            "09f2ec6ba20b455ab99db294564036f5",
            "646d087c52554f60a7fe1ce028d2c752",
            "e55101cde03a40a4b43616acad9c7a90",
            "d70bfd690cdc4b2397bac6c26e8802e8",
            "d1a7e7049b224f629fbb1e65d2d74dd6",
            "a752454288ab45e394fdbf6bb19d29c5",
            "492ee718d0f44af689c40a3f25e02235",
            "ee0988393dee4eb4b03e6833227196d1",
            "5c254a90c9e84ec8a656638cf6464116",
            "2b51fb167ae248d4a813966a30f936e6",
            "ce9f16bca3f340fb9fafa0fc46d88781",
            "da2a928bc2744563a62a75c9e0c71a8f",
            "41e0e4502fa54d1e9cdd7ffe7fdfb16c",
            "951793c45c9d42759a286dd997d9ca8f",
            "ee26865235df43b79566c2447bb9199b",
            "0d8e9a0c87a14445900134d00d9c7a86",
            "28ca1e61d62b4e80a5cc78e1d643f7e9",
            "3f3702be6c894a47ace20b29d2f56518",
            "09c12826fe8d4eadb13d69edfb47d4e8",
            "fd688c88ad404c57aeac5c3703caf448",
            "c1e0fc19449b46feb31354381f70f8c4",
            "df6f549f75a54325abba122838aeaf8f",
            "3b043e4d65684706b3dea858ab19dbbd",
            "f99638634d814e3b90dafe7c3337da0e",
            "876df0aff6db41e4a856b2a36ab15545",
            "f839b20910ed4d299fe2a97e17b57ade",
            "b23ace425df448babef6a3de52e55aa8",
            "5764ae0dd0504d19b5d1ff597feb2c91",
            "1d6ec7be03014633a4b3d9a43338853c",
            "3781fd577cc146cf885c7a5fbb2b3671",
            "c167ecfd633a4c9ba8bd1152e3170edf",
            "33979102946d4856a384c2626a53df7e",
            "12cd5ef4c23b4e4bb382ea3797c84477",
            "90236e4e930a430bb6c71bfc372fe668",
            "fda91ba92abb4887b567b919f2aa80c1",
            "8be0943870494a38987e4393981e8307",
            "70dd973c654741dbbf93b680a1caafac",
            "88572d9c8af746909f9e81eeb2ad9a40",
            "944b5ef100bc4b169871ce3d7ad22238",
            "3366e6dfb19e43ffb7254dc0495afd15",
            "8c931a585721446e8dcea563043e4942",
            "dbc5e2f68e834597996600076d40ae56",
            "3da1ce8321f14c7994b4519bfbaf02b7",
            "5ad1229877354a00bd5782b170ecd47d",
            "b201786c9a194ad7856c467998e278ac",
            "1ee3aaba1c004bcd9891d8ff862f8068",
            "f42aa377de5e4a21a5d373f78ed2dba4",
            "9a24cb6ce3144e1b98cc6d601cab9b04",
            "c981852b9b914b7282fa7abf51750e7d",
            "6de1fcb30ddf47b397fe5774fbe9bbca",
            "e7b2407b95dc4bc1a9937d08f32f619e",
            "bf728013fe474446a385c43277610d7a",
            "909fa65b4d974193ade60a4acde33d19"
          ]
        },
        "outputId": "12629811-e9bf-43c2-f5f2-2df7fca481dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1026e16ffca74b58b354f8ab7c7224fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The image processor of type `NougatImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27ae39676a5b4c77a6117508aa430850"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc96c7d65684636bb06221b8df033d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc195a57dc5944819502f438d8459481"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b51fb167ae248d4a813966a30f936e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e0fc19449b46feb31354381f70f8c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/484 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33979102946d4856a384c2626a53df7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/165 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3da1ce8321f14c7994b4519bfbaf02b7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoProcessor, VisionEncoderDecoderModel\n",
        "all_files = os.listdir('.')\n",
        "person_of_interest_files = [f for f in all_files if f.startswith(person_of_interest)]\n",
        "nougat_model_id = \"facebook/nougat-small\"\n",
        "processor = AutoProcessor.from_pretrained(nougat_model_id, do_crop_margin=False)\n",
        "model_base = VisionEncoderDecoderModel.from_pretrained(nougat_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H48Rs9_ZJ_gA"
      },
      "source": [
        "# AI ML Checks\n",
        "Checks whether the person is linked to illegal activities, terrorism or money laundering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kfdn_grrI-8u"
      },
      "outputs": [],
      "source": [
        "# @title Helper function to add citations\n",
        "def add_citations(response):\n",
        "    text = response.text\n",
        "\n",
        "    # Check if grounding metadata exists and has supports/chunks\n",
        "    if not response.candidates or not response.candidates[0].grounding_metadata:\n",
        "        print(\"No grounding metadata available. Returning original text.\")\n",
        "        return text\n",
        "\n",
        "    grounding_metadata = response.candidates[0].grounding_metadata\n",
        "    supports = grounding_metadata.grounding_supports\n",
        "    chunks = grounding_metadata.grounding_chunks\n",
        "\n",
        "    if not supports or not chunks:\n",
        "        print(\"No grounding supports or chunks available. Returning original text.\")\n",
        "        return text\n",
        "\n",
        "    # Sort supports by end_index in descending order to avoid shifting issues when inserting.\n",
        "    sorted_supports = sorted(supports, key=lambda s: s.segment.end_index, reverse=True)\n",
        "\n",
        "    for support in sorted_supports:\n",
        "        end_index = support.segment.end_index\n",
        "        if support.grounding_chunk_indices:\n",
        "            # Create citation string like [1](link1)[2](link2)\n",
        "            citation_links = []\n",
        "            for i in support.grounding_chunk_indices:\n",
        "                if i < len(chunks):\n",
        "                    uri = chunks[i].web.uri\n",
        "                    citation_links.append(f\"[{i + 1}]({uri})\")\n",
        "\n",
        "            citation_string = \", \".join(citation_links)\n",
        "            text = text[:end_index] + citation_string + text[end_index:]\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FmDrkXOGI-5n"
      },
      "outputs": [],
      "source": [
        "def aml_screening_with_grounding(name):\n",
        "    prompt = f\"\"\"\n",
        "    Based on recent news and publicly available information, is there any credible indication that {name} is involved in money laundering, terrorism financing, or other illegal activities?\n",
        "    Return 'True' if there are clear red flags or strong suspicious mentions; otherwise, return 'False'. Respond with only 'True' or 'False'.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=config,\n",
        "    )\n",
        "    print(f\"Raw response from Google: {response.text}\")\n",
        "\n",
        "    # Add citations for transparency\n",
        "    text_with_citations = add_citations(response)\n",
        "    print(f\"Grounding analysis for {name}:\\n{text_with_citations}\")\n",
        "\n",
        "    # Convert model's response to boolean\n",
        "    if response.text:\n",
        "      genai_analysis = response.text.strip().lower()\n",
        "      if \"true\" in genai_analysis:\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Zpora5ElN7jj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ba176c-1a16-4e09-b13b-6540f62f6ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw response from Google: False\n",
            "No grounding supports or chunks available. Returning original text.\n",
            "Grounding analysis for Jesse Nathan:\n",
            "False\n",
            "Red flags for Jesse Nathan: False\n"
          ]
        }
      ],
      "source": [
        "red_flags = aml_screening_with_grounding(person_of_interest)\n",
        "print(f\"Red flags for {person_of_interest}: {red_flags}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJgoChh8KTTZ"
      },
      "source": [
        "# Processing Source of Wealth Files\n",
        "##### Below code loads pdf, extracts text and generates the financial profile of the customer\n",
        "##### Note: It also supports image or scanned pdf documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kE7e_fL3KSXA"
      },
      "outputs": [],
      "source": [
        "import pymupdf as fitz\n",
        "from PIL import Image\n",
        "\n",
        "def pdf_to_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "    for page_num, page in enumerate(doc):\n",
        "        page_text_fitz = page.get_text()\n",
        "\n",
        "        # If fitz extracts no text, assume it's an image-based PDF and use Nougat\n",
        "        if not page_text_fitz.strip():\n",
        "            # Render page to an image (high resolution for OCR)\n",
        "            # Using a matrix to increase resolution (e.g., 2x2 or 3x3) can improve OCR accuracy.\n",
        "            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2)) # 2x resolution\n",
        "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "\n",
        "            # Process image with Nougat\n",
        "            pixel_values = processor(images=img, return_tensors=\"pt\", do_crop_margin=False, do_thumbnail=False, do_align_long_axis=False).pixel_values\n",
        "\n",
        "            # Ensure pixel_values are float32 for the model\n",
        "            if pixel_values.dtype != torch.float32:\n",
        "                pixel_values = pixel_values.float()\n",
        "\n",
        "            # Generate text using the Nougat model. Removed decoder_input_ids as it's not needed for starting generation from image.\n",
        "            outputs = model_base.generate(\n",
        "                pixel_values,\n",
        "                min_length=1,\n",
        "                max_new_tokens=1024, # Reduced max_new_tokens to prevent index out of range error\n",
        "                bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "            )\n",
        "            page_text_ocr = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "            full_text += page_text_ocr + \"\\n\\n\" # Add some separation between pages\n",
        "        else:\n",
        "            full_text += page_text_fitz + \"\\n\\n\" # Add some separation between pages\n",
        "    return full_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pny94jT5KSRC"
      },
      "outputs": [],
      "source": [
        "json_schema = \"\"\"\n",
        "    {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"all_sources_primarily_about_target_name\": { \"type\": \"string\" },\n",
        "        \"aggregated_values\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {\n",
        "            \"monthly_income\": {\n",
        "              \"type\": \"object\",\n",
        "              \"properties\": {\n",
        "                \"value\": { \"type\": \"number\" },\n",
        "                \"currency\": { \"type\": \"string\" },\n",
        "                \"period\": { \"type\": \"string\" }\n",
        "              },\n",
        "              \"required\": [\"value\", \"currency\", \"period\"]\n",
        "            },\n",
        "            \"immovable_assets\": {\n",
        "              \"type\": \"array\",\n",
        "              \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                  \"description\": { \"type\": \"string\" },\n",
        "                  \"value\": { \"type\": \"number\" },\n",
        "                  \"currency\": { \"type\": \"string\" },\n",
        "                  \"type\": { \"type\": \"string\" },\n",
        "                  \"valuation_basis\": { \"type\": \"string\" },\n",
        "                  \"age_of_property_years\": { \"type\": \"number\" }\n",
        "                },\n",
        "                \"required\": [\"description\", \"value\", \"currency\", \"type\", \"valuation_basis\", \"age_of_property_years\"]\n",
        "              }\n",
        "            },\n",
        "            \"movable_assets\": {\n",
        "              \"type\": \"object\",\n",
        "              \"properties\": {\n",
        "                \"stocks\": {\n",
        "                  \"type\": \"array\",\n",
        "                  \"items\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                      \"company_name\": { \"type\": \"string\" },\n",
        "                      \"number_of_shares\": { \"type\": \"number\" },\n",
        "                      \"par_value_per_share\": { \"type\": \"number\" },\n",
        "                      \"currency_per_share\": { \"type\": \"string\" },\n",
        "                      \"total_value\": { \"type\": \"number\" },\n",
        "                      \"total_value_currency\": { \"type\": \"string\" },\n",
        "                      \"owner\": { \"type\": \"string\" }\n",
        "                    },\n",
        "                    \"required\": [\"company_name\", \"number_of_shares\", \"par_value_per_share\", \"currency_per_share\", \"total_value\", \"total_value_currency\", \"owner\"]\n",
        "                  }\n",
        "                },\n",
        "                \"cash\": {\n",
        "                  \"type\": \"object\",\n",
        "                  \"properties\": {\n",
        "                    \"value\": { \"type\": \"number\" },\n",
        "                    \"currency\": { \"type\": \"string\" },\n",
        "                    \"note\": { \"type\": \"string\" }\n",
        "                  },\n",
        "                  \"required\": [\"value\", \"currency\", \"note\"]\n",
        "                }\n",
        "              },\n",
        "              \"required\": [\"stocks\", \"cash\"]\n",
        "            }\n",
        "          },\n",
        "          \"required\": [\"monthly_income\", \"immovable_assets\", \"movable_assets\"]\n",
        "        }\n",
        "      },\n",
        "      \"required\": [\"all_sources_primarily_about_target_name\", \"aggregated_values\"]\n",
        "    }\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yI8V_qycKSUO"
      },
      "outputs": [],
      "source": [
        "def verify_and_extract(text, target_name):\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following text from multiple sources regarding {target_name}.\n",
        "    1. Verify if all sources document is primarily about {target_name}. (Yes/No)\n",
        "    2. Aggregate the values to retrieve the following information:\n",
        "        - Monthly Income\n",
        "        - Immovable Assets (Real Estate)\n",
        "        - Movable Assets (Cash/Stocks)\n",
        "    3. Format as JSON.\n",
        "    Text: {text[:10000]} # Truncate for token limits\n",
        "    \"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config={\n",
        "            \"response_mime_type\": \"application/json\",\n",
        "            \"response_schema\": json.loads(json_schema)\n",
        "            }\n",
        "        )\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UIP2fJ-3KSOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e75b18b-7565-49c9-c473-898a9502d04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting information from Jesse Nathan_1.pdf\n",
            "Extracting information from Jesse Nathan_2.pdf\n",
            "Extracting information from Jesse Nathan_3.pdf\n",
            "{\"all_sources_primarily_about_target_name\":\"Yes\",\"aggregated_values\":{\"monthly_income\":{\"value\":8000,\"currency\":\"USD\",\"period\":\"Monthly\"},\"immovable_assets\":[],\"movable_assets\":{\"stocks\":[{\"company_name\":\"Everest Financial Group Inc.\",\"number_of_shares\":250,\"par_value_per_share\":1,\"currency_per_share\":\"USD\",\"total_value\":250,\"total_value_currency\":\"USD\",\"owner\":\"Jesse Nathan\"}],\"cash\":{\"value\":0,\"currency\":\"USD\",\"note\":\"No cash or bank account balances were specified in the documents.\"}}}}\n"
          ]
        }
      ],
      "source": [
        "combined_text = \"\"\n",
        "for file in person_of_interest_files:\n",
        "    text = pdf_to_text(file)\n",
        "    print(f\"Extracting information from {file}\")\n",
        "    combined_text += text + \"\\n\" # Added newline character\n",
        "result = verify_and_extract(combined_text, person_of_interest)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpZek5tnLSF5"
      },
      "source": [
        "## Next steps\n",
        "1. Token & Cost Management\n",
        "\n",
        "    Token Counts: Use model.count_tokens(prompt) before calling the API.\n",
        "\n",
        "    Billing: Gemini 1.5 Flash is significantly cheaper than Pro. For high-volume PDF parsing, use Flash.\n",
        "\n",
        "    Reduction: Implement Semantic Chunking. Instead of sending a 100-page PDF, use a lightweight NLP tool (like spaCy) to find pages containing \"Balance Sheet\" or \"Assets\" and only send those pages to the LLM.\n",
        "\n",
        "2. Metrics & Benchmarking\n",
        "Metric\tDescription\n",
        "Extraction Accuracy\tCompare LLM output against a manually labeled \"Golden Dataset.\"\n",
        "Latency\tTime taken from PDF upload to final report (Target: < 30s).\n",
        "F1 Score\tFor NER (Named Entity Recognition) of asset values.\n",
        "3. Hallucination Check & Monitoring\n",
        "\n",
        "    Self-Reflection: Ask the model to \"Provide the exact quote from the text where you found this asset value.\" If it can't, flag it as a potential hallucination.\n",
        "\n",
        "    NLI (Natural Language Inference): Use a smaller model to check if the generated \"Summary\" is logically entailed by the \"Source Text.\"\n",
        "\n",
        "    Monitoring: Use tools like Arize Phoenix or LangSmith to track drift and \"faithfulness\" scores in production.\n",
        "\n",
        "4. Human-in-the-Loop (HITL)\n",
        "\n",
        "In financial compliance, AI should never make the final \"Reject\" decision.\n",
        "\n",
        "    Confidence Thresholds: If the LLM confidence is <0.85, route the case to a compliance officer.\n",
        "\n",
        "    UI Annotation: Highlight the source PDF text in a dashboard so the human can quickly verify the AI's extraction.\n",
        "\n",
        "5. NLP Alternatives (Non-GenAI)\n",
        "\n",
        "To reduce costs or increase speed, use:\n",
        "\n",
        "    Entity Extraction: spaCy or Hugging Face FinBERT (fine-tuned for finance).\n",
        "\n",
        "    Pattern Matching: Regular Expressions (Regex) for specific formats like CIBIL scores or Currency amounts.\n",
        "\n",
        "    Classification: XGBoost on TF-IDF vectors to categorize documents before they reach the LLM."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5mi7BrkD44MF"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}