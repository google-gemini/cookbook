{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTx8eQlc3cP-"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "4HZoi8yf4GEU"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9I7LG483nXB"
      },
      "source": [
        "# Gemini API: Similarity Search using Qdrant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKO767lQIWh"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1xoF_bU4NCP"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWedABji6bXJ"
      },
      "source": [
        "The [Gemini API](https://ai.google.dev/models/gemini) provides access to a family of generative AI models for generating content and solving problems. These models are designed and trained to handle both text and images as input.\n",
        "\n",
        "[Qdrant](https://qdrant.tech/) is an open-source vector similarity search engine designed for efficient and scalable semantic search. It offers a simple yet powerful API to store and search high-dimensional vectors, supports filtering with metadata (payloads), and integrates easily into production systems. Qdrant can be self-hosted or accessed via its managed cloud service, making it quick to set up and ideal for a wide range of AI applications that rely on semantic understanding and retrieval.\n",
        "\n",
        "In this notebook, you'll learn how to perform a similarity search on data from a website with the help of Gemini API and Qdrant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIAarGkG8VwC"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, you must install the packages and set the necessary environment variables.\n",
        "\n",
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70wYOKUC8q1m"
      },
      "source": [
        "Install google's python client SDK for the Gemini API, `google-genai`. Next, install Qdrant's Python client SDK, `qdrant-client`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mnQbBnA1GKha"
      },
      "outputs": [],
      "source": [
        "%pip install -q \"google-genai>=1.0.0\"\n",
        "%pip install -q protobuf==4.25.1 qdrant-client[fastembed]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eomJzCa6lb90"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v-JZzORUpVR2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai_client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSI_-yD-f6RA"
      },
      "source": [
        "## Building the Movie Vector Index\n",
        "This section covers preparing the movie dataset, generating embeddings using Gemini, and indexing them in Qdrant for similarity search."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load the Dataset from Kaggle"
      ],
      "metadata": {
        "id": "eXG76XuDoq5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin by loading the dataset from Kaggle using the kagglehub library. The dataset used in this notebook is the TMDB Movie Dataset 2023, which contains approximately 1 Million+ movie entries."
      ],
      "metadata": {
        "id": "Y9a57dXrnIEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8n-X5X7cBWVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d24657-8089-45f5-bf28-68799b7218e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-be1b43b299ac>:6: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"TMDB_movie_dataset_v11.csv\"\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"asaniczka/tmdb-movies-dataset-2023-930k-movies\",\n",
        "  file_path,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Inspect the Dataset Structure"
      ],
      "metadata": {
        "id": "o5UoP2DknSdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform a basic inspection to understand the data schema and quality of this dataset."
      ],
      "metadata": {
        "id": "zbq3XQOso2ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dLAP-cw9DS3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984f41b8-90a0-4887-850d-c586bea29e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Columns:\n",
            "Index(['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date',\n",
            "       'revenue', 'runtime', 'adult', 'backdrop_path', 'budget', 'homepage',\n",
            "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
            "       'popularity', 'poster_path', 'tagline', 'genres',\n",
            "       'production_companies', 'production_countries', 'spoken_languages',\n",
            "       'keywords'],\n",
            "      dtype='object')\n",
            "\n",
            "Missing Values per Column:\n",
            "id                            0\n",
            "title                        13\n",
            "vote_average                  0\n",
            "vote_count                    0\n",
            "status                        0\n",
            "release_date             230430\n",
            "revenue                       0\n",
            "runtime                       0\n",
            "adult                         0\n",
            "backdrop_path            915284\n",
            "budget                        0\n",
            "homepage                1105934\n",
            "imdb_id                  609631\n",
            "original_language             0\n",
            "original_title               13\n",
            "overview                 263410\n",
            "popularity                    0\n",
            "poster_path              408557\n",
            "tagline                 1061787\n",
            "genres                   514526\n",
            "production_companies     689793\n",
            "production_countries     568330\n",
            "spoken_languages         546219\n",
            "keywords                 912769\n",
            "dtype: int64\n",
            "\n",
            "Number of rows: 1235247\n",
            "Number of unique IDs: 1234303\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDataset Columns:\")\n",
        "print(df.columns)\n",
        "\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(f\"\\nNumber of rows: {len(df)}\")\n",
        "print(f\"Number of unique IDs: {df['id'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Filter and Clean the Dataset"
      ],
      "metadata": {
        "id": "-DHqjBnho8sB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step filters the dataset to include only the relevant columns (`id`, `title`, `overview`, `genres`, `keywords`, `tagline`, and `release_date`) and removes entries missing critical information such as the movie title or both `overview` and `genres`.\n"
      ],
      "metadata": {
        "id": "90khrPi0pB1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FvanvDRbRGz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903e9d64-365c-4949-9261-64e5479e8f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 1235247\n",
            "Rows before dropping missing title: 1235247\n",
            "Rows after dropping missing title and dropping missing (genres and overview): 1095533\n",
            "\n",
            "Sample data after cleaning (keeping missing overviews):\n",
            "       id            title                                           overview  \\\n",
            "0   27205        Inception  Cobb, a skilled thief who commits corporate es...   \n",
            "1  157336     Interstellar  The adventures of a group of explorers who mak...   \n",
            "2     155  The Dark Knight  Batman raises the stakes in his war on crime. ...   \n",
            "3   19995           Avatar  In the 22nd century, a paraplegic Marine is di...   \n",
            "4   24428     The Avengers  When an unexpected enemy emerges and threatens...   \n",
            "\n",
            "                                        genres  \\\n",
            "0           Action, Science Fiction, Adventure   \n",
            "1            Adventure, Drama, Science Fiction   \n",
            "2               Drama, Action, Crime, Thriller   \n",
            "3  Action, Adventure, Fantasy, Science Fiction   \n",
            "4           Science Fiction, Action, Adventure   \n",
            "\n",
            "                                            keywords  \\\n",
            "0  rescue, mission, dream, airplane, paris, franc...   \n",
            "1  rescue, future, spacecraft, race against time,...   \n",
            "2  joker, sadism, chaos, secret identity, crime f...   \n",
            "3  future, society, culture clash, space travel, ...   \n",
            "4  new york city, superhero, shield, based on com...   \n",
            "\n",
            "                                             tagline  release_year  \n",
            "0               Your mind is the scene of the crime.        2010.0  \n",
            "1  Mankind was born on Earth. It was never meant ...        2014.0  \n",
            "2                  Welcome to a world without rules.        2008.0  \n",
            "3                        Enter the world of Pandora.        2009.0  \n",
            "4                            Some assembly required.        2012.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "print(f\"Original rows: {len(df)}\")\n",
        "\n",
        "columns_to_keep = ['id', 'title', 'overview', 'genres', 'keywords', 'tagline', 'release_date']\n",
        "\n",
        "df_relevant = df[columns_to_keep].copy()\n",
        "\n",
        "print(f\"Rows before dropping missing title: {len(df_relevant)}\")\n",
        "df_relevant.dropna(subset=['title'], inplace=True)\n",
        "df_relevant = df_relevant[~(df_relevant['genres'].isna() & df_relevant['overview'].isna())]\n",
        "print(f\"Rows after dropping missing title and dropping missing (genres and overview): {len(df_relevant)}\")\n",
        "\n",
        "# Fill missing text columns with empty strings\n",
        "text_cols_to_fill = ['overview', 'genres', 'keywords', 'tagline']\n",
        "for col in text_cols_to_fill:\n",
        "    df_relevant[col] = df_relevant[col].fillna('')\n",
        "\n",
        "\n",
        "# Extract release year from the release_date string\n",
        "def get_year(date_str):\n",
        "    if pd.isna(date_str) or not isinstance(date_str, str) or len(date_str) < 4:\n",
        "        return None\n",
        "    try:\n",
        "        return int(date_str[:4])\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "df_relevant['release_year'] = df_relevant['release_date'].apply(get_year)\n",
        "\n",
        "print(\"\\nSample data after cleaning (keeping missing overviews):\")\n",
        "print(df_relevant[['id', 'title', 'overview', 'genres', 'keywords', 'tagline', 'release_year']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Prepare Text for Embedding"
      ],
      "metadata": {
        "id": "lQOfcdqmxLqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step prepares the movie metadata for embedding by combining relevant fields into a single structured text string. This representation includes the title, overview, genres, keywords, tagline, and release year (if available). The output is stored in a new column called `text_for_embedding`.\n",
        "\n",
        "Embeddings are numerical vector representations of text that capture semantic meaning and relationships. These vectors can be used for tasks like similarity search and clustering.\n",
        "Learn more about [text embeddings](https://ai.google.dev/gemini-api/docs/embeddings) and explore the [Gemini embedding notebook](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/embedding_text_with_gemini.ipynb)."
      ],
      "metadata": {
        "id": "Bdcu4I9Lq0Kn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "POQgvioiZdYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8c7d85-0c76-4287-d755-a83853b9e1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id            title                                 text_for_embedding\n",
            "0   27205        Inception  Title: Inception\\nOverview: Cobb, a skilled th...\n",
            "1  157336     Interstellar  Title: Interstellar\\nOverview: The adventures ...\n",
            "2     155  The Dark Knight  Title: The Dark Knight\\nOverview: Batman raise...\n",
            "3   19995           Avatar  Title: Avatar\\nOverview: In the 22nd century, ...\n",
            "4   24428     The Avengers  Title: The Avengers\\nOverview: When an unexpec...\n"
          ]
        }
      ],
      "source": [
        "def create_embedding_text(row):\n",
        "    \"\"\"Combines available movie metadata into a single string for embedding.\"\"\"\n",
        "    # Title is always present, so it can be included directly\n",
        "    title_str = f\"Title: {row['title']}\"\n",
        "    overview_str = f\"Overview: {row['overview']}\" if row['overview'] else \"\"\n",
        "    year_str = f\"Release Year: {int(row['release_year'])}\" if pd.notna(row['release_year']) else \"\"\n",
        "    genre_str = f\"Genres: {row['genres']}\" if row['genres'] else \"\"\n",
        "    keywords_str = f\"Keywords: {row['keywords']}\" if row['keywords'] else \"\"\n",
        "    tagline_str = f\"Tagline: {row['tagline']}\" if row['tagline'] else \"\"\n",
        "\n",
        "    parts = [\n",
        "        title_str,\n",
        "        overview_str,\n",
        "        year_str,\n",
        "        genre_str,\n",
        "        keywords_str,\n",
        "        tagline_str\n",
        "    ]\n",
        "    return \"\\n\".join(part for part in parts if part)\n",
        "\n",
        "df_relevant['text_for_embedding'] = df_relevant.apply(create_embedding_text, axis=1)\n",
        "\n",
        "# Use this to inspect how movie data has been transformed for embedding\n",
        "print(df_relevant[['id', 'title', 'text_for_embedding']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9aASY5Uf_RO"
      },
      "source": [
        "### 5. Sample a Subset for Development"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve efficiency during development, especially when working with resource-intensive processes like embedding generation and vector indexing, it is common to work with a smaller subset of the full dataset. This step randomly samples 5,000 movies from the cleaned dataset if it contains more entries. If the dataset is already smaller than the sample size, the entire dataset is used."
      ],
      "metadata": {
        "id": "4G6hxoLDx0vz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U7xpaVeLZxYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1d1b44-8114-4b39-f564-50b6c01c233a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Taking a random sample of 5000 movies for development.\n",
            "Working with 5000 movies for the next steps.\n",
            "              id                       title  release_year\n",
            "89006     787356                           X        2021.0\n",
            "1085978  1005027  Pistruiatul 2: Ascunzișuri           NaN\n",
            "1105919   938917                  Chanakyudu        2012.0\n",
            "617410   1491546               She's Legal 3        2018.0\n",
            "438702   1086816             Pleasure Vision        2017.0\n",
            "\n",
            "Final sample DataFrame structure for embedding/indexing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5000 entries, 89006 to 1158379\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   id                  5000 non-null   int64  \n",
            " 1   text_for_embedding  5000 non-null   object \n",
            " 2   title               5000 non-null   object \n",
            " 3   overview            5000 non-null   object \n",
            " 4   genres              5000 non-null   object \n",
            " 5   keywords            5000 non-null   object \n",
            " 6   tagline             5000 non-null   object \n",
            " 7   release_year        4287 non-null   float64\n",
            "dtypes: float64(1), int64(1), object(6)\n",
            "memory usage: 351.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "SAMPLE_SIZE = 5000\n",
        "\n",
        "if len(df_relevant) > SAMPLE_SIZE:\n",
        "    print(f\"\\nTaking a random sample of {SAMPLE_SIZE} movies for development.\")\n",
        "    df_sample = df_relevant.sample(n=SAMPLE_SIZE, random_state=42)\n",
        "else:\n",
        "    print(f\"\\nCleaned dataset size ({len(df_relevant)}) is smaller than or equal to SAMPLE_SIZE. Using the full cleaned dataset.\")\n",
        "    df_sample = df_relevant\n",
        "\n",
        "print(f\"Working with {len(df_sample)} movies for the next steps.\")\n",
        "print(df_sample[['id', 'title', 'release_year']].head())\n",
        "\n",
        "columns_for_payload = ['title', 'overview', 'genres', 'keywords', 'tagline', 'release_year']\n",
        "columns_final = ['id', 'text_for_embedding'] + columns_for_payload\n",
        "df_sample = df_sample[columns_final]\n",
        "\n",
        "print(\"\\nFinal sample DataFrame structure for embedding/indexing:\")\n",
        "print(df_sample.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Initialize Qdrant for Vector Indexing\n"
      ],
      "metadata": {
        "id": "NNK2HU9CyQ-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "With the data prepared, the next step is to set up **Qdrant**, a vector similarity search engine optimized for storing and querying high-dimensional vectors. It supports fast indexing, filtering, and similarity search across millions of vectors.\n",
        "\n",
        "Qdrant can run:\n",
        "\n",
        "* Locally as a standalone service\n",
        "* In the cloud for production deployments\n",
        "* Or entirely **in-memory** for fast, temporary use during development\n",
        "\n",
        "In this notebook, Qdrant is initialized using in-memory mode by passing `\":memory:\"` to the client. This stores data only in RAM, meaning it **will not persist after the session ends**. This is suitable for experimentation but not for saving results long-term.\n",
        "\n",
        "You also configure the following:\n",
        "\n",
        "* `COLLECTION_NAME`: The name of the Qdrant collection to store movie vectors\n",
        "* `VECTOR_SIZE`: Set to `768` to match the dimensionality of the text embeddings generated by Gemini\n",
        "* `DISTANCE_METRIC`: Set to **cosine distance**, which is ideal for measuring semantic similarity between embedding vectors"
      ],
      "metadata": {
        "id": "s-cBsGtF3xVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OQqy7lxgajVI"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "import time\n",
        "\n",
        "COLLECTION_NAME = \"tmdb_movies_sample\"\n",
        "\n",
        "VECTOR_SIZE = 768\n",
        "DISTANCE_METRIC = models.Distance.COSINE\n",
        "\n",
        "\n",
        "# Initialize Qdrant client using in-memory storage\n",
        "client = QdrantClient(\":memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If3cSgEHgGlJ"
      },
      "source": [
        "### 7. Define Batch Embedding Function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step defines a function to generate embeddings for movie text data in batches using the Gemini embedding model, with automatic retries for robustness."
      ],
      "metadata": {
        "id": "VHkDkoBQ31Ie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qWODHe__bAeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57bf6ba-fa7a-4f8b-da7d-05c5939fde8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch embedding function 'get_embeddings_batch' defined using model: embedding-001\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from google.api_core import exceptions, retry\n",
        "\n",
        "MODEL_FOR_EMBEDDING = \"embedding-001\" # @param [\"embedding-001\", \"text-embedding-004\",\"gemini-embedding-exp-03-07\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "QDRANT_BATCH_SIZE = 768\n",
        "\n",
        "\n",
        "@retry.Retry(timeout=3000)\n",
        "def get_embeddings_batch(texts: list[str], task_type=\"RETRIEVAL_DOCUMENT\") -> list[list[float]] | None:\n",
        "    \"\"\"\n",
        "    Generates embeddings for a batch of texts using Gemini API with retry.\n",
        "\n",
        "    Args:\n",
        "        texts: A list of strings to embed.\n",
        "        task_type: The task type for the embedding model.\n",
        "\n",
        "    Returns:\n",
        "        A list of embedding vectors (list of floats), or None if a non-retryable error occurs.\n",
        "    \"\"\"\n",
        "    if not texts:\n",
        "        return []\n",
        "    try:\n",
        "        response = genai_client.models.embed_content(\n",
        "          model=MODEL_FOR_EMBEDDING,\n",
        "          contents=texts,\n",
        "          config={\n",
        "            \"task_type\":task_type,\n",
        "          }\n",
        "        )\n",
        "        return response.embeddings\n",
        "    except exceptions.RetryError as e:\n",
        "        print(f\"Embedding batch failed after retries: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "print(f\"Batch embedding function 'get_embeddings_batch' defined using model: {MODEL_FOR_EMBEDDING}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-LbEZvKghOW"
      },
      "source": [
        "### 8. Create a Collection in Qdrant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A collection in Qdrant is like a table in a database, it stores vectors along with optional metadata (payload). Each collection has its own configuration, including vector size and similarity metric."
      ],
      "metadata": {
        "id": "X9tIp23934sv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m0TDkDU7bPq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cb5e9b-24fd-4021-8a39-f0b7e0bcdba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing collection 'tmdb_movies_sample' deleted.\n",
            "Collection 'tmdb_movies_sample' created successfully.\n"
          ]
        }
      ],
      "source": [
        "# In case someone tries running the whole notebook again they would want to create the collection again\n",
        "\n",
        "try:\n",
        "    client.delete_collection(collection_name=COLLECTION_NAME)\n",
        "    print(f\"Existing collection '{COLLECTION_NAME}' deleted.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error deleting collection (it might not exist): {e}\")\n",
        "\n",
        "try:\n",
        "    client.create_collection(\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=VECTOR_SIZE,\n",
        "            distance=DISTANCE_METRIC\n",
        "        )\n",
        "    )\n",
        "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating collection: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Create Payloads for Metadata Storage\n"
      ],
      "metadata": {
        "id": "-Dp5nla31TJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Qdrant, besides storing vector embeddings, you can attach additional information called payload to each vector. This metadata helps in filtering or retrieving relevant results based on attributes like title, genres, or release year.\n",
        "\n",
        "The function below prepares the payload by extracting specified columns from each movie record, handling missing values and ensuring data types are compatible with Qdrant."
      ],
      "metadata": {
        "id": "lyIG8Ip24KGO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YhcyKADBbXze"
      },
      "outputs": [],
      "source": [
        "def create_payload(row, payload_columns):\n",
        "    payload = {}\n",
        "    for col in payload_columns:\n",
        "        value = row[col]\n",
        "        if pd.isna(value):\n",
        "            payload[col] = None\n",
        "        elif isinstance(value, (np.int64, np.int32)):\n",
        "            payload[col] = int(value)\n",
        "        elif isinstance(value, (np.float64, np.float32)):\n",
        "             payload[col] = float(value)\n",
        "        else:\n",
        "            payload[col] = value\n",
        "    return payload\n",
        "\n",
        "payload_columns = [\n",
        "    'title', 'overview', 'genres', 'keywords', 'tagline', 'release_year'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Batch Embedding and Indexing to Qdrant\n"
      ],
      "metadata": {
        "id": "XRmxfjDj1zmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This step processes the sampled movies dataset in batches to generate vector embeddings using the Gemini API and upload (upsert) these embeddings along with their metadata payloads to the Qdrant collection.\n",
        "\n",
        "**Key points of this process:**\n",
        "\n",
        "* The dataset is divided into batches of size `BATCH_SIZE` for embedding generation to stay within API limits.\n",
        "* Each batch's text data is sent to the Gemini embedding API with retries handled in the embedding function.\n",
        "* For every successfully embedded batch, the code prepares **points** (each containing an ID, vector embedding, and metadata payload) to be uploaded to Qdrant.\n",
        "* Points are buffered and uploaded in chunks of size `QDRANT_BATCH_SIZE` to optimize performance.\n",
        "* The process includes error handling and retry logic to avoid failures halting the entire operation.\n",
        "* At the end, any remaining points in the buffer are uploaded.\n",
        "* Summary statistics of processed, failed, and successfully upserted items are printed.\n",
        "\n"
      ],
      "metadata": {
        "id": "QImVW0tC38fi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Jp-omB2jbfpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321cf6dc-f88f-4928-b266-132b9cecfd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting batch embedding and indexing process for 5000 movies...\n",
            "Using Gemini Batch Size: 100, Qdrant Upsert Batch Size: 768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Batches: 100%|██████████| 50/50 [01:23<00:00,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch embedding and indexing finished.\n",
            "Total items processed (attempted embedding): 5000\n",
            "Total points successfully prepared for upsert: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"Starting batch embedding and indexing process for {len(df_sample)} movies...\")\n",
        "print(f\"Using Gemini Batch Size: {BATCH_SIZE}, Qdrant Upsert Batch Size: {QDRANT_BATCH_SIZE}\")\n",
        "\n",
        "points_to_upsert_buffer = []\n",
        "total_processed = 0\n",
        "total_failed_embedding = 0\n",
        "total_upserted = 0\n",
        "\n",
        "num_batches = (len(df_sample) + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "for i in tqdm(range(0, len(df_sample), BATCH_SIZE), total=num_batches, desc=\"Processing Batches\"):\n",
        "    batch_df = df_sample.iloc[i : i + BATCH_SIZE]\n",
        "    batch_texts = batch_df['text_for_embedding'].tolist()\n",
        "    batch_ids = batch_df['id'].tolist()\n",
        "\n",
        "    if not batch_texts:\n",
        "        continue\n",
        "\n",
        "    # Generate embeddings for the current batch of movie texts\n",
        "    batch_embeddings = get_embeddings_batch(batch_texts, task_type=\"RETRIEVAL_DOCUMENT\")\n",
        "\n",
        "    # Check if embeddings were successfully generated and correspond to batch size\n",
        "    if batch_embeddings and len(batch_embeddings) == len(batch_texts):\n",
        "        for j in range(len(batch_ids)):\n",
        "            item_id = batch_ids[j]\n",
        "            item_embedding = batch_embeddings[j]\n",
        "            row_data = batch_df.iloc[j]\n",
        "\n",
        "            # Prepare metadata payload for this movie\n",
        "            payload = create_payload(row_data, payload_columns)\n",
        "\n",
        "            # Create a Qdrant PointStruct with id, embedding vector, and payload\n",
        "            point = models.PointStruct(\n",
        "                id=int(item_id),\n",
        "                vector=item_embedding.values,\n",
        "                payload=payload\n",
        "            )\n",
        "            points_to_upsert_buffer.append(point)\n",
        "\n",
        "        total_processed += len(batch_ids)\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to get embeddings for batch starting at index {i}. Skipping {len(batch_ids)} items.\")\n",
        "        total_failed_embedding += len(batch_ids)\n",
        "        continue\n",
        "\n",
        "    # Upload buffered points to Qdrant if buffer reached batch size or end of data\n",
        "    if len(points_to_upsert_buffer) >= QDRANT_BATCH_SIZE or (i + BATCH_SIZE >= len(df_sample)):\n",
        "        if points_to_upsert_buffer:\n",
        "            try:\n",
        "                client.upsert(\n",
        "                    collection_name=COLLECTION_NAME,\n",
        "                    points=points_to_upsert_buffer,\n",
        "                    wait=False\n",
        "                )\n",
        "                total_upserted += len(points_to_upsert_buffer)\n",
        "                points_to_upsert_buffer = []\n",
        "            except Exception as e:\n",
        "                print(f\"Error upserting chunk to Qdrant: {e}\")\n",
        "                points_to_upsert_buffer = []\n",
        "                time.sleep(5)\n",
        "                # Pause before retrying to avoid hammering the service after an error\n",
        "\n",
        "# Upload any remaining points left in buffer after loop completion\n",
        "if points_to_upsert_buffer:\n",
        "    print(f\"Upserting final remaining chunk of {len(points_to_upsert_buffer)} points.\")\n",
        "    try:\n",
        "        client.upsert(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            points=points_to_upsert_buffer,\n",
        "            wait=True\n",
        "        )\n",
        "        total_upserted += len(points_to_upsert_buffer)\n",
        "        points_to_upsert_buffer = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error upserting final chunk: {e}\")\n",
        "\n",
        "print(\"Batch embedding and indexing finished.\")\n",
        "print(f\"Total items processed (attempted embedding): {total_processed}\")\n",
        "print(f\"Total points successfully prepared for upsert: {total_upserted}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v6l-OtOFsmeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248b7c12-110c-4c4a-844c-5de4b2ee7e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verification: Collection 'tmdb_movies_sample' now contains 5000 points.\n"
          ]
        }
      ],
      "source": [
        "# Waiting for collection to settle\n",
        "time.sleep(5)\n",
        "\n",
        "try:\n",
        "    count = client.count(collection_name=COLLECTION_NAME, exact=True)\n",
        "    print(f\"\\nVerification: Collection '{COLLECTION_NAME}' now contains {count.count} points.\") # it should print 5000\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error verifying collection count: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Search and Recommend Similar Movies Using Vector Embeddings\n"
      ],
      "metadata": {
        "id": "jtFYhuo52rGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With all movie vectors indexed in Qdrant, you can now perform semantic search. This allows you to take any user query (such as a phrase, movie description, or concept), convert it into an embedding using the same Gemini model, and retrieve the most similar movie vectors from the collection using cosine similarity.\n",
        "\n",
        "This function demonstrates how to:\n",
        "\n",
        "* Generate an embedding from your input query using the Gemini API.\n",
        "* Perform a similarity search using Qdrant’s `search()` method.\n",
        "* Retrieve the top `k` most similar movie entries, including their metadata and similarity scores.\n",
        "\n",
        "This is the final step where the vector database functions as a recommendation engine.\n"
      ],
      "metadata": {
        "id": "bjNKMgn54GSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i3gAZ30qtGZo"
      },
      "outputs": [],
      "source": [
        "def recommend_movies(query_text, top_k=5):\n",
        "    \"\"\"\n",
        "    Finds movies similar to the query_text using the Qdrant index.\n",
        "\n",
        "    Args:\n",
        "        query_text (str): The user's query (e.g., movie title, description, theme).\n",
        "        top_k (int): The maximum number of recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              payload (movie details) and similarity score of a recommended movie.\n",
        "              Returns an empty list if query embedding fails or no results found.\n",
        "    \"\"\"\n",
        "    print(f\"Searching for recommendations based on: '{query_text}'\")\n",
        "    # Generate embedding for the user query using Gemini\n",
        "    query_embedding = get_embeddings_batch(query_text, task_type=\"RETRIEVAL_QUERY\")[0].values\n",
        "\n",
        "    if query_embedding is None:\n",
        "        print(\"Error: Could not generate embedding for the query.\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        # Perform a semantic search on Qdrant using the query vector\n",
        "        search_result = client.search(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            query_vector=query_embedding,\n",
        "            limit=top_k,\n",
        "            with_payload=True\n",
        "        )\n",
        "\n",
        "        recommendations = []\n",
        "        if search_result:\n",
        "            print(f\"Found {len(search_result)} potential recommendations:\")\n",
        "            for hit in search_result:\n",
        "                recommendation = {\n",
        "                    \"id\": hit.id,\n",
        "                    \"score\": hit.score,\n",
        "                    \"payload\": hit.payload\n",
        "                }\n",
        "                recommendations.append(recommendation)\n",
        "        else:\n",
        "            print(\"No recommendations found matching the query.\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Qdrant search: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Out Your Movie Recommender\n",
        "You can now try querying your movie recommender by describing a theme, genre, or concept in natural language. The system will return the most semantically similar movies from your dataset based on vector similarity search using Gemini-generated embeddings.\n",
        "\n",
        "In this example, a query like \"spy and action based movies\" is used to retrieve 5 similar movie entries."
      ],
      "metadata": {
        "id": "kN6jiYMB3OWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T3aRrQZltXM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610602f5-e7f0-431e-99f9-5be15d8f5d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for recommendations based on: 'spy and action based movies'\n",
            "Found 5 potential recommendations:\n",
            "\n",
            "--- Recommendations ---\n",
            "  - Score: 0.6662\n",
            "    Title: The Tiger Gang\n",
            "    Genre: Drama, Action, Thriller\n",
            "    Year: 1971.0\n",
            "----------\n",
            "  - Score: 0.6588\n",
            "    Title: From Istanbul with Orders to Kill\n",
            "    Genre: \n",
            "    Year: 1968.0\n",
            "----------\n",
            "  - Score: 0.6508\n",
            "    Title: Jatt James Bond\n",
            "    Genre: Comedy, Drama, Thriller\n",
            "    Year: 2014.0\n",
            "----------\n",
            "  - Score: 0.6488\n",
            "    Title: The Blue Panther\n",
            "    Genre: Action, Crime, Thriller\n",
            "    Year: 1965.0\n",
            "----------\n",
            "  - Score: 0.6454\n",
            "    Title: Spies, Lies & Naked Thighs\n",
            "    Genre: Comedy, TV Movie\n",
            "    Year: 1988.0\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-008662d28af0>:24: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  search_result = client.search(\n"
          ]
        }
      ],
      "source": [
        "query = \"spy and action based movies\"\n",
        "recommendations = recommend_movies(query, top_k=5)\n",
        "\n",
        "if recommendations:\n",
        "    print(\"\\n--- Recommendations ---\")\n",
        "    for rec in recommendations:\n",
        "        print(f\"  - Score: {rec['score']:.4f}\")\n",
        "        print(f\"    Title: {rec['payload'].get('title', 'N/A')}\")\n",
        "        print(f\"    Genre: {rec['payload'].get('genres', 'N/A')}\")\n",
        "        print(f\"    Year: {rec['payload'].get('release_year', 'N/A')}\")\n",
        "        print(\"-\" * 10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Movie_Recommendation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}