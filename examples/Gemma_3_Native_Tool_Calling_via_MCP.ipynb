{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "intro"
            },
            "source": [
                "# Gemma 3: Native Tool-Calling via Model Context Protocol (MCP)\n",
                "\n",
                "Gemma 3 is a highly capable open-weights model from Google DeepMind. One of its standout features is native support for function calling via standardized control tokens. \n",
                "\n",
                "This tutorial demonstrates how to integrate Gemma 3 with the **Model Context Protocol (MCP)**. MCP is an open standard that allows models to reach out to local or remote system environments to perform actions, search for data, or interact with files in a secure and standardized way.\n",
                "\n",
                "In this notebook, you will learn:\n",
                "1. How to define local tools using the MCP standard.\n",
                "2. How to map MCP tool definitions to Gemma 3's native function calling format.\n",
                "3. How to implement an autonomous execution loop for agentic workflows."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup-markdown"
            },
            "source": [
                "## Setup\n",
                "\n",
                "First, we install the necessary libraries. We use the `mcp` SDK for the protocol logic and `google-genai` for model interaction (if using hosted Gemma via Vertex AI) or standard Python libraries for local simulation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "installs"
            },
            "outputs": [],
            "source": [
                "%pip install -U mcp httpx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "import json\n",
                "import re\n",
                "import asyncio\n",
                "import os\n",
                "from typing import Dict, List, Any, Optional\n",
                "from mcp import server\n",
                "from mcp.types import Tool, TextContent, CallToolRequest\n",
                "import httpx"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "mcp-logic-markdown"
            },
            "source": [
                "## 1. Defining MCP Tool Logic\n",
                "\n",
                "The Model Context Protocol allows us to expose local functions to an LLM. Here, we define a simple `FileCreator` tool that allows Gemma to create files in the local environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mcp-server-impl"
            },
            "outputs": [],
            "source": [
                "# @title MCP Tool Definitions and Implementation\n",
                "\n",
                "class LocalMCPGateway:\n",
                "    \"\"\"\n",
                "    A simplified MCP Gateway that manages tool registration and execution.\n",
                "    \"\"\"\n",
                "    def __init__(self):\n",
                "        self.registry = {}\n",
                "\n",
                "    def register_tool(self, name: str, description: str, schema: Dict[str, Any], func: Any):\n",
                "        self.registry[name] = {\n",
                "            \"description\": description,\n",
                "            \"schema\": schema,\n",
                "            \"func\": func\n",
                "        }\n",
                "\n",
                "    def get_tool_definitions(self) -> str:\n",
                "        \"\"\"\n",
                "        Formats tools for Gemma 3's <start_function_declaration> block.\n",
                "        \"\"\"\n",
                "        definitions = []\n",
                "        for name, info in self.registry.items():\n",
                "            def_str = f\"declaration:{name}{json.dumps(info['schema'])}\"\n",
                "            definitions.append(def_str)\n",
                "        return \"\\n\".join(definitions)\n",
                "\n",
                "    async def call_tool(self, name: str, arguments: Dict[str, Any]) -> str:\n",
                "        \"\"\"\n",
                "        Executes a tool and returns the result encapsulated for Gemma.\n",
                "        \"\"\"\n",
                "        if name not in self.registry:\n",
                "            return f\"Error: Tool {name} not found.\"\n",
                "        \n",
                "        try:\n",
                "            result = await self.registry[name][\"func\"](**arguments)\n",
                "            return str(result)\n",
                "        except Exception as e:\n",
                "            return f\"Execution Error: {str(e)}\"\n",
                "\n",
                "# Define a local tool implementation\n",
                "async def create_local_file(filename: str, content: str) -> str:\n",
                "    \"\"\"\n",
                "    Creates a file on the local filesystem.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        with open(filename, 'w') as f:\n",
                "            f.write(content)\n",
                "        return f\"Successfully created {filename}.\"\n",
                "    except Exception as e:\n",
                "        return f\"Failed to create file: {str(e)}\"\n",
                "\n",
                "# Initialize and Register\n",
                "gateway = LocalMCPGateway()\n",
                "gateway.register_tool(\n",
                "    name=\"create_file\",\n",
                "    description=\"Creates a new file with the specified content.\",\n",
                "    schema={\n",
                "        \"type\": \"object\",\n",
                "        \"properties\": {\n",
                "            \"filename\": {\"type\": \"string\", \"description\": \"The name of the file to create.\"},\n",
                "            \"content\": {\"type\": \"string\", \"description\": \"The content to write to the file.\"}\n",
                "        },\n",
                "        \"required\": [\"filename\", \"content\"]\n",
                "    },\n",
                "    func=create_local_file\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "gemma-integration-markdown"
            },
            "source": [
                "## 2. Gemma 3 Integration Logic\n",
                "\n",
                "Gemma 3 uses specialized tokens to handle tool-calling. We need to wrap the model interaction to parse these tokens and feed results back into the context."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "gemma-native-logic"
            },
            "outputs": [],
            "source": [
                "# @title Native Token Handling Utilities\n",
                "\n",
                "GEMMA_SYSTEM_PROMPT = \"\"\"You are a model that can do function calling with the following functions:\n",
                "<start_function_declaration>\n",
                "{tool_definitions}\n",
                "<end_function_declaration>\n",
                "\n",
                "When you need to use a tool, use the following format:\n",
                "<thought>\n",
                "[Your reasoning here]\n",
                "</thought>\n",
                "<start_function_call>call:{tool_name}{{\"arg1\": \"value1\"}}<end_function_call>\n",
                "\n",
                "You will then receive a response in this format:\n",
                "<start_function_response>... result ...<end_function_response>\n",
                "\"\"\"\n",
                "\n",
                "def parse_tool_call(text: str):\n",
                "    \"\"\"\n",
                "    Regex parser for Gemma 3's official <start_function_call> token.\n",
                "    \"\"\"\n",
                "    match = re.search(r\"<start_function_call>call:(\\w+)(\\{.*?\\})<end_function_call>\", text, re.DOTALL)\n",
                "    if match:\n",
                "        return match.group(1), json.loads(match.group(2))\n",
                "    return None, None\n",
                "\n",
                "def format_response_token(result: str) -> str:\n",
                "    \"\"\"\n",
                "    Wraps a tool result in official Gemma 3 response tokens.\n",
                "    \"\"\"\n",
                "    return f\"<start_function_response>{result}<end_function_response>\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "execution-markdown"
            },
            "source": [
                "## 3. The Execution Loop\n",
                "\n",
                "In a real-world scenario, you would call a Gemma 3 API (like Vertex AI or a local Ollama instance). Here, we simulate the model's responses to demonstrate the multi-turn protocol flow."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "agent-loop"
            },
            "outputs": [],
            "source": [
                "async def run_gemma_mcp_session(user_query: str):\n",
                "    \"\"\"\n",
                "    Demonstrates the full lifecycle of an MCP-enabled Gemma 3 session.\n",
                "    \"\"\"\n",
                "    print(f\"USER: {user_query}\\n\")\n",
                "    \n",
                "    # 1. Initialize System Instruction\n",
                "    tool_defs = gateway.get_tool_definitions()\n",
                "    system_instr = GEMMA_SYSTEM_PROMPT.format(tool_definitions=tool_defs)\n",
                "    \n",
                "    # 2. Simulate Model Output (In reality, this would be an API call)\n",
                "    # We assume Gemma sees the query and decides to call the tool.\n",
                "    simulated_model_output = \"\"\"<thought>\n",
                "I need to create a file as requested by the user. I should use the 'create_file' tool.\n",
                "</thought>\n",
                "<start_function_call>call:create_file{\"filename\": \"hello.txt\", \"content\": \"Hello from the Gemma 3 MCP Gateway!\"}<end_function_call>\"\"\"\n",
                "    \n",
                "    print(f\"MODEL THOUGHTS & CALL:\\n{simulated_model_output}\\n\")\n",
                "    \n",
                "    # 3. Parse and Execute Tool via MCP\n",
                "    tool_name, tool_args = parse_tool_call(simulated_model_output)\n",
                "    \n",
                "    if tool_name:\n",
                "        print(f\"--- EXECUTING MCP TOOL: {tool_name} ---\")\n",
                "        result = await gateway.call_tool(tool_name, tool_args)\n",
                "        print(f\"RESULT: {result}\\n\")\n",
                "        \n",
                "        # 4. Feed Result Back to Model\n",
                "        response_token = format_response_token(result)\n",
                "        \n",
                "        # Simulate Final Model Response\n",
                "        final_output = \"I have successfully created 'hello.txt' with the greeting you requested.\"\n",
                "        print(f\"MODEL FINAL ANSWER: {final_output}\")\n",
                "    else:\n",
                "        print(\"No tool call detected.\")\n",
                "\n",
                "# Run the demonstration\n",
                "await run_gemma_mcp_session(\"Create a file named 'hello.txt' with a greeting.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "conclusion"
            },
            "source": [
                "## Conclusion\n",
                "\n",
                "By using **Native Control Tokens** and the **Model Context Protocol**, Gemma 3 becomes a powerful agent capable of interacting with its environment in a decoupled, standardized way. This architecture allows developers to build specialized toolsets that can be shared across any MCP-compliant application."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mips_identifier": "python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}