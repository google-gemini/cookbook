{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Quick RAG Implementation using BeyondLLM\n",
        "\n",
        "BeyondLLM helps you build, experiment and evaluate RAG pipeline in just 5-7 lines of code."
      ],
      "metadata": {
        "id": "h_zDR_aMuOdg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lJprtUouLOS"
      },
      "outputs": [],
      "source": [
        "!pip install beyondllm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from beyondllm.source import fit\n",
        "from beyondllm.embeddings import GeminiEmbeddings\n",
        "from beyondllm.llms import GeminiModel\n",
        "from beyondllm.retrieve import auto_retriever\n",
        "from beyondllm.generator import Generate"
      ],
      "metadata": {
        "id": "uTt5JErGuk0m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google API Key\n",
        "\n",
        "RAG pipeline consists of two components:\n",
        "- Retriever: Returns relevant document based on your query\n",
        "- Generator: Generates AI response from the returned context and user query\n",
        "\n",
        "In this example, we will built Chat with Document RAG application,using Gemini Embeddings and Gemini LLMs.\n",
        "\n",
        "> Note: BeyondLLM supports Gemini as default embeddings and LLMs"
      ],
      "metadata": {
        "id": "aNoHGS0rvIMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get your API Key: [ai.google.dev](https://ai.google.dev/)"
      ],
      "metadata": {
        "id": "NI0N8HM-w-50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = getpass(\"Enter your Google API Key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTCeG5bQw6ME",
        "outputId": "a59dd894-81dc-4282-b079-6987893e4940"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build-Experiment-Evaluate RAG in 5 lines of code\n",
        "\n",
        "### Approach-1 Using Default LLMs and Embeddings (Gemini)\n"
      ],
      "metadata": {
        "id": "pSRfQdr1wX4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = fit(\"my_resume.pdf\",dtype=\"pdf\",chunk_size=756,chunk_overlap=100)"
      ],
      "metadata": {
        "id": "L0CLgwGZvHoW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = auto_retriever(data,type=\"normal\",top_k=2) # embed_model = GeminiEmbeddings() - default\n",
        "prompt = \"summarize Tarun's role at AI Planet\"\n",
        "pipeline = Generate(question=prompt,retriever=retriever) # llm = GeminiModel() - default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "76PvKqiDw0EO",
        "outputId": "18cbfa31-e94e-479b-bf73-bfed4a1ccf32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline.call()) # generates AI response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReZx9aG3x_Tq",
        "outputId": "aa7d4f8b-388d-4c65-85f4-5a258ef943c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tarun is a Developer Relations and Community Manager at AI Planet. He is part of the Data Science team and handles the community. He has worked on Fine Tuning LLMs, building Consultant POC to migrate the enterprise and business into AI, and deploying 6+ state-of-the-art models on AI Planet’s AI Marketplace. He has organized 20+ live sessions with experts from Google, Weights & Biases, Intel, and more. He is also the lead curriculum contributor to the LLM Bootcamp, where he reached out to 11 speakers and led a group of 8 AI Ambassadors for the AI Changemaker program. He also built Panda Coder 13B, a state-of-the-art LLM, a fine-tuned model, specifically designed to generate code based on natural language instructions. He is the core maintainer at GenAI Stack, an end-to-end LLM framework built above Langchain and LLamaIndex.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline.get_rag_triad_evals()) # Evaluate LLM response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "0dibSjCjyVN0",
        "outputId": "fd2fb574-82b7-4811-db6b-b59dd0eac65a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing RAG Triad Evaluations...\n",
            "Context relevancy Score: 5.0\n",
            "This response does not meet the evaluation threshold. Consider refining the structure and content for better clarity and effectiveness.\n",
            "Answer relevancy Score: 10.0\n",
            "This response meets the evaluation threshold. It demonstrates strong comprehension and coherence.\n",
            "Groundness score: 10.0\n",
            "This response meets the evaluation threshold. It demonstrates strong comprehension and coherence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reference- Documentation: [BeyondLLM](https://beyondllm.aiplanet.com/)"
      ],
      "metadata": {
        "id": "PGVkgYLryaiM"
      }
    }
  ]
}