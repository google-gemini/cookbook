{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkenge/cookbook/blob/apollo/examples/Apollo_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Prompting with an Apollo 11 transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQ_LVlzIeXo"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7QvXQMrIhuZ"
      },
      "source": [
        "This notebook provides a quick example of how to prompt Gemini using a text file. In this case, you'll use a 400 page transcript from [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qLuL9m7KhvxR"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-genai>=1.7.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "Download the transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V4XeFdX1rxaE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-05 08:12:28--  https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.207, 74.125.197.207, 74.125.135.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 847790 (828K) [text/plain]\n",
            "Saving to: ‘a11.txt’\n",
            "\n",
            "\ra11.txt               0%[                    ]       0  --.-KB/s               \ra11.txt             100%[===================>] 827.92K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-04-05 08:12:29 (120 MB/s) - ‘a11.txt’ saved [847790/847790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoiKgO2CswzA"
      },
      "source": [
        "Upload the file using the File API so its easier to pass it to the model later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_HzrDdp2Q1Cu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/8m6sosor9tvy\n"
          ]
        }
      ],
      "source": [
        "text_file_name = \"a11.txt\"\n",
        "print(f\"Uploading file...\")\n",
        "text_file = client.files.upload(file=text_file_name)\n",
        "print(f\"Completed upload: {text_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "## Generate Content\n",
        "\n",
        "After the file has been uploaded, you can make `client.models.generate_content` requests that reference the File API URI. Then you will ask the model to find a few lighthearted moments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9b1d2fe3ea31"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Here are four lighthearted moments from the Apollo 11 transcript:\n\n1.  **00 00 05 35 CDR: \"You sure sound clear down there, Bruce. Sounds like you're sitting in your living room.\"** This comment is light and friendly, acknowledging the quality of communication.\n2.  **00 00 05 39 CC: \"Oh, thank you. You all are coming through beautifully, too.\"** This is a polite and humorous response to the previous comment.\n3.  **00 00 54 13 CMP: \"And tell Glenn Parker down at the Cape that he lucked out.\"**  This is a humorous, informal message sent to someone on the ground, suggesting they were fortunate in some way.\n4. **00 02 28 45 CMP: \"I wanted to be 18 or 20 pounds above nominal, babe.\" 00 02 28 49 CC: \"Sorry about that.\"**  This exchange suggests a light tone of self-deprecating humor to a mistake made.\n",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "prompt = \"Find four lighthearted moments in this text file.\"\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model=f\"models/{MODEL_ID}\",\n",
        "  contents=[\n",
        "   prompt,\n",
        "   text_file\n",
        "  ],\n",
        "  config={\n",
        "   \"httpOptions\": {\"timeout\": 10 * 60 * 1000}\n",
        "  }\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPDYdQSKTg4"
      },
      "source": [
        "## Delete File\n",
        "\n",
        "Files are automatically deleted after 2 days or you can manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d4eO8ZXoKdZf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeleteFileResponse()"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.files.delete(name=text_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oUCqb6IUnH"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "The File API accepts files under 2GB in size and can store up to 20GB of files per project. Learn more about the [File API](../quickstarts/File_API.ipynb) here."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "Apollo_11.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
