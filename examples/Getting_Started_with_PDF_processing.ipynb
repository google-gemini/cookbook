{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "# Gemini API: Read a PDF\n",
        "\n",
        "This notebook demonstrates how you can convert a PDF file so that it can be read by the Gemini API.\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Getting_Started_with_PDF_processing.ipynb\"><img src=\"../images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Set up Environment and create inference Client\n",
        "\n",
        "The first task is to install the `google-genai` [Python SDK](https://googleapis.github.io/python-genai/) and obtain an API key. If you don”t have a can get one from Google AI Studio: [Get a Gemini API key](https://aistudio.google.com/app/apikey).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install \"google-genai>=1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have the SDK and API key, we can create a client and define your model we are going to use the new Gemini 2.0 Flash model, which is available via [free tier](https://ai.google.dev/pricing#2_0flash_lite) with 1,500 request per day. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "# Comment in if you are using Colab and repace\n",
        "# from google.colab import userdata\n",
        "# api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "api_key = \"YOUR_API_KEY\"\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "model_id =  \"gemini-2.0-flash\" # or \"gemini-2.0-flash-lite-preview-02-05\"  , \"gemini-2.0-pro-exp-02-05\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Note: If you want to use Vertex AI see [here](https://googleapis.github.io/python-genai/#create-a-client) how to create your client*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Work with PDFs and other files\n",
        "\n",
        "Gemini models are able to process [images and videos](https://ai.google.dev/gemini-api/docs/vision?lang=python#image-input), which can used with base64 strings or using the `files`api. After uploading the file we can include the file uri in the call directly. The Python API includes a [upload](https://googleapis.github.io/python-genai/#upload) and [delete](https://googleapis.github.io/python-genai/#delete) method. \n",
        "\n",
        "I prepared 3 PDFs one sample invoice, one invoice with scribles on it and on handwriting form. \n",
        "\n",
        "We can download the files to our environment using `wget`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/datasets/philschmid/pdf-samples/resolve/main/invoice.pdf\n",
        "!wget https://huggingface.co/datasets/philschmid/pdf-samples/resolve/main/invoice_with_scribbles.pdf\n",
        "!wget https://huggingface.co/datasets/philschmid/pdf-samples/resolve/main/handwriting.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now upload the files using our client with the `upload` method. Let's try this for one of the files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "invoice_pdf = client.files.upload(file=\"invoice.pdf\", config={'display_name': 'invoice'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Note: The File API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. They can be accessed in that period with your API key, but they cannot be downloaded. File uploads are available at no cost._\n",
        "\n",
        "After our files are uploaded we can check to how many tokens they were converted. This not only help us understand the context we are working with it also helps to keep track of the cost. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: invoice equals to 821 tokens\n"
          ]
        }
      ],
      "source": [
        "file_size = client.models.count_tokens(model=model_id,contents=invoice_pdf)\n",
        "print(f'File: {invoice_pdf.display_name} equals to {file_size.total_tokens} tokens')\n",
        "# File: invoice equals to 821 tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Structured outputs with Gemini 2.0 and Pydantic\n",
        "\n",
        "Structured Outputs is a feature that ensures Gemini always generate responses that adhere to a predefined format, such as JSON Schema. This means we have more control over the output and how to integrate it into our application as it is guaranteed to return a valid JSON object with the schema we define. \n",
        "\n",
        "Gemini 2.0 currenlty supports 3 dfferent types of how to define a JSON schemas:\n",
        "- A single python type, as you would use in a [typing annotation](https://docs.python.org/3/library/typing.html).\n",
        "- A Pydantic [BaseModel](https://docs.pydantic.dev/latest/concepts/models/)\n",
        "- A dict equivalent of [genai.types.Schema](https://googleapis.github.io/python-genai/genai.html#genai.types.Schema) / [Pydantic BaseModel](https://docs.pydantic.dev/latest/concepts/models/)\n",
        "\n",
        "Lets look at quick text-based example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"age\": 0,\n",
            "  \"first_name\": \"Philipp\",\n",
            "  \"last_name\": \"Schmid\",\n",
            "  \"work_topics\": [\n",
            "    {\n",
            "      \"name\": \"AI\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Gemini\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Gemma\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Responsible AI\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Developer Relations\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "First name is Philipp\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define a Pydantic model\n",
        "# We use the Field class to add a description and default value to provide more context to the model\n",
        "class Topic(BaseModel):\n",
        "    name: str = Field(description=\"The name of the topic\")\n",
        "\n",
        "class Person(BaseModel):\n",
        "    first_name: str = Field(description=\"The first name of the person\")\n",
        "    last_name: str = Field(description=\"The last name of the person\")\n",
        "    age: int = Field(description=\"The age of the person, if not provided please return 0\")\n",
        "    work_topics: list[Topic] = Field(description=\"The fields of interest of the person, if not provided please return an empty list\")\n",
        "\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Philipp Schmid is a Senior AI Developer Relations Engineer at Google DeepMind working on Gemini, Gemma with the mission to help every developer to build and benefit from AI in a responsible way.  \"\n",
        "\n",
        "# Generate a response using the Person model\n",
        "response = client.models.generate_content(model=model_id, contents=prompt, config={'response_mime_type': 'application/json',\n",
        "        'response_schema': Person})\n",
        "\n",
        "# print the response as a json string\n",
        "print(response.text)\n",
        "\n",
        "# sdk automatically converts the response to the pydantic model\n",
        "philipp: Person = response.parsed\n",
        "\n",
        "# access an attribute of the json response\n",
        "print(f\"First name is {philipp.first_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract Structured data from PDFs using Gemini 2.0\n",
        "\n",
        "Now, let's combine the File API and structured output to extract information from our PDFs. We can create a simple method that accepts a local file path and a pydantic model and return the structured data for us. The method will:\n",
        "\n",
        "1. Upload the file to the File API\n",
        "2. Generate a structured response using the Gemini API\n",
        "3. Convert the response to the pydantic model and return it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_structured_data(file_path: str, model: BaseModel):\n",
        "    # Upload the file to the File API\n",
        "    file = client.files.upload(file=file_path, config={'display_name': file_path.split('/')[-1].split('.')[0]})\n",
        "    # Generate a structured response using the Gemini API\n",
        "    prompt = f\"Extract the structured data from the following PDF file\"\n",
        "    response = client.models.generate_content(model=model_id, contents=[prompt, file], config={'response_mime_type': 'application/json', 'response_schema': model})\n",
        "    # Convert the response to the pydantic model and return it\n",
        "    return response.parsed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our Example every PDF is a different to each other. So we want to define unique Pydantic models for each PDF to show the performance of the Gemini 2.0. If you have very similar PDFs and want to extract the same information you can use the same model for all of them. \n",
        "\n",
        "We are going to:\n",
        "- `Invoice.pdf` : Extract the invoice number, date and all list items with description, quantity and gross worth and the total gross worth\n",
        "- `Invoice_with_scribles.pdf` : Extract the total balance\n",
        "- `handwriting.pdf` : Extract the form number, fiscal start date, fiscal end date, and the plan liabilities beginning of the year and end of the year\n",
        "\n",
        "You can inspect the PDFs using a local PDF viewer or in the [browser](https://huggingface.co/datasets/philschmid/pdf-samples/tree/main).\n",
        "\n",
        "_Note: Using Pydantic features we can add more context to the model to make it more accurate as well as some validation to the data. Adding a comprehensive description can significantly improve the performance of the model. Libraries like [instructor](https://python.useinstructor.com/) added automatic retries based on validation errors, which can be a great help, but come at the cost of additional requests._\n",
        "\n",
        "\n",
        "### Invoice.pdf\n",
        "\n",
        "![Invoice.pdf](https://huggingface.co/datasets/philschmid/pdf-samples/resolve/main/invoice.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.Invoice'>\n",
            "Extracted Invoice: 27301261 on 10/09/2012 with total gross worth 544.46\n",
            "Item: Lilly Pulitzer dress Size 2 with quantity 5.0 and gross worth 247.5\n",
            "Item: New ERIN Erin Fertherston Straight Dress White Sequence Lining Sleeveless SZ 10 with quantity 1.0 and gross worth 65.99\n",
            "Item: Sequence dress Size Small with quantity 3.0 and gross worth 115.5\n",
            "Item: fire los angeles dress Medium with quantity 3.0 and gross worth 21.45\n",
            "Item: Eileen Fisher Women's Long Sleeve Fleece Lined Front Pockets Dress XS Gray with quantity 3.0 and gross worth 52.77\n",
            "Item: Lularoe Nicole Dress Size Small Light Solid Grey/ White Ringer Tee Trim with quantity 2.0 and gross worth 8.25\n",
            "Item: J.Crew Collection Black & White sweater Dress sz S with quantity 1.0 and gross worth 33.0\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Item(BaseModel):\n",
        "    description: str = Field(description=\"The description of the item\")\n",
        "    quantity: float = Field(description=\"The Qty of the item\")\n",
        "    gross_worth: float = Field(description=\"The gross worth of the item\")\n",
        "\n",
        "class Invoice(BaseModel):\n",
        "    \"\"\"Extract the invoice number, date and all list items with description, quantity and gross worth and the total gross worth.\"\"\"\n",
        "    invoice_number: str = Field(description=\"The invoice number e.g. 1234567890\")\n",
        "    date: str = Field(description=\"The date of the invoice e.g. 2024-01-01\")\n",
        "    items: list[Item] = Field(description=\"The list of items with description, quantity and gross worth\")\n",
        "    total_gross_worth: float = Field(description=\"The total gross worth of the invoice\")\n",
        "\n",
        "\n",
        "result = extract_structured_data(\"invoice.pdf\", Invoice)\n",
        "print(type(result))\n",
        "print(f\"Extracted Invoice: {result.invoice_number} on {result.date} with total gross worth {result.total_gross_worth}\")\n",
        "for item in result.items:\n",
        "    print(f\"Item: {item.description} with quantity {item.quantity} and gross worth {item.gross_worth}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fantastic! If we compare this to the original invoice we can see that the information is extracted correctly. \n",
        "\n",
        "\n",
        "### Invoice_with_scribbles.pdf\n",
        "\n",
        "![Invoice_with_scribbles.pdf](https://huggingface.co/datasets/philschmid/pdf-samples/resolve/main/invoice_with_scribbles.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.InvoiceWithScribles'>\n",
            "Extracted Invoice: 1350.0\n"
          ]
        }
      ],
      "source": [
        "class InvoiceWithScribles(BaseModel):\n",
        "    total_balance: float = Field(description=\"The total balance of the invoice\")\n",
        "\n",
        "result = extract_structured_data(\"invoice_with_scribbles.pdf\", InvoiceWithScribles)\n",
        "print(type(result))\n",
        "print(f\"Extracted Invoice: {result.total_balance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome, Gemini didn't get distracted by the scribles and extracted the total balance correctly. \n",
        "\n",
        "\n",
        "### handwriting.pdf\n",
        "\n",
        "![handwriting.pdf](https://huggingface.co/datasets/philschmid/pdf-samples/resolve/main/handwriting.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Form Number: CA530082 with fiscal start date 01/02/2022 and fiscal end date 01/02/2023. \n",
            "Plan liabilities beginning of the year 4000.0 and end of the year 5000.0\n"
          ]
        }
      ],
      "source": [
        "class handwriting(BaseModel):\n",
        "    \"\"\"Extract the form number, fiscal start date, fiscal end date, and the plan liabilities beginning of the year and end of the year.\"\"\"\n",
        "    form_number: str = Field(description=\"The Form Number\")\n",
        "    fiscal_start_date: str = Field(description=\"The fiscal start date of the handwriting\")\n",
        "    fiscal_end_date: str = Field(description=\"The fiscal end date of the handwriting\")\n",
        "    plan_liabilities_beginning_of_year: float = Field(description=\"The plan liabilities beginning of the year\")\n",
        "    plan_liabilities_end_of_year: float = Field(description=\"The plan liabilities end of the year\")\n",
        "\n",
        "result = extract_structured_data(\"handwriting.pdf\", handwriting)\n",
        "\n",
        "print(f'Extracted Form Number: {result.form_number} with fiscal start date {result.fiscal_start_date} and fiscal end date {result.fiscal_end_date}. \\nPlan liabilities beginning of the year {result.plan_liabilities_beginning_of_year} and end of the year {result.plan_liabilities_end_of_year}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "PDF_Files.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
