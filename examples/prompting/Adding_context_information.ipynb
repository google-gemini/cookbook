{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axbjnTrz9cxf"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h6NnvxwW9fT9"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP8PQnz1QrcF"
      },
      "source": [
        "# Gemini API: Adding context information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxGr_x3MRA0z"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/prompting/Adding_context_information.ipynb\"><img src = \"../../images/colab_logo_32px.png\"/>Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysy--KfNRrCq"
      },
      "source": [
        "While LLMs are trained extensively on various documents and data, the LLM does not know everything. New information or information that is not easily accessible cannot be known by the LLM, unless it was specifically added to its corpus of knowledge somehow. For this reason, it is sometimes necessary to provide the LLM, with information and context necessary to answer our queries by providing additional context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ne-3gnXqR0hI"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EconMHePQHGw"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eomJzCa6lb90"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v-JZzORUpVR2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JljcHgI2ltTY"
      },
      "source": [
        "## Example\n",
        "\n",
        "Let's say you provide some statistics from a recent Olympics competition, and this data wasn't used to train the LLM. Insert it into the prompt, and input the prompt to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uFcm6Dd7ls_F"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Here are the athletes who competed in the Olympics exactly 9 times:\n\n* **Hubert Raudaschl**\n* **Afanasijs Kuzmins**\n* **Nino Salukvadze** \n",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the list as of April 2024\n",
        "prompt = \"\"\"\n",
        "QUERY: provide a list of atheletes that competed in olympics exactly 9 times.\n",
        "CONTEXT:\n",
        "\n",
        "Table title: Olympic athletes and number of times they've competed\n",
        "Ian Millar, 10\n",
        "Hubert Raudaschl, 9\n",
        "Afanasijs Kuzmins, 9\n",
        "Nino Salukvadze, 9\n",
        "Piero d'Inzeo, 8\n",
        "Raimondo d'Inzeo, 8\n",
        "Claudia Pechstein, 8\n",
        "Jaqueline Mourão, 8\n",
        "Ivan Osiier, 7\n",
        "François Lafortune, Jr, 7\n",
        "\n",
        "\"\"\"\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest')\n",
        "Markdown(model.generate_content(prompt).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1jF9yUx91Fv"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "While some information may be easily searchable online without the use of an LLM, consider data that is not found on the internet, such as private documentation, quickbooks, and forums. Use this code as a template to help you input that information into the Gemini model.\n",
        "\n",
        "Be sure to explore other examples of prompting in the repository. Try writing prompts about classifying your own data, or try some of the other prompting techniques such as few-shot prompting."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Adding_context_information.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
