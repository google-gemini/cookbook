{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239fd94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Self-Improving Prompts with Gemini\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]\n",
    "(https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/prompting/self_improving_prompts.ipynb)\n",
    "\n",
    "This notebook demonstrates a simple self-improving prompt loop\n",
    "using Gemini models. The prompt is iteratively refined using\n",
    "model-generated critique to improve output quality.\n",
    "\n",
    "\n",
    "\n",
    "##setup\n",
    "\n",
    "\n",
    "This notebook requires a `GEMINI_API_KEY` environment variable.\n",
    "\n",
    "Set your API key before running the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849ee3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# Make sure your API key is set like:\n",
    "# export GEMINI_API_KEY=\"your_key_here\"\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "initial_prompt = \"\"\"\n",
    "Write a polite and helpful response to a customer\n",
    "who is upset about a delayed order.\n",
    "\"\"\"\n",
    "\n",
    "def generate_response(prompt):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-pro\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def critique_response(response_text):\n",
    "    critique_prompt = f\"\"\"\n",
    "    Review the following response and suggest improvements\n",
    "    in clarity, tone, and helpfulness.\n",
    "\n",
    "    RESPONSE:\n",
    "    {response_text}\n",
    "    \"\"\"\n",
    "    return generate_response(critique_prompt)\n",
    "\n",
    "def improve_response(original_response, critique):\n",
    "    improve_prompt = f\"\"\"\n",
    "    Improve the following response based on the critique.\n",
    "\n",
    "    RESPONSE:\n",
    "    {original_response}\n",
    "\n",
    "    CRITIQUE:\n",
    "    {critique}\n",
    "    \"\"\"\n",
    "    return generate_response(improve_prompt)\n",
    "\n",
    "response = generate_response(initial_prompt)\n",
    "print(\"Initial Response:\\n\", response)\n",
    "\n",
    "for i in range(2):\n",
    "    critique = critique_response(response)\n",
    "    response = improve_response(response, critique)\n",
    "    print(f\"\\nImproved Response (iteration {i+1}):\\n\", response)\n",
    "\n",
    "## Why this works\n",
    "\n",
    "By allowing the model to critique and improve its own outputs,\n",
    "we can iteratively refine responses without manual prompt tuning.\n",
    "\n",
    "This pattern is useful for customer support bots, agents,\n",
    "and automated content refinement workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817d720",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
