{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTx8eQlc3cP-"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "4HZoi8yf4GEU"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9I7LG483nXB"
      },
      "source": [
        "# Movie Recommendation System with Gemini API and Qdrant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKO767lQIWh"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/qdrant/Movie_Recommendation.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1xoF_bU4NCP"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWedABji6bXJ"
      },
      "source": [
        "The [Gemini API](https://ai.google.dev/models/gemini) provides access to a family of generative AI models for generating content and solving problems. These models are designed and trained to handle both text and images as input.\n",
        "\n",
        "[Qdrant](https://qdrant.tech/) is an open-source vector similarity search engine designed for efficient and scalable semantic search. It offers a simple yet powerful API to store and search high-dimensional vectors, supports filtering with metadata (payloads), and integrates easily into production systems. Qdrant can be self-hosted or accessed via its managed cloud service, making it quick to set up and ideal for a wide range of AI applications that rely on semantic understanding and retrieval.\n",
        "\n",
        "In this notebook, you'll learn how to perform a similarity search on data from a website with the help of Gemini API and Qdrant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIAarGkG8VwC"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, you must install the packages and set the necessary environment variables.\n",
        "\n",
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70wYOKUC8q1m"
      },
      "source": [
        "Install google's python client SDK for the Gemini API, `google-genai`. Next, install Qdrant's Python client SDK, `qdrant-client`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mnQbBnA1GKha"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/294.6 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/294.6 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q \"google-genai>=1.0.0\"\n",
        "%pip install -q protobuf==4.25.1 qdrant-client[fastembed]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eomJzCa6lb90"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v-JZzORUpVR2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSI_-yD-f6RA"
      },
      "source": [
        "## Building the Movie Vector Index\n",
        "This section covers preparing the movie dataset, generating embeddings using Gemini, and indexing them in Qdrant for similarity search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXG76XuDoq5H"
      },
      "source": [
        "### 1. Load the Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9a57dXrnIEt"
      },
      "source": [
        "Begin by loading the dataset from Kaggle using the kagglehub library. The dataset used in this notebook is the [TMDB Movie Dataset 2024](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies), which contains approximately 1 Million+ movie entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8n-X5X7cBWVL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-be1b43b299ac>:6: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/asaniczka/tmdb-movies-dataset-2023-930k-movies?dataset_version_number=596&file_name=TMDB_movie_dataset_v11.csv...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 533M/533M [00:10<00:00, 51.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"TMDB_movie_dataset_v11.csv\"\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"asaniczka/tmdb-movies-dataset-2023-930k-movies\",\n",
        "  file_path,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5UoP2DknSdw"
      },
      "source": [
        "### 2. Inspect the Dataset Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbq3XQOso2ca"
      },
      "source": [
        "Since the dataset is large, inspecting it helps you identify useful fields and filter out irrelevant data early on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dLAP-cw9DS3O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset Columns:\n",
            "Index(['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date',\n",
            "       'revenue', 'runtime', 'adult', 'backdrop_path', 'budget', 'homepage',\n",
            "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
            "       'popularity', 'poster_path', 'tagline', 'genres',\n",
            "       'production_companies', 'production_countries', 'spoken_languages',\n",
            "       'keywords'],\n",
            "      dtype='object')\n",
            "\n",
            "Missing Values per Column:\n",
            "id                            0\n",
            "title                        13\n",
            "vote_average                  0\n",
            "vote_count                    0\n",
            "status                        0\n",
            "release_date             231604\n",
            "revenue                       0\n",
            "runtime                       0\n",
            "adult                         0\n",
            "backdrop_path            916971\n",
            "budget                        0\n",
            "homepage                1107810\n",
            "imdb_id                  611252\n",
            "original_language             0\n",
            "original_title               13\n",
            "overview                 264156\n",
            "popularity                    0\n",
            "poster_path              409739\n",
            "tagline                 1063611\n",
            "genres                   515818\n",
            "production_companies     691253\n",
            "production_countries     569744\n",
            "spoken_languages         547562\n",
            "keywords                 914563\n",
            "dtype: int64\n",
            "\n",
            "Number of rows: 1237355\n",
            "Number of unique IDs: 1236407\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDataset Columns:\")\n",
        "print(df.columns)\n",
        "\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(f\"\\nNumber of rows: {len(df)}\")\n",
        "print(f\"Number of unique IDs: {df['id'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DHqjBnho8sB"
      },
      "source": [
        "### 3. Filter and Clean the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90khrPi0pB1G"
      },
      "source": [
        "This step filters the dataset to keep only metadata useful for semantic search: `id`, `title`, `overview`, `genres`, `keywords`, `tagline`, and `release_date`. These fields provide enough context to generate meaningful embeddings.\n",
        "\n",
        "Entries (rows) missing a `title` or lacking both `overview` and `genres` are removed, as they don’t have enough descriptive data for accurate recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FvanvDRbRGz2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original rows: 1237355\n",
            "Rows before dropping missing title: 1237355\n",
            "Rows after dropping missing title and dropping missing (genres and overview): 1097135\n",
            "\n",
            "Sample data after cleaning (keeping missing overviews):\n",
            "       id            title                                           overview  \\\n",
            "0   27205        Inception  Cobb, a skilled thief who commits corporate es...   \n",
            "1  157336     Interstellar  The adventures of a group of explorers who mak...   \n",
            "2     155  The Dark Knight  Batman raises the stakes in his war on crime. ...   \n",
            "3   19995           Avatar  In the 22nd century, a paraplegic Marine is di...   \n",
            "4   24428     The Avengers  When an unexpected enemy emerges and threatens...   \n",
            "\n",
            "                                        genres  \\\n",
            "0           Action, Science Fiction, Adventure   \n",
            "1            Adventure, Drama, Science Fiction   \n",
            "2               Drama, Action, Crime, Thriller   \n",
            "3  Action, Adventure, Fantasy, Science Fiction   \n",
            "4           Science Fiction, Action, Adventure   \n",
            "\n",
            "                                            keywords  \\\n",
            "0  rescue, mission, dream, airplane, paris, franc...   \n",
            "1  rescue, future, spacecraft, race against time,...   \n",
            "2  joker, sadism, chaos, secret identity, crime f...   \n",
            "3  future, society, culture clash, space travel, ...   \n",
            "4  new york city, superhero, shield, based on com...   \n",
            "\n",
            "                                             tagline  release_year  \n",
            "0               Your mind is the scene of the crime.        2010.0  \n",
            "1  Mankind was born on Earth. It was never meant ...        2014.0  \n",
            "2                  Welcome to a world without rules.        2008.0  \n",
            "3                        Enter the world of Pandora.        2009.0  \n",
            "4                            Some assembly required.        2012.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "print(f\"Original rows: {len(df)}\")\n",
        "\n",
        "columns_to_keep = ['id', 'title', 'overview', 'genres', 'keywords', 'tagline', 'release_date']\n",
        "\n",
        "df_relevant = df[columns_to_keep].copy()\n",
        "\n",
        "print(f\"Rows before dropping missing title: {len(df_relevant)}\")\n",
        "df_relevant.dropna(subset=['title'], inplace=True)\n",
        "df_relevant = df_relevant[~(df_relevant['genres'].isna() & df_relevant['overview'].isna())]\n",
        "print(f\"Rows after dropping missing title and dropping missing (genres and overview): {len(df_relevant)}\")\n",
        "\n",
        "# Fill missing text columns with empty strings\n",
        "text_cols_to_fill = ['overview', 'genres', 'keywords', 'tagline']\n",
        "for col in text_cols_to_fill:\n",
        "    df_relevant[col] = df_relevant[col].fillna('')\n",
        "\n",
        "\n",
        "# Extract release year from the release_date string\n",
        "def get_year(date_str):\n",
        "    if pd.isna(date_str) or not isinstance(date_str, str) or len(date_str) < 4:\n",
        "        return None\n",
        "    try:\n",
        "        return int(date_str[:4])\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "df_relevant['release_year'] = df_relevant['release_date'].apply(get_year)\n",
        "\n",
        "print(\"\\nSample data after cleaning (keeping missing overviews):\")\n",
        "print(df_relevant[['id', 'title', 'overview', 'genres', 'keywords', 'tagline', 'release_year']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQOfcdqmxLqE"
      },
      "source": [
        "### 4. Prepare Text for Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdcu4I9Lq0Kn"
      },
      "source": [
        "This step prepares the movie metadata for embedding by combining relevant fields into a single structured text string. This representation includes the title, overview, genres, keywords, tagline, and release year (if available). The output is stored in a new column called `text_for_embedding`.\n",
        "\n",
        "Embeddings are numerical vector representations of text that capture semantic meaning and relationships. These vectors can be used for tasks like similarity search and clustering.\n",
        "Learn more about [text embeddings](https://ai.google.dev/gemini-api/docs/embeddings) and explore the [Gemini embedding notebook](../../quickstarts/Embeddings.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "POQgvioiZdYe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       id            title                                 text_for_embedding\n",
            "0   27205        Inception  Title: Inception\\nOverview: Cobb, a skilled th...\n",
            "1  157336     Interstellar  Title: Interstellar\\nOverview: The adventures ...\n",
            "2     155  The Dark Knight  Title: The Dark Knight\\nOverview: Batman raise...\n",
            "3   19995           Avatar  Title: Avatar\\nOverview: In the 22nd century, ...\n",
            "4   24428     The Avengers  Title: The Avengers\\nOverview: When an unexpec...\n"
          ]
        }
      ],
      "source": [
        "def create_embedding_text(row):\n",
        "    \"\"\"Combines available movie metadata into a single string for embedding.\"\"\"\n",
        "    # Title is always present, so it can be included directly\n",
        "    title_str = f\"Title: {row['title']}\"\n",
        "    overview_str = f\"Overview: {row['overview']}\" if row['overview'] else \"\"\n",
        "    year_str = f\"Release Year: {int(row['release_year'])}\" if pd.notna(row['release_year']) else \"\"\n",
        "    genre_str = f\"Genres: {row['genres']}\" if row['genres'] else \"\"\n",
        "    keywords_str = f\"Keywords: {row['keywords']}\" if row['keywords'] else \"\"\n",
        "    tagline_str = f\"Tagline: {row['tagline']}\" if row['tagline'] else \"\"\n",
        "\n",
        "    parts = [\n",
        "        title_str,\n",
        "        overview_str,\n",
        "        year_str,\n",
        "        genre_str,\n",
        "        keywords_str,\n",
        "        tagline_str\n",
        "    ]\n",
        "    return \"\\n\".join(part for part in parts if part)\n",
        "\n",
        "df_relevant['text_for_embedding'] = df_relevant.apply(create_embedding_text, axis=1)\n",
        "\n",
        "# Use this to inspect how movie data has been transformed for embedding\n",
        "print(df_relevant[['id', 'title', 'text_for_embedding']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9aASY5Uf_RO"
      },
      "source": [
        "### 5. Sample a Subset for Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G6hxoLDx0vz"
      },
      "source": [
        "To keep the notebook easy to run and ensure efficient development, you’ll want to iterate quickly and minimize resource usage. Instead of using the full dataset, this step samples 5,000 movies from the cleaned data, unless the dataset is already smaller, in which case all entries are used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U7xpaVeLZxYc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Taking a random sample of 5000 movies for development.\n",
            "Working with 5000 movies for the next steps.\n",
            "              id                             title  release_year\n",
            "1022852   913650                             SERYO        2015.0\n",
            "1081047   990808  Ang Galing-galing Mo, Mrs. Jones        1980.0\n",
            "191884    422235                             Hedda        2016.0\n",
            "1007202   535478                          Deducked        2018.0\n",
            "393540   1238198                 Songs of Paradise           NaN\n",
            "\n",
            "Final sample DataFrame structure for embedding/indexing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5000 entries, 1022852 to 604641\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   id                  5000 non-null   int64  \n",
            " 1   text_for_embedding  5000 non-null   object \n",
            " 2   title               5000 non-null   object \n",
            " 3   overview            5000 non-null   object \n",
            " 4   genres              5000 non-null   object \n",
            " 5   keywords            5000 non-null   object \n",
            " 6   tagline             5000 non-null   object \n",
            " 7   release_year        4255 non-null   float64\n",
            "dtypes: float64(1), int64(1), object(6)\n",
            "memory usage: 351.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "SAMPLE_SIZE = 5000\n",
        "\n",
        "if len(df_relevant) > SAMPLE_SIZE:\n",
        "    print(f\"\\nTaking a random sample of {SAMPLE_SIZE} movies for development.\")\n",
        "    df_sample = df_relevant.sample(n=SAMPLE_SIZE, random_state=42)\n",
        "else:\n",
        "    print(f\"\\nCleaned dataset size ({len(df_relevant)}) is smaller than or equal to SAMPLE_SIZE. Using the full cleaned dataset.\")\n",
        "    df_sample = df_relevant\n",
        "\n",
        "print(f\"Working with {len(df_sample)} movies for the next steps.\")\n",
        "print(df_sample[['id', 'title', 'release_year']].head())\n",
        "\n",
        "columns_for_payload = ['title', 'overview', 'genres', 'keywords', 'tagline', 'release_year']\n",
        "columns_final = ['id', 'text_for_embedding'] + columns_for_payload\n",
        "df_sample = df_sample[columns_final]\n",
        "\n",
        "print(\"\\nFinal sample DataFrame structure for embedding/indexing:\")\n",
        "print(df_sample.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNK2HU9CyQ-N"
      },
      "source": [
        "### 6. Initialize Qdrant for Vector Indexing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-cBsGtF3xVK"
      },
      "source": [
        "With the data prepared, the next step is to set up **Qdrant**, a vector similarity search engine optimized for storing and querying high-dimensional vectors. It supports fast indexing, filtering, and similarity search across millions of vectors.\n",
        "\n",
        "Qdrant can run:\n",
        "\n",
        "* Locally as a standalone service\n",
        "* In the cloud for production deployments\n",
        "* Or entirely **in-memory** for fast, temporary use during development\n",
        "\n",
        "In this notebook, Qdrant is initialized using in-memory mode by passing `\":memory:\"` to the client. This stores data only in RAM, meaning it **will not persist after the session ends**. This is suitable for experimentation but not for saving results long-term.\n",
        "\n",
        "You also configure the following:\n",
        "\n",
        "* `COLLECTION_NAME`: The name of the Qdrant collection to store movie vectors\n",
        "* `VECTOR_SIZE`: Set to `768` to match the dimensionality of the text embeddings generated by Gemini\n",
        "* `DISTANCE_METRIC`: Set to **cosine distance**, which is ideal for measuring semantic similarity between embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OQqy7lxgajVI"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "import time\n",
        "\n",
        "COLLECTION_NAME = \"tmdb_movies_sample\"\n",
        "\n",
        "VECTOR_SIZE = 768\n",
        "DISTANCE_METRIC = models.Distance.COSINE\n",
        "\n",
        "\n",
        "# Initialize Qdrant client using in-memory storage\n",
        "qdrant_client = QdrantClient(\":memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If3cSgEHgGlJ"
      },
      "source": [
        "### 7. Define Batch Embedding Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHkDkoBQ31Ie"
      },
      "source": [
        "This step defines the `get_embeddings_batch` function, which generates text embeddings for batches of movie data using the Gemini embedding model (`embedding-001`) including automatic retries for robustness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qWODHe__bAeO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example embedding vector: [0.04476204, -0.021633359, -0.08440986, -0.0115498435, 0.06313622, 0.011256916, 0.0036218397, 0.018719628, 0.012621079, 0.03685386]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from google.api_core import exceptions, retry\n",
        "\n",
        "MODEL_FOR_EMBEDDING = \"embedding-001\" # @param [\"embedding-001\", \"text-embedding-004\",\"gemini-embedding-exp-03-07\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "QDRANT_BATCH_SIZE = 768\n",
        "\n",
        "\n",
        "@retry.Retry(timeout=3000)\n",
        "def get_embeddings_batch(texts: list[str], task_type=\"RETRIEVAL_DOCUMENT\") -> list[list[float]] | None:\n",
        "    \"\"\"\n",
        "    Generates embeddings for a batch of texts using Gemini API with retry.\n",
        "\n",
        "    Args:\n",
        "        texts: A list of strings to embed.\n",
        "        task_type: The task type for the embedding model.\n",
        "\n",
        "    Returns:\n",
        "        A list of embedding vectors (list of floats), or None if a non-retryable error occurs.\n",
        "    \"\"\"\n",
        "    if not texts:\n",
        "        return []\n",
        "    try:\n",
        "        response = client.models.embed_content(\n",
        "          model=MODEL_FOR_EMBEDDING,\n",
        "          contents=texts,\n",
        "          config={\n",
        "            \"task_type\":task_type,\n",
        "          }\n",
        "        )\n",
        "        return response.embeddings\n",
        "    except exceptions.RetryError as e:\n",
        "        print(f\"Embedding batch failed after retries: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example of what an embedding looks like\n",
        "sample_embedding = get_embeddings_batch([\"Example movie about space and survival\"])[0]\n",
        "print(\"Example embedding vector:\", sample_embedding.values[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-LbEZvKghOW"
      },
      "source": [
        "### 8. Create a Collection in Qdrant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tIp23934sv"
      },
      "source": [
        "A collection in Qdrant is like a table in a database, it stores vectors along with optional metadata (payload). Each collection has its own configuration, including vector size and similarity metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m0TDkDU7bPq5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existing collection 'tmdb_movies_sample' deleted.\n",
            "Collection 'tmdb_movies_sample' created successfully.\n"
          ]
        }
      ],
      "source": [
        "# In case someone tries running the whole notebook again they would want to create the collection again\n",
        "\n",
        "try:\n",
        "    qdrant_client.delete_collection(collection_name=COLLECTION_NAME)\n",
        "    print(f\"Existing collection '{COLLECTION_NAME}' deleted.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error deleting collection (it might not exist): {e}\")\n",
        "\n",
        "try:\n",
        "    qdrant_client.create_collection(\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=VECTOR_SIZE,\n",
        "            distance=DISTANCE_METRIC\n",
        "        )\n",
        "    )\n",
        "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating collection: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dp5nla31TJn"
      },
      "source": [
        "### 9. Create Payloads for Metadata Storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyIG8Ip24KGO"
      },
      "source": [
        "In Qdrant, besides storing vector embeddings, you can attach additional information called payload to each vector. This metadata helps in filtering or retrieving relevant results based on attributes like title, genres, or release year.\n",
        "\n",
        "The `create_payload` function prepares the payload by extracting specified columns from each movie record, handling missing values and ensuring data types are compatible with Qdrant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YhcyKADBbXze"
      },
      "outputs": [],
      "source": [
        "payload_columns = [\n",
        "    'title', 'overview', 'genres', 'keywords', 'tagline', 'release_year'\n",
        "]\n",
        "\n",
        "def create_payload(row, payload_columns):\n",
        "    payload = {}\n",
        "    for col in payload_columns:\n",
        "        value = row[col]\n",
        "        if pd.isna(value):\n",
        "            payload[col] = None\n",
        "        elif isinstance(value, (np.int64, np.int32)):\n",
        "            payload[col] = int(value)\n",
        "        elif isinstance(value, (np.float64, np.float32)):\n",
        "             payload[col] = float(value)\n",
        "        else:\n",
        "            payload[col] = value\n",
        "    return payload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRmxfjDj1zmN"
      },
      "source": [
        "### 10. Batch Embedding and Indexing to Qdrant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QImVW0tC38fi"
      },
      "source": [
        "This step processes the sampled movies dataset in batches to generate vector embeddings using the Gemini API and upload (upsert) these embeddings along with their metadata payloads to the Qdrant collection.\n",
        "\n",
        "**Key points of this process:**\n",
        "\n",
        "* The dataset is divided into batches of size `BATCH_SIZE` for embedding generation to stay within API limits.\n",
        "* Each batch's text data is sent to the Gemini embedding API with retries handled in the embedding function.\n",
        "* For every successfully embedded batch, the code prepares **points** (each containing an ID, vector embedding, and metadata payload) to be uploaded to Qdrant.\n",
        "* Points are buffered and uploaded in chunks of size `QDRANT_BATCH_SIZE` to optimize performance.\n",
        "* The process includes error handling and retry logic to avoid failures halting the entire operation.\n",
        "* At the end, any remaining points in the buffer are uploaded.\n",
        "* Summary statistics of processed, failed, and successfully upserted items are printed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Jp-omB2jbfpS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting batch embedding and indexing process for 5000 movies...\n",
            "Using Gemini Batch Size: 100, Qdrant Upsert Batch Size: 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Batches: 100%|██████████| 50/50 [00:52<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch embedding and indexing finished.\n",
            "Total items processed (attempted embedding): 5000\n",
            "Total points successfully prepared for upsert: 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"Starting batch embedding and indexing process for {len(df_sample)} movies...\")\n",
        "print(f\"Using Gemini Batch Size: {BATCH_SIZE}, Qdrant Upsert Batch Size: {QDRANT_BATCH_SIZE}\")\n",
        "\n",
        "points_to_upsert_buffer = []\n",
        "total_processed = 0\n",
        "total_failed_embedding = 0\n",
        "total_upserted = 0\n",
        "\n",
        "num_batches = (len(df_sample) + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "for i in tqdm(range(0, len(df_sample), BATCH_SIZE), total=num_batches, desc=\"Processing Batches\"):\n",
        "    batch_df = df_sample.iloc[i : i + BATCH_SIZE]\n",
        "    batch_texts = batch_df['text_for_embedding'].tolist()\n",
        "    batch_ids = batch_df['id'].tolist()\n",
        "\n",
        "    if not batch_texts:\n",
        "        continue\n",
        "\n",
        "    # Generate embeddings for the current batch of movie texts\n",
        "    batch_embeddings = get_embeddings_batch(batch_texts, task_type=\"RETRIEVAL_DOCUMENT\")\n",
        "\n",
        "    # Check if embeddings were successfully generated and correspond to batch size\n",
        "    if batch_embeddings and len(batch_embeddings) == len(batch_texts):\n",
        "        for j in range(len(batch_ids)):\n",
        "            item_id = batch_ids[j]\n",
        "            item_embedding = batch_embeddings[j]\n",
        "            row_data = batch_df.iloc[j]\n",
        "\n",
        "            # Prepare metadata payload for this movie\n",
        "            payload = create_payload(row_data, payload_columns)\n",
        "\n",
        "            # Create a Qdrant PointStruct with id, embedding vector, and payload\n",
        "            point = models.PointStruct(\n",
        "                id=int(item_id),\n",
        "                vector=item_embedding.values,\n",
        "                payload=payload\n",
        "            )\n",
        "            points_to_upsert_buffer.append(point)\n",
        "\n",
        "        total_processed += len(batch_ids)\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to get embeddings for batch starting at index {i}. Skipping {len(batch_ids)} items.\")\n",
        "        total_failed_embedding += len(batch_ids)\n",
        "        continue\n",
        "\n",
        "    # Upload buffered points to Qdrant if buffer reached batch size or end of data\n",
        "    if len(points_to_upsert_buffer) >= QDRANT_BATCH_SIZE or (i + BATCH_SIZE >= len(df_sample)):\n",
        "        if points_to_upsert_buffer:\n",
        "            try:\n",
        "                qdrant_client.upsert(\n",
        "                    collection_name=COLLECTION_NAME,\n",
        "                    points=points_to_upsert_buffer,\n",
        "                    wait=False\n",
        "                )\n",
        "                total_upserted += len(points_to_upsert_buffer)\n",
        "                points_to_upsert_buffer = []\n",
        "            except Exception as e:\n",
        "                print(f\"Error upserting chunk to Qdrant: {e}\")\n",
        "                points_to_upsert_buffer = []\n",
        "                time.sleep(5)\n",
        "                # Pause before retrying to avoid hammering the service after an error\n",
        "\n",
        "# Upload any remaining points left in buffer after loop completion\n",
        "if points_to_upsert_buffer:\n",
        "    print(f\"Upserting final remaining chunk of {len(points_to_upsert_buffer)} points.\")\n",
        "    try:\n",
        "        qdrant_client.upsert(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            points=points_to_upsert_buffer,\n",
        "            wait=True\n",
        "        )\n",
        "        total_upserted += len(points_to_upsert_buffer)\n",
        "        points_to_upsert_buffer = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error upserting final chunk: {e}\")\n",
        "\n",
        "print(\"Batch embedding and indexing finished.\")\n",
        "print(f\"Total items processed (attempted embedding): {total_processed}\")\n",
        "print(f\"Total points successfully prepared for upsert: {total_upserted}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v6l-OtOFsmeW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Verification: Collection 'tmdb_movies_sample' now contains 5000 points.\n"
          ]
        }
      ],
      "source": [
        "# Waiting for collection to settle\n",
        "time.sleep(5)\n",
        "\n",
        "try:\n",
        "    count = qdrant_client.count(collection_name=COLLECTION_NAME, exact=True)\n",
        "    print(f\"\\nVerification: Collection '{COLLECTION_NAME}' now contains {count.count} points.\") # it should print 5000\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error verifying collection count: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtFYhuo52rGi"
      },
      "source": [
        "### 11. Search and Recommend Similar Movies Using Vector Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjNKMgn54GSG"
      },
      "source": [
        "With all movie vectors indexed in Qdrant, you can now perform semantic search. This allows you to take any user query (such as a phrase, movie description, or concept), convert it into an embedding using the same Gemini model, and retrieve the most similar movie vectors from the collection using cosine similarity.\n",
        "\n",
        "This `recommend_movies` function demonstrates how to:\n",
        "\n",
        "* Generate an embedding from your input query using the Gemini API.\n",
        "* Perform a similarity search using Qdrant’s `search()` method.\n",
        "* Retrieve the top `k` most similar movie entries, including their metadata and similarity scores.\n",
        "\n",
        "This is the final step where the vector database functions as a recommendation engine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i3gAZ30qtGZo"
      },
      "outputs": [],
      "source": [
        "def recommend_movies(query_text, top_k=5):\n",
        "    \"\"\"\n",
        "    Finds movies similar to the query_text using the Qdrant index.\n",
        "\n",
        "    Args:\n",
        "        query_text (str): The user's query (e.g., movie title, description, theme).\n",
        "        top_k (int): The maximum number of recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the\n",
        "              payload (movie details) and similarity score of a recommended movie.\n",
        "              Returns an empty list if query embedding fails or no results found.\n",
        "    \"\"\"\n",
        "    print(f\"Searching for recommendations based on: '{query_text}'\")\n",
        "    # Generate embedding for the user query using Gemini\n",
        "    query_embedding = get_embeddings_batch(query_text, task_type=\"RETRIEVAL_QUERY\")[0].values\n",
        "\n",
        "    if query_embedding is None:\n",
        "        print(\"Error: Could not generate embedding for the query.\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        # Perform a semantic search on Qdrant using the query vector\n",
        "        search_result = qdrant_client.search(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            query_vector=query_embedding,\n",
        "            limit=top_k,\n",
        "            with_payload=True\n",
        "        )\n",
        "\n",
        "        recommendations = []\n",
        "        if search_result:\n",
        "            print(f\"Found {len(search_result)} potential recommendations:\")\n",
        "            for hit in search_result:\n",
        "                recommendation = {\n",
        "                    \"id\": hit.id,\n",
        "                    \"score\": hit.score,\n",
        "                    \"payload\": hit.payload\n",
        "                }\n",
        "                recommendations.append(recommendation)\n",
        "        else:\n",
        "            print(\"No recommendations found matching the query.\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Qdrant search: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN6jiYMB3OWG"
      },
      "source": [
        "## Try Out Your Movie Recommender\n",
        "You can now try querying your movie recommender by describing a theme, genre, or concept in natural language. The system will return the most semantically similar movies from your dataset based on vector similarity search using Gemini-generated embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T3aRrQZltXM5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for recommendations based on: '\n",
            "  I want to watch something with my girlfriends that’s \n",
            "  both funny and teaches something.\n",
            "'\n",
            "Found 5 potential recommendations:\n",
            "\n",
            "--- Recommendations ---\n",
            "  - Score: 0.6326\n",
            "    Title: #pregnancytestroulette\n",
            "    Genre: Comedy, Drama\n",
            "    Year: 2022.0\n",
            "----------\n",
            "  - Score: 0.6244\n",
            "    Title: Locas y atrapadas\n",
            "    Genre: Comedy\n",
            "    Year: 2014.0\n",
            "----------\n",
            "  - Score: 0.6222\n",
            "    Title: Amigas de Sorte\n",
            "    Genre: Comedy\n",
            "    Year: 2021.0\n",
            "----------\n",
            "  - Score: 0.6206\n",
            "    Title: The Perfect Secret\n",
            "    Genre: Comedy, Drama\n",
            "    Year: 2019.0\n",
            "----------\n",
            "  - Score: 0.6192\n",
            "    Title: YOLO\n",
            "    Genre: Drama, Music\n",
            "    Year: 2013.0\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-6899941fa2e0>:24: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  search_result = qdrant_client.search(\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"\n",
        "  I want to watch something with my girlfriends that’s\n",
        "  both funny and teaches something.\n",
        "\"\"\"\n",
        "recommendations = recommend_movies(query, top_k=5)\n",
        "\n",
        "if recommendations:\n",
        "    print(\"\\n--- Recommendations ---\")\n",
        "    for rec in recommendations:\n",
        "        print(f\"  - Score: {rec['score']:.4f}\")\n",
        "        print(f\"    Title: {rec['payload'].get('title', 'N/A')}\")\n",
        "        print(f\"    Genre: {rec['payload'].get('genres', 'N/A')}\")\n",
        "        print(f\"    Year: {rec['payload'].get('release_year', 'N/A')}\")\n",
        "        print(\"-\" * 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRqEnlN8AK6w"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "This notebook demonstrated how to build a movie recommendation system by combining the Gemini API’s embedding capabilities with Qdrant’s vector search.\n",
        "\n",
        "### Useful API References\n",
        "\n",
        "For more detailed understanding and to explore advanced features, refer to the official documentation:\n",
        "\n",
        "* **[Gemini API Embeddings Documentation](https://ai.google.dev/gemini-api/docs/embeddings)**: Learn how to generate text embeddings, understand model parameters, and use them effectively for semantic search and similarity tasks.\n",
        "\n",
        "* **[Qdrant Python Client Docs](https://python-client.qdrant.tech/)**: Understand how to manage collections, insert and search vectors, configure indexing, and interact with the vector database.\n",
        "\n",
        "### Related Examples\n",
        "\n",
        "To explore more use cases and get additional inspiration, check out these related notebooks in this directory:\n",
        "\n",
        "* **[Similarity Search using Qdrant](../examples/qdrant/Qdrant_similarity_search.ipynb)**: A focused example on building semantic search systems with embeddings and Qdrant.\n",
        "\n",
        "* **[Google GenAI SDK Overview](../../quickstarts/Get_started.ipynb)**: Walks you through installing and setting up the SDK, text and multimodal prompting, token counting, safety filters, multi-turn chat, function calling, file uploads, context caching, and more.\n",
        "\n",
        "* **[Text Embeddings with Gemini API](../../quickstarts/Embeddings.ipynb)**: Focuses on generating and working with text embeddings using the Gemini API, ideal for building vector-based search and recommendation systems.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Movie_Recommendation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
