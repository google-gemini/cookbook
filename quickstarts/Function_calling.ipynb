{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Function calling with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1767a3d1cc"
      },
      "source": [
        " Function calling lets developers create a description of a function in their code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with. Function calling lets you use functions as tools in generative AI applications, and you can define more than one function within a single request.\n",
        "\n",
        "This notebook provides code examples to help you get started. The documentation's [quickstart](https://ai.google.dev/tutorials/function_calling_python_quickstart) is also a good place to start understanding function calling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY2NtS3jV56U"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5027929de8f"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU 'google-genai'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "from google import genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-hHZfLZ7FfH"
      },
      "source": [
        "### Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](../quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpaKynP8qLw1"
      },
      "source": [
        "### Choose a model\n",
        "\n",
        "Function calling should work with all the [Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) models with the GenAI SDK. It also works with the 1.5 generation of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sEK4ZDVGqJ5H"
      },
      "outputs": [],
      "source": [
        "MODEL_ID=\"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.5-flash-preview-04-17\", \"gemini-2.5-pro-preview-03-25\", \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f383614ec30"
      },
      "source": [
        "## Function calling basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b82c1aecb657"
      },
      "source": [
        "To use function calling, pass a list of functions to the `tools` parameter when creating a [`GenerativeModel`](https://ai.google.dev/api/python/google/generativeai/GenerativeModel). The model uses the function name, docstring, parameters, and parameter type annotations to decide if it needs the function to best answer a prompt.\n",
        "\n",
        "> Important: The SDK converts function parameter type annotations to a format the API understands (`genai.types.FunctionDeclaration`). The API only supports a limited selection of parameter types, and the Python SDK's automatic conversion only supports a subset of that: `AllowedTypes = int | float | bool | str | list['AllowedTypes'] | dict`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "42b27b02d2f5"
      },
      "outputs": [],
      "source": [
        "from google.genai import types\n",
        "def add(a: float, b: float):\n",
        "    \"\"\"returns a + b.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def subtract(a: float, b: float):\n",
        "    \"\"\"returns a - b.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float):\n",
        "    \"\"\"returns a * b.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def divide(a: float, b: float):\n",
        "    \"\"\"returns a / b.\"\"\"\n",
        "    return a / b\n",
        "\n",
        "\n",
        "operation_tools = [add, subtract, multiply, divide]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzUgtaY99BTg"
      },
      "source": [
        "## Automatic function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5fd91032a1e"
      },
      "source": [
        "Function calls naturally fit in to [multi-turn chats](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#chat) as they capture a back and forth interaction between the user and model. The Python SDK's [`Chat` Session](https://googleapis.github.io/python-genai/index.html#chats) is a great interface for chats because handles the conversation history for you, and using the parameter `automatic_function_calling` (enabled by default) simplifies function calling even further:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d3b91c855257"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(\n",
        "    model = MODEL_ID,\n",
        "    config = {\n",
        "        \"tools\": operation_tools,\n",
        "        \"automatic_function_calling\": {\"disable\": False} # This line is not needed as automatic_function_calling is enabled by default\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1481a6159399"
      },
      "source": [
        "With automatic function calling enabled, `Chat.send_message` automatically calls your function if the model asks it to.\n",
        "\n",
        "In the following example, the result appears to simply be a text response containing the correct answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "81d8def3d865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'That would be 2508 mittens in total.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.send_message(\n",
        "    \"I have 57 cats, each owns 44 mittens, how many mittens is that in total?\"\n",
        ")\n",
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "951c0f83f72e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2508"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "57 * 44"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7731e35f2383"
      },
      "source": [
        "However, by examining the chat history, you can see the flow of the conversation and how function calls are integrated within it.\n",
        "\n",
        "The `Chat.history` property stores a chronological record of the conversation between the user and the Gemini model. You can get the history using `Chat.get_history()`. Each turn in the conversation is represented by a [`genai.types.Content`](https://googleapis.github.io/python-genai/genai.html#genai.types.Content) object, which contains the following information:\n",
        "\n",
        "*   **Role**: Identifies whether the content originated from the \"user\" or the \"model\".\n",
        "*   **Parts**: A list of [`genai.types.Part`](https://googleapis.github.io/python-genai/genai.html#genai.types.Part) objects that represent individual components of the message. With a text-only model, these parts can be:\n",
        "    *   **Text**: Plain text messages.\n",
        "    *   **Function Call** ([`genai.types.FunctionCall`](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionCall)): A request from the model to execute a specific function with provided arguments.\n",
        "    *   **Function Response** ([`genai.types.FunctionResponse`](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionResponse)): The result returned by the user after executing the requested function.\n",
        "\n",
        " In the previous example with the mittens calculation, the history shows the following sequence:\n",
        "\n",
        "1.  **User**: Asks the question about the total number of mittens.\n",
        "1.  **Model**: Determines that the multiply function is helpful and sends a FunctionCall request to the user.\n",
        "1.  **User**: The `Chat` session automatically executes the function (due to `_automatic_function_calling` being set) and sends back a `FunctionResponse` with the calculated result.\n",
        "1.  **Model**: Uses the function's output to formulate the final answer and presents it as a text response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9f7eff1e8e60"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "I have 57 cats, each owns 44 mittens, how many mittens is that in total?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'a': 57, 'b': 44} name='multiply' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='multiply' response={'result': 2508} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "That would be 2508 mittens in total."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "for content in chat.get_history():\n",
        "    display(Markdown(\"###\" + content.role + \":\"))\n",
        "    for part in content.parts:\n",
        "        if part.text:\n",
        "            display(Markdown(part.text))\n",
        "        if part.function_call:\n",
        "            print(\"Function call: {\", part.function_call, \"}\")\n",
        "        if part.function_response:\n",
        "            print(\"Function response: {\", part.function_response, \"}\")\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2471fd72f05e"
      },
      "source": [
        "In general the state diagram is:\n",
        "\n",
        "<img src=\"https://codelabs.developers.google.com/static/codelabs/gemini-function-calling/img/gemini-function-calling-overview_1440.png\" alt=\"The model can always reply with text, or a FunctionCall. If the model sends a FunctionCall the user must reply with a FunctionResponse\" width=50%>\n",
        "\n",
        "The model can respond with multiple function calls before returning a text response, and function calls come before the text response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eea8e3a0b89f"
      },
      "source": [
        "## Manual function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9610f3465a69"
      },
      "source": [
        "For more control, you can process [`genai.types.FunctionCall`](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionCall) requests from the model yourself. This would be the case if:\n",
        "\n",
        "- You use a `Chat` with the default `\"automatic_function_calling\": {\"disable\": False}`.\n",
        "- You use [`Client.model.generate_content`](https://googleapis.github.io/python-genai/genai.html#genai.types.) (and manage the chat history yourself)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34ffab0bf365"
      },
      "source": [
        "The following example is a rough equivalent of the [function calling single-turn curl sample](https://ai.google.dev/docs/function_calling#function-calling-single-turn-curl-sample) in Python. It uses functions that return (mock) movie playtime information, possibly from a hypothetical API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "46ba0fa3d09a"
      },
      "outputs": [],
      "source": [
        "def find_movies(description: str, location: str):\n",
        "    \"\"\"find movie titles currently playing in theaters based on any description, genre, title words, etc.\n",
        "\n",
        "    Args:\n",
        "        description: Any kind of description including category or genre, title words, attributes, etc.\n",
        "        location: The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\n",
        "    \"\"\"\n",
        "    return [\"Barbie\", \"Oppenheimer\"]\n",
        "\n",
        "\n",
        "def find_theaters(location: str, movie: str):\n",
        "    \"\"\"Find theaters based on location and optionally movie title which are is currently playing in theaters.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\n",
        "        movie: Any movie title\n",
        "    \"\"\"\n",
        "    return [\"Googleplex 16\", \"Android Theatre\"]\n",
        "\n",
        "\n",
        "def get_showtimes(location: str, movie: str, theater: str, date: str):\n",
        "    \"\"\"\n",
        "    Find the start times for movies playing in a specific theater.\n",
        "\n",
        "    Args:\n",
        "      location: The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\n",
        "      movie: Any movie title\n",
        "      thearer: Name of the theater\n",
        "      date: Date for requested showtime\n",
        "    \"\"\"\n",
        "    return [\"10:00\", \"11:00\"]\n",
        "\n",
        "theater_functions = [find_movies, find_theaters, get_showtimes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11631c6e2b10"
      },
      "source": [
        "After using `generate_content()` to ask a question, the model requests a `function_call`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5e3b9c84d883"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id=None, args={'location': 'Mountain View, CA', 'movie': 'Barbie'}, name='find_theaters'), function_response=None, inline_data=None, text=None)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Which theaters in Mountain View show the Barbie movie?\",\n",
        "    config = {\n",
        "        \"tools\": theater_functions,\n",
        "        \"automatic_function_calling\": {\"disable\": True} # This line is not needed as automatic_function_calling is enabled by default\n",
        "    }\n",
        ")\n",
        "\n",
        "response.candidates[0].content.parts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuldoypuAC1i"
      },
      "source": [
        "Since this is not using a `ChatSession` with automatic function calling, you have to call the function yourself.\n",
        "\n",
        "A very simple way to do this would be with `if` statements:\n",
        "\n",
        "```python\n",
        "if function_call.name == 'find_theaters':\n",
        "  find_theaters(**function_call.args)\n",
        "elif ...\n",
        "```\n",
        "\n",
        "However, since you already made the `functions` dictionary, this can be simplified to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rjkZ8MA00Coc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Googleplex 16', 'Android Theatre']\n"
          ]
        }
      ],
      "source": [
        "def call_function(function_call, functions):\n",
        "    function_name = function_call.name\n",
        "    function_args = function_call.args\n",
        "    # Find the function object from the list based on the function name\n",
        "    for func in functions:\n",
        "        if func.__name__ == function_name:\n",
        "            return func(**function_args)\n",
        "\n",
        "part = response.candidates[0].content.parts[0]\n",
        "\n",
        "# Check if it's a function call; in real use you'd need to also handle text\n",
        "# responses as you won't know what the model will respond with.\n",
        "if part.function_call:\n",
        "    result = call_function(part.function_call, theater_functions)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLWrHOatBtRz"
      },
      "source": [
        "Finally, pass the response plus the message history to the next `generate_content()` call to get a final text response from the model. The next code cell is showing on purpose different ways to write down `Content` so you can choose the one that you prefer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xr13VGnJAgZv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Barbie movie is currently playing at the Googleplex 16 and Android Theatre in Mountain View.\n"
          ]
        }
      ],
      "source": [
        "# Build the message history\n",
        "messages = [\n",
        "    genai.types.Content(role=\"user\", parts=[genai.types.Part(text=\"Which theaters in Mountain View show the Barbie movie?.\")]),\n",
        "    genai.types.Content(role=\"model\", parts=[part]),\n",
        "    {\"role\":\"user\", \"parts\":[{\"function_response\":{\"response\":{\"output\":result}, \"name\":part.function_call.name}}]},\n",
        "]\n",
        "\n",
        "# Generate the next response\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=messages,\n",
        "    config = {\n",
        "        \"tools\": theater_functions,\n",
        "        \"automatic_function_calling\": {\"disable\": True}\n",
        "    }\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94a52c498cb8"
      },
      "source": [
        "## Function calling chain\n",
        "\n",
        "The model is not limited to one function call, it can chain them until it finds the right answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "809deb79f194"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Which comedy movies are shown tonight (01/01/2025) in Mountain view, in which cinema and at what time?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Okay, I can help you with that. First, I need to find the comedy movies playing in Mountain View, CA tonight. Then, for each movie, I will find the theaters showing it and finally get the showtimes for January 1st, 2025.\n",
              "\n",
              "Let's start by finding the comedy movies.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'location': 'Mountain View, CA', 'description': 'comedy'} name='find_movies' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='find_movies' response={'result': ['Barbie', 'Oppenheimer']} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "According to the search results, \"Barbie\" and \"Oppenheimer\" are playing in Mountain View and are categorized as comedy movies.\n",
              "\n",
              "Now let me find the theaters that are showing \"Barbie\" in Mountain View tonight.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'movie': 'Barbie', 'location': 'Mountain View, CA'} name='find_theaters' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='find_theaters' response={'result': ['Googleplex 16', 'Android Theatre']} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Now I will find the showtimes for \"Barbie\" in Googleplex 16 for tonight, January 1st, 2025.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'location': 'Mountain View, CA', 'theater': 'Googleplex 16', 'date': '01/01/2025', 'movie': 'Barbie'} name='get_showtimes' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='get_showtimes' response={'result': ['10:00', '11:00']} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The movie \"Barbie\" is playing at Googleplex 16 at 10:00 and 11:00 PM tonight.\n",
              "\n",
              "Now let me find the showtimes for \"Barbie\" in Android Theatre for tonight, January 1st, 2025.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'movie': 'Barbie', 'location': 'Mountain View, CA', 'date': '01/01/2025', 'theater': 'Android Theatre'} name='get_showtimes' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='get_showtimes' response={'result': ['10:00', '11:00']} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "The movie \"Barbie\" is playing at Android Theatre at 10:00 and 11:00 PM tonight.\n",
              "\n",
              "Now let me find the theaters that are showing \"Oppenheimer\" in Mountain View tonight.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'movie': 'Oppenheimer', 'location': 'Mountain View, CA'} name='find_theaters' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='find_theaters' response={'result': ['Googleplex 16', 'Android Theatre']} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Now I will find the showtimes for \"Oppenheimer\" in Googleplex 16 for tonight, January 1st, 2025.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'theater': 'Googleplex 16', 'date': '01/01/2025', 'location': 'Mountain View, CA', 'movie': 'Oppenheimer'} name='get_showtimes' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='get_showtimes' response={'result': ['10:00', '11:00']} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Okay, here are the comedy movies the API found playing tonight, January 1st, 2025, in Mountain View, CA, along with their showtimes:\n",
              "\n",
              "Based on the search, the movies \"Barbie\" and \"Oppenheimer\" were found under the \"comedy\" description.\n",
              "\n",
              "For \"Barbie\":\n",
              "*   At Googleplex 16, the showtimes are 10:00 PM and 11:00 PM.\n",
              "*   At Android Theatre, the showtimes are 10:00 PM and 11:00 PM.\n",
              "\n",
              "For \"Oppenheimer\":\n",
              "*   At Googleplex 16, the showtimes are 10:00 PM and 11:00 PM.\n",
              "*   At Android Theatre, the showtimes are 10:00 PM and 11:00 PM."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat = client.chats.create(\n",
        "    model = MODEL_ID,\n",
        "    config = {\n",
        "        \"tools\": theater_functions,\n",
        "    }\n",
        ")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Which comedy movies are shown tonight (01/01/2025) in Mountain view, in which cinema and at what time?\"\n",
        ")\n",
        "\n",
        "for content in chat.get_history():\n",
        "    display(Markdown(\"###\" + content.role + \":\"))\n",
        "    for part in content.parts:\n",
        "        if part.text:\n",
        "            display(Markdown(part.text))\n",
        "        if part.function_call:\n",
        "            print(\"Function call: {\", part.function_call, \"}\")\n",
        "        if part.function_response:\n",
        "            print(\"Function response: {\", part.function_response, \"}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb364196a719"
      },
      "source": [
        "Here you can see that the model made seven calls to answer your question and used the outputs of them in the subsequent calls and in the final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuwKoNIhGBJN"
      },
      "source": [
        "## Parallel function calls\n",
        "\n",
        "The Gemini API can call multiple functions in a single turn. This caters for scenarios where there are multiple function calls that can take place independently to complete a task.\n",
        "\n",
        "First set the tools up. Unlike the movie example above, these functions do not require input from each other to be called so they should be good candidates for parallel calling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cJ-mSixWGqLv"
      },
      "outputs": [],
      "source": [
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
        "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      energetic: Whether the music is energetic or not.\n",
        "      loud: Whether the music is loud or not.\n",
        "      bpm: The beats per minute of the music.\n",
        "\n",
        "    Returns: The name of the song being played.\n",
        "    \"\"\"\n",
        "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "    \"\"\"\n",
        "    print(f\"Lights are now set to {brightness:.0%}\")\n",
        "    return True\n",
        "\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlrmXN7fxQi0"
      },
      "source": [
        "Now call the model with an instruction that could use all of the specified tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "21ecYHLgIsCl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Disco ball is spinning!\n",
            "Starting music! energetic=True loud=True, bpm=130\n",
            "Lights are now set to 30%\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Turn this place into a party!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Okay, I can help with that! I'll turn on the disco ball, start some loud, energetic music, and dim the lights.\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: { id=None args={'power': True} name='power_disco_ball' }\n",
            "Function call: { id=None args={'energetic': True, 'loud': True, 'bpm': 130} name='start_music' }\n",
            "Function call: { id=None args={'brightness': 0.3} name='dim_lights' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###user:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function response: { id=None name='power_disco_ball' response={'result': True} }\n",
            "Function response: { id=None name='start_music' response={'result': 'Never gonna give you up.'} }\n",
            "Function response: { id=None name='dim_lights' response={'result': True} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "###model:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Alright, the party is starting! The disco ball is on, the lights are dimmed, and we've got some energetic music playing."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Set the chat up with tools.\n",
        "chat = client.chats.create(\n",
        "    model = MODEL_ID,\n",
        "    config = {\n",
        "        \"tools\": house_fns,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Call the API\n",
        "response = chat.send_message(\n",
        "    \"Turn this place into a party!\"\n",
        ")\n",
        "\n",
        "# Print out each of the function calls requested from this single call.\n",
        "for content in chat.get_history():\n",
        "    display(Markdown(\"###\" + content.role + \":\"))\n",
        "    for part in content.parts:\n",
        "        if part.text:\n",
        "            display(Markdown(part.text))\n",
        "        if part.function_call:\n",
        "            print(\"Function call: {\", part.function_call, \"}\")\n",
        "        if part.function_response:\n",
        "            print(\"Function response: {\", part.function_response, \"}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6iYpty7yZct"
      },
      "source": [
        "As you can see, the model didn't wait for the different function calls and instead called multiple ones in parallel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c2f31504490"
      },
      "source": [
        "## Next Steps\n",
        "### Useful API references:\n",
        "\n",
        "- The [genai.Client](https://googleapis.github.io/python-genai/genai.html#module-genai.client) class\n",
        "  - Its [Client.models.generate_content](https://googleapis.github.io/python-genai/genai.html#genai.models.Models.generate_content) method has a [genai.types.GenerateContentConfig](https://googleapis.github.io/python-genai/genai.html#genai.types.GenerateContentConfig) field that is in particular used to set the tools and function calls.\n",
        "    - The config's `tools` attribute contains a list of [genai.types.Tool](https://googleapis.github.io/python-genai/genai.html#genai.types.Tool)s objects.\n",
        "    - The `function_declarations` attribute contains a list of [genai.types.FunctionDeclarations](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionDeclaration) objects.\n",
        "- The [response](https://googleapis.github.io/python-genai/genai.html#genai.types.GenerateContentResponse)'s [candidate](https://googleapis.github.io/python-genai/genai.html#genai.types.Candidate)'s [content](https://googleapis.github.io/python-genai/genai.html#genai.types.Content)'s [parts](https://googleapis.github.io/python-genai/genai.html#genai.types.Part) may contain a [genai.types.FunctionCall](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionCall), in `response.candidates[0].contents.parts[0]`.\n",
        "- if `automatic_function_calling` is not disabled, the [genai.Chats](https://googleapis.github.io/python-genai/genai.html#module-genai.chats) session executes the call, and sends back the [genai.types.FunctionResponse]https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionResponse).\n",
        "- In response to a [FunctionCall](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionCall) the model always expects a [FunctionResponse](https://googleapis.github.io/python-genai/genai.html#genai.types.FunctionResponse).\n",
        "- If you reply manually using [Chats.send_message](https://googleapis.github.io/python-genai/genai.html#genai.chats.AsyncChat.send_message) or [models.generate_content](https://googleapis.github.io/python-genai/genai.html#genai.models.Models.generate_content) remember thart the API is stateless you have to send the whole conversation history (a list of [Content](https://googleapis.github.io/python-genai/genai.html#genai.types.Content) objects), not just the last one containing the `FunctionResponse`.\n",
        "\n",
        "### Related examples\n",
        "\n",
        "Check those examples using function calling to give you more ideas on how to use that very useful feature:\n",
        "* [Barista Bot](../examples/Agents_Function_Calling_Barista_Bot.ipynb), an agent to order coffee\n",
        "* [Browser-as-a-tool](../examples/Browser_as_a_tool.ipynb), using function calling to call a web-browser.\n",
        "* Using function calling to [re-rank seach results](../examples/Search_reranking_using_embeddings.ipynb).\n",
        "* [Using tools with the Live API](../quickstarts/Get_started_LiveAPI_tools.ipynb), using function calling and other tools with the Live APIs.\n",
        "\n",
        "### Continue your discovery of the Gemini API\n",
        "\n",
        "Learn how to control how the Gemini API interact with your functions in the [function calling config](../quickstarts/Function_calling_config.ipynb) quickstart, discover how to control the model output in [JSON](../quickstarts/JSON_mode.ipynb) or using an [Enum](../quickstarts/Enum.ipynb) or learn how the Gemini API can generate and run code by itself using [Code execution](../quickstarts/Code_Execution.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hY2NtS3jV56U"
      ],
      "name": "Function_calling.ipynb",
      "toc_visible": true
    },
    "google": {
      "image_path": "/site-assets/images/share.png",
      "keywords": [
        "examples",
        "googleai",
        "samplecode",
        "python",
        "embed",
        "function"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
