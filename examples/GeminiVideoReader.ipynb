{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright 2024 Google LLC."
      ],
      "metadata": {
        "id": "7mSjwDa6XKIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "YZKjA-Q3WVYn"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gemini API: GeminiVideoReader -- Batch Prediction with Long Context and Context Caching Code Sample ðŸš€ðŸ§ \n",
        "\n",
        "This notebook serves as a step-by-step guide for building an AI-powered video analysis application.\n",
        "\n",
        "The app uses Streamlit for the web interface, Vertex AI for generating content from video transcripts, and the YouTube Transcript API to fetch transcripts. We also cache summaries to save API calls.\n"
      ],
      "metadata": {
        "id": "QLn8Bjl7XO0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-genai youtube_transcript_api"
      ],
      "metadata": {
        "id": "aGDDxCU8YJcx"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure your API key\n",
        "To run the following cell, your API key must be stored in a Colab Secret named GOOGLE_API_KEY. If you don't already have an API key, or you're not sure how to create a Colab Secret, see Authentication for an example."
      ],
      "metadata": {
        "id": "SgHmdp_javKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "QBvi8w3FYKs1"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries and Initialize Google Gemini Client\n",
        "Import required libraries and initialize the Google Gemini API client using Colabâ€™s userdata."
      ],
      "metadata": {
        "id": "-QmgdCf2YR24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from hashlib import sha256\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\"\n",
        "SYSTEM_PROMPT = \"Answer the question based on the provided transcript context. Provide a concise answer.\"\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"GeminiVideoReader\")\n"
      ],
      "metadata": {
        "id": "nmz--fuOg6Y3"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Define Helper Functions\n",
        "Define functions to extract the YouTube video ID, fetch its transcript, and call the Gemini API asynchronously."
      ],
      "metadata": {
        "id": "NRyRTE8yhAGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_id(url):\n",
        "    if \"v=\" in url:\n",
        "        return url.split(\"v=\")[1].split(\"&\")[0]\n",
        "    elif \"youtu.be/\" in url:\n",
        "        return url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
        "    return None\n",
        "\n",
        "def fetch_youtube_transcript(video_id, lang_code=\"en\"):\n",
        "    try:\n",
        "        return YouTubeTranscriptApi.get_transcript(video_id, languages=[lang_code])\n",
        "    except NoTranscriptFound:\n",
        "        try:\n",
        "            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "            generated_transcript = transcript_list.find_generated_transcript([lang_code])\n",
        "            return generated_transcript.fetch()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Fallback transcript fetch failed: {e}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error fetching transcript: {e}\")\n",
        "        return None\n",
        "\n",
        "def segment_text(text, max_chars=3000):\n",
        "    sentences = text.split('. ')\n",
        "    segments = []\n",
        "    current_segment = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current_segment) + len(sentence) + 1 < max_chars:\n",
        "            current_segment += sentence + \". \"\n",
        "        else:\n",
        "            segments.append(current_segment.strip())\n",
        "            current_segment = sentence + \". \"\n",
        "    if current_segment:\n",
        "        segments.append(current_segment.strip())\n",
        "    return segments\n",
        "\n",
        "class GeminiCache:\n",
        "    CACHE_FILE = \"context_cache.json\"\n",
        "    def __init__(self):\n",
        "        if os.path.exists(self.CACHE_FILE):\n",
        "            with open(self.CACHE_FILE, \"r\") as f:\n",
        "                self.cache = json.load(f)\n",
        "        else:\n",
        "            self.cache = {}\n",
        "    def save_cache(self):\n",
        "        with open(self.CACHE_FILE, \"w\") as f:\n",
        "            json.dump(self.cache, f)\n",
        "    def generate_cache_key(self, text):\n",
        "        return sha256(text.encode()).hexdigest()\n",
        "    def get_or_summarize(self, text, summarization_prompt):\n",
        "        key = self.generate_cache_key(text)\n",
        "        if key in self.cache:\n",
        "            return self.cache[key]\n",
        "        response = client.models.generate_content(\n",
        "            model=f\"models/{MODEL_ID}\",\n",
        "            contents=[f\"{summarization_prompt}\\n{text}\"],\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=\"Summarize the text concisely.\")\n",
        "        )\n",
        "        summary = response.text\n",
        "        self.cache[key] = summary\n",
        "        self.save_cache()\n",
        "        return summary\n",
        "\n",
        "gemini_cache = GeminiCache()\n",
        "\n",
        "def process_long_transcript(transcript_context, max_chars=3000):\n",
        "    if len(transcript_context) <= max_chars:\n",
        "        return transcript_context\n",
        "    segments = segment_text(transcript_context, max_chars)\n",
        "    summarized_segments = []\n",
        "    for seg in segments:\n",
        "        summary = gemini_cache.get_or_summarize(seg, \"Summarize this transcript segment:\")\n",
        "        summarized_segments.append(summary)\n",
        "    return \"\\n\".join(summarized_segments)\n",
        "\n",
        "def call_gemini_api_sync(prompt, cached_context, history, max_retries=3):\n",
        "    history_text = \"\\n\".join([f\"Q: {q['question']} A: {q['answer']}\" for q in history])\n",
        "    full_prompt = f\"Use this context:\\n{cached_context}\\n\\n{history_text}\\n\\n{prompt}\"\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=f\"models/{MODEL_ID}\",\n",
        "                contents=[full_prompt],\n",
        "                config=genai.types.GenerateContentConfig(system_instruction=SYSTEM_PROMPT)\n",
        "            )\n",
        "            return {\"question\": prompt, \"answer\": response.text}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calling Gemini API: {e}. Retrying in {2 ** retries} seconds...\")\n",
        "            time.sleep(2 ** retries)\n",
        "            retries += 1\n",
        "    return {\"question\": prompt, \"answer\": \"Error: Unable to get response after retries.\"}\n",
        "\n",
        "async def call_gemini_api(prompt, cached_context, history):\n",
        "    return await asyncio.to_thread(call_gemini_api_sync, prompt, cached_context, history)\n",
        "\n",
        "async def batch_predict_async(prompts, cached_context, history, max_concurrent=5):\n",
        "    semaphore = asyncio.Semaphore(max_concurrent)\n",
        "    results = []\n",
        "    async def sem_call(prompt):\n",
        "        async with semaphore:\n",
        "            result = await call_gemini_api(prompt, cached_context, history)\n",
        "            history.append(result)\n",
        "            return result\n",
        "    tasks = [asyncio.create_task(sem_call(p)) for p in prompts]\n",
        "    for task in asyncio.as_completed(tasks):\n",
        "        results.append(await task)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "6OqELwaShBTC"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input YouTube Link, Language, and Fetch Transcript\n",
        "\n",
        "Let's use [GSOC 2025 Complete Roadmap: Step by Step Guide as a example](https://www.youtube.com/watch?v=5JYJlQpni6o)"
      ],
      "metadata": {
        "id": "haVE3Xi4lGRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "youtube_url = input(\"Enter the YouTube video URL: \")\n",
        "video_id = extract_video_id(youtube_url)\n",
        "lang_code = input(\"Enter transcript language code (default 'en'): \") or \"en\"\n",
        "if not video_id:\n",
        "    print(\"Invalid YouTube URL!\")\n",
        "else:\n",
        "    print(\"Extracted video ID:\", video_id)\n",
        "transcript_data = fetch_youtube_transcript(video_id, lang_code)\n",
        "if transcript_data is None:\n",
        "    print(\"No transcript available for this video!\")\n",
        "else:\n",
        "    if isinstance(transcript_data, list):\n",
        "        transcript_context = \"\\n\".join([item[\"text\"] for item in transcript_data])\n",
        "    else:\n",
        "        transcript_context = \"\\n\".join(transcript_data)\n",
        "    print(\"Transcript fetched successfully.\")\n",
        "    print(\"\\n--- Transcript Preview (first 500 characters) ---\\n\")\n",
        "    print(transcript_context[:500] + \"\\n...\")\n",
        "    transcript_context = process_long_transcript(transcript_context)\n",
        "    print(\"\\nTranscript context processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIrQWm6FlJPr",
        "outputId": "f3fe6756-f553-4f7f-9df0-08e620c110b6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube video URL: https://www.youtube.com/watch?v=5JYJlQpni6o\n",
            "Enter transcript language code (default 'en'): \n",
            "Extracted video ID: 5JYJlQpni6o\n",
            "Transcript fetched successfully.\n",
            "\n",
            "--- Transcript Preview (first 500 characters) ---\n",
            "\n",
            "20 people got into gck last year from\n",
            "the 100ex cohort I've personally done\n",
            "gck twice it's November right now gso\n",
            "application start in March I think it's\n",
            "the perfect time to get a high level\n",
            "road map of gck in this video I'll take\n",
            "you through how I would prepare for G if\n",
            "I had to do it all over again today G is\n",
            "open not just to students but also to\n",
            "working professionals so irrespective of\n",
            "where you're looking at this video from\n",
            "this video is a high level guide to G\n",
            "2025 without any further Ado l\n",
            "...\n",
            "\n",
            "Transcript context processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Questions and Run Batch Prediction"
      ],
      "metadata": {
        "id": "XxYNMIuIlSRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Enter your questions (one per line). Press Enter on an empty line when done:\")\n",
        "questions_list = []\n",
        "while True:\n",
        "    line = input()\n",
        "    if not line:\n",
        "        break\n",
        "    questions_list.append(line)\n",
        "if not questions_list:\n",
        "    print(\"No questions were entered!\")\n",
        "else:\n",
        "    print(\"Questions received:\", questions_list)\n",
        "if transcript_data is not None and questions_list:\n",
        "    conversation_history = []\n",
        "    results = asyncio.run(batch_predict_async(questions_list, transcript_context, conversation_history))\n",
        "    print(\"\\n--- AI-Generated Answers ---\\n\")\n",
        "    for i, res in enumerate(results, start=1):\n",
        "        print(f\"Q{i}: {res['question']}\")\n",
        "        print(f\"A{i}: {res['answer']}\\n\")\n",
        "    print(\"\\n--- Conversation History ---\\n\")\n",
        "    for entry in conversation_history:\n",
        "        print(f\"Q: {entry['question']}\\nA: {entry['answer']}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "if transcript_data is not None and questions_list:\n",
        "    conversation_history = []\n",
        "    results = asyncio.run(batch_predict_async(questions_list, transcript_context, conversation_history))\n",
        "end_time = time.time()\n",
        "print(f\"\\nTotal batch prediction time: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp6d6KoGlTcd",
        "outputId": "72d1b29c-27a7-48f6-8556-38e05ed0c46a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your questions (one per line). Press Enter on an empty line when done:\n",
            "How to prepaer for Gsoc\n",
            "How to get into Gsoc\n",
            "\n",
            "Questions received: ['How to prepaer for Gsoc', 'How to get into Gsoc']\n",
            "\n",
            "--- AI-Generated Answers ---\n",
            "\n",
            "Q1: How to get into Gsoc\n",
            "A1: To get into GSoC, focus on contributing to open-source projects early and often, especially targeting newer or less popular organizations, and communicate with maintainers.\n",
            "\n",
            "\n",
            "Q2: How to prepaer for Gsoc\n",
            "A2: To prepare for GSoC, target \"luck-based\" organizations if you're a beginner, focus on contributions, talk to maintainers, start early, and choose a stack like JavaScript or Python to become proficient in. Contributions are the most important factor for selection.\n",
            "\n",
            "\n",
            "\n",
            "--- Conversation History ---\n",
            "\n",
            "Q: How to get into Gsoc\n",
            "A: To get into GSoC, focus on contributing to open-source projects early and often, especially targeting newer or less popular organizations, and communicate with maintainers.\n",
            "\n",
            "\n",
            "Q: How to prepaer for Gsoc\n",
            "A: To prepare for GSoC, target \"luck-based\" organizations if you're a beginner, focus on contributions, talk to maintainers, start early, and choose a stack like JavaScript or Python to become proficient in. Contributions are the most important factor for selection.\n",
            "\n",
            "\n",
            "\n",
            "Total batch prediction time: 0.70 seconds\n"
          ]
        }
      ]
    }
  ]
}